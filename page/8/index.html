<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">


























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.0.1">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.0.1">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.0.1">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.0.1">


  <link rel="mask-icon" href="/images/logo.svg?v=7.0.1" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '7.0.1',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false,"dimmer":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta property="og:type" content="website">
<meta property="og:title" content="the Home of MuZhen">
<meta property="og:url" content="http://www.muzhen.tk/page/8/index.html">
<meta property="og:site_name" content="the Home of MuZhen">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="the Home of MuZhen">






  <link rel="canonical" href="http://www.muzhen.tk/page/8/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>the Home of MuZhen</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">the Home of MuZhen</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/machine learning/machine learning/a brief overview of rule learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/machine learning/machine learning/a brief overview of rule learning/" class="post-title-link" itemprop="url">a brief overview of rule learning</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/machine-learning/" itemprop="url" rel="index"><span itemprop="name">machine learning</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><br>本文为《a brief overview of rule learning》的阅读笔记。</p>
<h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h1><p>规则学习分为两类：</p>
<ul>
<li>descriptive rule discovery 描述性规则发现</li>
<li>predictive rule learning 预测性规则学习</li>
</ul>
<h1 id="2-descriptive-rule-discovery"><a href="#2-descriptive-rule-discovery" class="headerlink" title="2 descriptive rule discovery"></a>2 descriptive rule discovery</h1><blockquote>
<p>the focus lies on finding individual rules.</p>
</blockquote>
<p>有两个主要任务：subgroup discovery &amp; association rule discovery</p>
<h2 id="2-1-Subgroup-discovery"><a href="#2-1-Subgroup-discovery" class="headerlink" title="2.1 Subgroup discovery"></a>2.1 Subgroup discovery</h2><p>寻找IF-THEN规则，指向一个类别。</p>
<p>top-down，自顶向下不断缩小规则范围。有一般到特殊。top可以理解为上层比较范的情况，也可以理解为图搜索中的顶点；down可以理解为比较底层比较约束的情况，也可以理解为图搜索中的终点。</p>
<p>下面是一个贪婪搜索的Hill-Climbing算法：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">function FindPredictiveRule (Examples)</span><br><span class="line">Input: Examples, a <span class="keyword">set</span> <span class="keyword">of</span> positive <span class="keyword">and</span> negative examples <span class="keyword">for</span> a <span class="keyword">class</span> c.</span><br><span class="line">//initialize the rule <span class="keyword">body</span></span><br><span class="line">rb ← ∅</span><br><span class="line">// repeatedly find the best refinement <span class="keyword">repeat</span></span><br><span class="line"><span class="keyword">build</span> refinements R ← &#123;rb′ | rb′ = rb ∧ f, <span class="keyword">for</span> <span class="keyword">some</span> feature f&#125; <span class="keyword">evaluate</span> <span class="keyword">all</span> rb′ ∈ R according <span class="keyword">to</span> <span class="keyword">some</span> quality criterion</span><br><span class="line">rb = the best refinement <span class="keyword">in</span> R</span><br><span class="line"><span class="keyword">until</span> rb satisfies a stopping criterion <span class="keyword">or</span> covers <span class="keyword">no</span> examples</span><br><span class="line"><span class="keyword">Output</span>: rule (c ← R)</span><br></pre></td></tr></table></figure>
<p>假设P和N分别为正负样例数，p和n是规则覆盖到的正负样例数。常用的是评价指标有：</p>
<ol>
<li><p>Laplace estimate：<br>$$<br>Lap = \frac{p+1}{p+n+2}<br>$$</p>
</li>
<li><p>m-estimate<br>$$<br>m-estimate = \frac{p+m\cdot P/(P+N)}{p+n+m}<br>$$<br>​</p>
<p>​</p>
</li>
<li><p>information gain<br>$$<br>ig = p\cdot(log_2\frac{p}{p+n}-log_2\frac{p’}{p’+n’})<br>$$</p>
</li>
<li><p>Correlation and $\chi^2$<br>$$<br>corr = \frac{p(N-n)-(P-p)n}{\sqrt{PN(p+n)(P-p+N-n)}}\\<br>\chi^2 = (P+N)corr^2<br>$$<br>​</p>
</li>
</ol>
<h2 id="2-2-Association-Rule-Discovery"><a href="#2-2-Association-Rule-Discovery" class="headerlink" title="2.2 Association Rule Discovery"></a>2.2 Association Rule Discovery</h2><p>Support： 项集覆盖的样本所占比例，也就是频繁程度<br>$$<br>s(X \rightarrow Y) = \frac{\sigma (X \cup Y)}{N}<br>$$<br>Confidence：  Y在包含X的交易中出现的频繁程度<br>$$<br>c(X \rightarrow Y) = \frac{\sigma (X \cup Y)}{\sigma (X)}<br>$$<br>反单调性： 如果一个项集是频繁的，则它的所有子集一定也是频繁的。</p>
<h1 id="3-Predictive-Rule-Learning"><a href="#3-Predictive-Rule-Learning" class="headerlink" title="3 Predictive Rule Learning"></a>3 Predictive Rule Learning</h1><blockquote>
<p>As individual rules will typically only cover part of the training data, we wil need to enforce completeness by learning an unordered rule set or a decision list.</p>
</blockquote>
<p>规则集是无序的，而决策列表有顺序。规则集中每个规则独立的拟合某个类别，而决策列表因为有序，加入了全局性考量。</p>
<p>规则集会带来两个问题：</p>
<ul>
<li>multiple rules fire： 多个规则覆盖相同的样本，并且规则指向的类别不同。可以通过Lap类似指标进行规则重要性排序，这样也相当于将规则集转变为有序的决策列表。还有朴素贝叶斯等解决方案。</li>
<li>no rules fire： 有样本没有被任何规则覆盖到，可以通过default rule，也就是划归多数类来解决。</li>
</ul>
<h2 id="3-1-Classification-by-Association"><a href="#3-1-Classification-by-Association" class="headerlink" title="3.1 Classification by Association"></a>3.1 Classification by Association</h2><p>利用关联规则挖掘去寻找分类规则。</p>
<h2 id="3-2-Covering-Algorithm"><a href="#3-2-Covering-Algorithm" class="headerlink" title="3.2 Covering Algorithm"></a>3.2 Covering Algorithm</h2><blockquote>
<p>the so-called covering or separate-and-conquer algorithm. After a new rule has been learned, all examples that are covered by this rule are removed.</p>
</blockquote>
<figure class="highlight delphi"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">procedure</span> <span class="title">Covering</span> <span class="params">(Examples,Classifier)</span></span></span><br><span class="line"><span class="function"><span class="title">Input</span>:</span> Examples, a <span class="keyword">set</span> <span class="keyword">of</span> positive <span class="keyword">and</span> negative examples <span class="keyword">for</span> a <span class="keyword">class</span> c.</span><br><span class="line"><span class="comment">// initialize the rule set R=;</span></span><br><span class="line"><span class="comment">//loop until no more positive examples are covered while not all positive examples are covered do</span></span><br><span class="line"><span class="comment">// find the best rule for the current examples r = FindPredictiveRule (Examples)</span></span><br><span class="line"><span class="comment">// check if we need more rules if R [ r is good enough</span></span><br><span class="line"><span class="keyword">then</span> <span class="keyword">break</span> <span class="keyword">while</span></span><br><span class="line"><span class="comment">// remove covered examples and add rule to rule set Examples = Examples \ &#123; examples covered by r&#125;</span></span><br><span class="line">R=R[r endwhile</span><br><span class="line">Output: the learned rule <span class="keyword">set</span> R</span><br></pre></td></tr></table></figure>
<h1 id="4-Well-known-Rule-Learning-Algorithms"><a href="#4-Well-known-Rule-Learning-Algorithms" class="headerlink" title="4 Well-known Rule Learning Algorithms"></a>4 Well-known Rule Learning Algorithms</h1><p>AQ2</p>
<p>CN2</p>
<p>FOIL</p>
<p>RIPPER</p>
<p>OPUS</p>
<h1 id="5-Applications-in-Linked-Data-and-Semantic-Web"><a href="#5-Applications-in-Linked-Data-and-Semantic-Web" class="headerlink" title="5 Applications in Linked Data and Semantic Web"></a>5 Applications in Linked Data and Semantic Web</h1><h1 id="6-Conclusion"><a href="#6-Conclusion" class="headerlink" title="6 Conclusion"></a>6 Conclusion</h1><blockquote>
<p>However, whereas a decision tree split is chosen to optimize all successor branches simultaneously, a rule learning heuristic only focuses on a single rule. As a result, rule sets are often more compact than decision trees.</p>
</blockquote>
<p><strong><em>和决策树的区别，规则学习只考虑单分支，或者说满足规则后指向特定分类的有效性，而决策树要整合考虑每个分支的情况。从评价指标就可以看出来，规则学习只考虑规则覆盖样本和总体样本的区分度，而决策树则是综合考虑各个分支，gini求期望。</em></strong></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/machine learning/machine learning/cost function/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/machine learning/machine learning/cost function/" class="post-title-link" itemprop="url">cost function</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/machine-learning/" itemprop="url" rel="index"><span itemprop="name">machine learning</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script></p>
<h1 id="hinge-loss"><a href="#hinge-loss" class="headerlink" title="hinge loss"></a>hinge loss</h1><p>对于非连续可微损失函数，如何优化？以hinge loss为例</p>
<p><a href>Pegasos: primal estimated sub-gradient solver for SVM</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/machine learning/machine learning/covariate shift/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/machine learning/machine learning/covariate shift/" class="post-title-link" itemprop="url">covariate shift</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/machine-learning/" itemprop="url" rel="index"><span itemprop="name">machine learning</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script></p>
<h1 id="covariate-shift"><a href="#covariate-shift" class="headerlink" title="covariate shift"></a>covariate shift</h1><p>训练集和测试集的分布不一致，会导致train得到的estimator无法在test上有好的效果。</p>
<h1 id="method"><a href="#method" class="headerlink" title="method"></a>method</h1><p>可以通过sample reweight方法来改变训练集的分布，从而达到实际训练的train分布和test分布一致。</p>
<p>权重计算一般可以采用这样的方式：</p>
<p>将train和test合在一起建模，label为case所属的数据集，train-1，test-0，通过五折交叉可以得到trian的每个case的预测得分，得分越高，说明越容易和test区分，也就是越不可能是test分布所产出的结果。故而得分取倒数在做归一化就可以得到train的每个case对应权重。</p>
<p>同时根据得分可以计算<strong><em>mcc指标</em></strong>，该指标可以作为train和test分布不一致性的一个度量指标，越大越不一致。</p>
<p><strong><em>但是在个人实践中发现，sample reweight并不能带来更好的效果，反而有时效果还更差。</em></strong></p>
<p>由于这个结果比较反常识，个人查阅了一些资料，发现确实有论文和实验强调sample reweight无效。具体见<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5070592/" target="_blank" rel="noopener">Understanding covariate shift in model performance</a>。</p>
<p>当然，可以不同的数据集适用不同的处理方法， 不能一概而论之。</p>
<h1 id="另一种解决方法"><a href="#另一种解决方法" class="headerlink" title="另一种解决方法"></a>另一种解决方法</h1><p>可以考虑从分布不一致的根源上入手来解决问题。</p>
<p>个人面临的实际问题是业务策略频繁变动，导致同一个产品在不同时间的客群并不一样（对客群划分等级，然后这个星期将低等级用户分发给该产品，下个星期将高等级用户分发给该产品）。在这种情况下，如果使用历史样本进行建模，会发现在近期客群上效果很差。由于一般情况下，客群本身并不大可能在短时间频繁变动。因此，可以拉长采样的时间线，确保客群的不同类型都可以被纳入样本之中，如此一来，就可以保证模型对新客群（总体客群中的某一部分）具有适应性。在这个过程中，有一点需要注意，采样时应当保证客群各等级比例和实际情况应当一致，不然会受到产品策略的影响导致比重失衡。</p>
<h1 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h1>
          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/machine learning/machine learning/logistic regression/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/machine learning/machine learning/logistic regression/" class="post-title-link" itemprop="url">logistic regression</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/machine-learning/" itemprop="url" rel="index"><span itemprop="name">machine learning</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

<h1 id="LR形式"><a href="#LR形式" class="headerlink" title="LR形式"></a>LR形式</h1><p>$$f(x) = \frac{1}{1+e^{-\theta^T x}}$$</p>
<p>$$P(y=1) = \frac{1}{1+e^{-\theta^T x}} = h_\theta(x)$$</p>
<p>$$P(y=0) = 1 - \frac{1}{1+e^{-\theta^T x}} = 1 - h_\theta(x)$$</p>
<p>$$P(y) = (\frac{1}{1+e^{-\theta^T x}})^y (1 - \frac{1}{1+e^{-\theta^T x}})^{1-y}$$<br>这里蕴含一个假设：<strong><em>给定X和参数，Y服从二项分布</em></strong> </p>
<p>在普通线性回归中，我们也有一个假设：<strong><em>随机扰动项服从零均值正态分布，故而给定X和参数，Y服从正态分布</em></strong></p>
<h1 id="极大似然法"><a href="#极大似然法" class="headerlink" title="极大似然法"></a>极大似然法</h1><p>需要使样本$(x_i,y_i)$出现几率最大，即：<br>$$\arg\max_{\theta} \prod_i h_\theta(x_i)^{y_i} (1-h_\theta(x_i))^{1-y_i}$$</p>
<p>转为为对数问题有：<br>$$\arg\max_{\theta} \sum_i y_i \ln(h_\theta(x_i)) + (1-y_i) \ln((1-h_\theta(x_i)))$$</p>
<p>即是：<br>$$\arg\min_{\theta} -\sum_i y_i \ln(h_\theta(x_i)) + (1-y_i) \ln((1-h_\theta(x_i)))$$</p>
<p>即是最小化损失函数：<br>$$\arg\min_{\theta}  J(\theta) = \arg\min_{\theta}  -\sum_i y_i \ln(h_\theta(x_i)) + (1-y_i) \ln((1-h_\theta(x_i)))$$</p>
<h1 id="references"><a href="#references" class="headerlink" title="references"></a>references</h1><p><strong><em><a href="http://blog.csdn.net/lilyth_lilyth/article/details/10032993" target="_blank" rel="noopener">对数线性模型之一(逻辑回归), 广义线性模型学习总结</a></em></strong></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/machine learning/machine learning/pagerank/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/machine learning/machine learning/pagerank/" class="post-title-link" itemprop="url">pagerank</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/machine-learning/" itemprop="url" rel="index"><span itemprop="name">machine learning</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p>pagerank算法是为了分析网页排名（PR值）。可以想象：</p>
<ul>
<li>网页被其他网页指向次数越多，越重要</li>
<li>排名高的网页具有更大的表决权，换言之，具有更大的权重</li>
</ul>
<p>所以，pagerank的原理就是： 一个网页的排名等于所有链接到该网页的网页的排名加权和。</p>
<p>显然，这样的排名相较于根据关键词在网页中出现次数的搜索更为客观。</p>
<p>但是，每个网页应该只能投一票。因此，如果一个网页链接到10个网页，那么它对每个网页的贡献就是其自身排名的1/10。</p>
<p>由于每个网页排名取决于其他，因此就存在“鸡生蛋蛋生鸡”的问题。通过赋初值，然后求收敛值的方法来求解。pagerank是否有解通过以下两点来决定：</p>
<ul>
<li>是否存在收敛值</li>
<li>收敛极限是否与初值有关</li>
</ul>
<p>这样，问题也就转化成了Markov过程的收敛性证明。若要收敛，需要状态转移矩阵满足3个条件：</p>
<ul>
<li>是随机矩阵，严格的说是每一列的矩阵元素非负、之和为1（随机矩阵并非只有这一种形式）</li>
<li>不可约，即矩阵对应有向图必须强连通，对于任意两个节点存在连通路径</li>
<li>非周期，每个节点存在自回路</li>
</ul>
<p>当我们假设用户可以一定概率不根据状态转移矩阵而是随机访问（等概率访问）每个网页时，不可约和非周期就得到了满足。这个假设的现实意义就是用户不通过链接进行跳转而是直接在地址栏输入网址进行访问。</p>
<h1 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h1><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><p>是一个与查询无关的静态算法，所有网页的PageRank值通过离线计算获得；有效减少在线查询时的计算量，极大降低了查询响应时间。</p>
<h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><ol>
<li><p>人们的查询具有主题特征，PageRank忽略了主题相关性，导致结果的相关性和主题性降低</p>
</li>
<li><p>没有区分站内导航链接。很多网站的首页都有很多对站内其他页面的链接，称为站内导航链接。这些链接与不同网站之间的链接相比，肯定是后者更能体现PageRank值的传递关系。</p>
</li>
<li><p>没有过滤广告链接和功能链接（例如常见的“分享到微博”）。这些链接通常没有什么实际价值，前者链接到广告页面，后者常常链接到某个社交网站首页。</p>
</li>
<li><p>对新网页不友好。一个新网页的一般入链相对较少，即使它的内容的质量很高，要成为一个高PR值的页面仍需要很长时间的推广。</p>
</li>
</ol>
<h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python3</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Sat Sep  2 18:52:27 2017</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: muzhen</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># transition matrix a, a[i][j] represents whether web j exists link to web i or not.</span></span><br><span class="line">a = np.array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">              [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">              [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">              [<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>]], dtype=float)</span><br><span class="line"></span><br><span class="line"><span class="comment"># compute the transition probability matrix</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">graphmove</span><span class="params">(a)</span>:</span></span><br><span class="line">    b = np.sum(a, axis=<span class="number">0</span>)</span><br><span class="line">    c = a / b</span><br><span class="line">    <span class="keyword">return</span> c</span><br><span class="line">    </span><br><span class="line"><span class="comment"># init probability vector which represents the probability user in each web at first.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">firstPr</span><span class="params">(c)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.full((c.shape[<span class="number">0</span>],<span class="number">1</span>), <span class="number">1.0</span>/c.shape[<span class="number">1</span>])</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pagerank</span><span class="params">(c,pr,b)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        b is the prob user changes web by transition matrix, (1 - b) is the prob user changes web accordding to probability vector.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    pr_init = pr</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">        pr_new = b * np.dot(c, pr) + (<span class="number">1</span> - b) * pr_init</span><br><span class="line">        <span class="keyword">if</span> (pr == pr_new).all() == <span class="keyword">True</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            pr = pr_new</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> pr_new</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:o</span><br><span class="line"></span><br><span class="line">    c = graphmove(a)</span><br><span class="line">    pr = firstPr(c)</span><br><span class="line">    b = <span class="number">0.85</span></span><br><span class="line">    pr = pagerank(c, pr, b)</span><br><span class="line">    print(pr)</span><br></pre></td></tr></table></figure>
<h1 id="references"><a href="#references" class="headerlink" title="references"></a>references</h1><p><a href="http://blog.csdn.net/hguisu/article/details/7996185" target="_blank" rel="noopener">PageRank算法</a></p>
<p><a href="http://blog.csdn.net/lanchunhui/article/details/50618566" target="_blank" rel="noopener">随机矩阵（stochastic matrix）与 PageRank</a></p>
<p><a href="http://www.cnblogs.com/en-heng/p/6124526.html" target="_blank" rel="noopener">【十大经典数据挖掘算法】PageRank</a></p>
<p><a href="http://www.cnblogs.com/rubinorth/p/5799848.html" target="_blank" rel="noopener">PageRank算法–从原理到实现</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/machine learning/machine learning/《ESL第2章 有指导学习概述》/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/machine learning/machine learning/《ESL第2章 有指导学习概述》/" class="post-title-link" itemprop="url">《ESL第2章 有指导学习概述》</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/machine-learning/" itemprop="url" rel="index"><span itemprop="name">machine learning</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script></p>
<h1 id="第2章-有指导学习概述"><a href="#第2章-有指导学习概述" class="headerlink" title="第2章 有指导学习概述"></a>第2章 有指导学习概述</h1><p>线性判别边界：在不同类别服从区分明显的不同分布时合适<br>非线性判别边界：在不同类别所服从分布相对紧密时适用</p>
<p>最小二乘方：假定可以用一个全局线性函数很好地近似<br>k-最近邻：假定可以用一个局部常量函数很好地近似</p>
<p>knn有效参数个数：表面上是1个，即邻居个数k，其实是N/k个（其中N为样本量，k为邻居个数，如果邻域不重叠，需要为每个邻域配一个参数（均值））。  </p>
<p>真实数据往往是由类似高斯混合分布这样的形式所产生。</p>
<p>回归函数就是求给定x下的条件期望。（个人以为推广到分类问题中也没有问题。。）<br>\begin{split} f(x) = E(Y|X = x)\end{split}</p>
<p>最近邻则是<br>\begin{split} \hat{f(x)} = Ave(y_i|x_i \in N_k(x))\end{split}<br>发生了两次近似：</p>
<ol>
<li>用均值来近似期望</li>
<li>在点上取条件放宽为在“靠近”目标点的某区域上取条件</li>
</ol>
<p>可以证明：<br>\begin{split} \hat{f(x)} \rightarrow E(Y|X = x) \text{ when } N,k \rightarrow \infty,N/k \rightarrow 0,\end{split}</p>
<p>那么最近邻的缺点在哪里呢？</p>
<ol>
<li>在样本容量不够大的情况下，收敛效果并不会很好</li>
<li>随着样本维度提高，邻域度量规模也增大。虽然收敛性依然成立，但是收敛速度会随着维数增加而降低。</li>
</ol>
<p>因此我们可以考虑某种更结构化的模型，通常可以得到更稳定的估值。</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/machine learning/machine learning/《ESL第3章 回归的线性方法》/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/machine learning/machine learning/《ESL第3章 回归的线性方法》/" class="post-title-link" itemprop="url">《ESL第3章 回归的线性方法》</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/machine-learning/" itemprop="url" rel="index"><span itemprop="name">machine learning</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script></p>
<h1 id="第3章-回归的线性方法"><a href="#第3章-回归的线性方法" class="headerlink" title="第3章 回归的线性方法"></a>第3章 回归的线性方法</h1><h2 id="3-2-线性回归模型和最小二乘方"><a href="#3-2-线性回归模型和最小二乘方" class="headerlink" title="3.2 线性回归模型和最小二乘方"></a>3.2 线性回归模型和最小二乘方</h2><p>线性回归模型是指<strong>参数线性</strong>。</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/machine learning/machine learning/不同模型分数统一尺度/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/machine learning/machine learning/不同模型分数统一尺度/" class="post-title-link" itemprop="url">不同模型分数统一尺度</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/machine-learning/" itemprop="url" rel="index"><span itemprop="name">machine learning</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>



<p>最近在做一个项目，希望将不同风险评分模型的输出概率统一，得到一个标准尺度来度量所有用户的风险评分。</p>
<p>阅读了论文<a href="http://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0087357&amp;type=printable" target="_blank" rel="noopener">《Mutual Information between Discrete and Continuous Data Sets》</a> 之后，有一点想法。</p>
<p>首先，这篇论文比较了基于KNN的互信息（MI）计算方法和基于分箱的MI计算方法，可以看到基于分箱的MI严重受到分箱数量影响。而基于kNN的MI则很稳定，基本不受到超参K的影响。我利用数据计算了基于不同分箱数的IV，发现随着分箱数的增加，IV呈现增加趋势。在传统处理中，我们一般在计算IV时都会选择十等分，这显然是没有考虑到不同特征的差异。换言之，基于十等分的IV在不同特征上很难说有可比性。</p>
<p>其次，我觉得基于KNN的MI计算方法可以应用到模型评分统一上来。有两种方案：</p>
<ul>
<li>基于KNN，计算每个点的K近邻范围内所有样本的逾期率，建立该点得分到逾期率的映射。相较于直接进行等频分箱，可以保证映射的连续性。至于说这样做法可能导致低概率点的映射逾期率比高概率点更低的情况，这是由于模型本身效果不佳，缺乏排序能力导致的，只能从模型端来根本解决，能够进行的后期修正就是得到映射关系之后，再进行小范围的聚合来进行分数平滑。牵涉的难点是超参k的选择和平滑方式。超参k的选择可以转化为距离度量问题，根据输出概率的一阶差分来进行动态设定。平滑方式也可以采用类似方式。</li>
<li>用户只有好坏两类，用户评分的本质就是对于用户类型的不确定性度量。所以可以直接计算基于KNN的MI，作为该点的不确定性度量，然后配合采用分箱方法得到的基准逾期率进行调整。</li>
</ul>
<p>其实根本问题就是如何细致的分箱，在保证每箱对应的逾期率有意义的同时保留尽可能多的信息。</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/machine learning/machine learning/决策树/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/machine learning/machine learning/决策树/" class="post-title-link" itemprop="url">决策树</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/machine-learning/" itemprop="url" rel="index"><span itemprop="name">machine learning</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

<h1 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h1><ol>
<li><p>ID3为什么用信息增益最大而不是直接用熵最小？<br>因为只有信息增益大于0才有继续分裂的价值。</p>
</li>
<li><p>为什么在计算信息增益时使用的是分裂后子节点熵的期望？<br>因为关注的是分裂后的效果。只要子节点平均程度上熵减，就说明分裂后分类效果更好。</p>
</li>
<li><p>C4.5中是直接使用信息增益比来选择特征么？<br>先需要计算信息增益，大于一定值后在计算信息增益比。不然的话可能因为特征熵很小导致信息增益比很大。从而选择不合适的特征。</p>
</li>
<li><p>cart 和 id3、c4.5区别？<br>最重要的区别cart是二叉树！并且cart可以做回归！</p>
</li>
<li><p>CART 分类与回归的区别？<br>分类树：使用分裂后gini期望作为评判标准（和信息增益并没有区别，因为父节点熵都相同，用不用父节点熵去减来计算信息增益不影响计算）。而不使用信息增益比则是因为它是二叉树，不会受特征取值影响！<br>在分裂上，按等于某个值和不等于某一个值来选择最有特征和最优切分点进行分裂。<br>在决策上，取叶子节点众数作为label。<br>回归树：使用均方误差总和作为标准来进行分裂。<br>在分裂上，按小于等于某个值和大于某个值来选择最有特征和最优切分点进行分裂。<br>在决策上，取叶子节点均值作为label。<br><strong>需要注意，在使用gini时，是求期望，而在使用mse时，是分裂后两个叶子节点的mse直接加和。可以这样理解，gini度量的是不纯度，两个叶节点的不纯度不适合通过加和来表明总样本的不纯度，而应该使用期望。但mse应当求和，这样子才能反映总样本的偏差。</strong></p>
</li>
<li><p>cart分类树为什么在特征切分上不使用大于等于的二分法？<br>[TBC]</p>
</li>
<li><p>cart的剪枝原理？<br>[TBC]</p>
</li>
<li><p>gini系数 和 信息增益的区别<br><a href="https://www.garysieling.com/blog/sklearn-gini-vs-entropy-criteria" target="_blank" rel="noopener">Decision Trees: “Gini” vs. “Entropy” criteria</a></p>
<figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Gini <span class="keyword">is</span> intended <span class="keyword">for</span> continuous attributes, <span class="keyword">and</span> Entropy <span class="keyword">for</span> attributes <span class="keyword">that</span> occur <span class="keyword">in</span> classes</span><br><span class="line">“Gini” will tend <span class="keyword">to</span> find <span class="keyword">the</span> largest <span class="built_in">class</span>, <span class="keyword">and</span> “entropy” tends <span class="keyword">to</span> find groups <span class="keyword">of</span> classes <span class="keyword">that</span> make up ~<span class="number">50</span>% <span class="keyword">of</span> <span class="keyword">the</span> data</span><br><span class="line">“Gini” <span class="keyword">to</span> minimize misclassification3</span><br><span class="line">“Entropy” <span class="keyword">for</span> exploratory analysis4</span><br><span class="line">Some studies show this doesn’t matter – these differ <span class="keyword">less than</span> <span class="number">2</span>% <span class="keyword">of</span> <span class="keyword">the</span> time5</span><br><span class="line">Entropy may be a little slower <span class="keyword">to</span> compute6</span><br></pre></td></tr></table></figure>
</li>
</ol>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/machine learning/machine learning/分类和回归/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/machine learning/machine learning/分类和回归/" class="post-title-link" itemprop="url">分类和回归</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/machine-learning/" itemprop="url" rel="index"><span itemprop="name">machine learning</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script></p>
<h1 id="分类和回归区别"><a href="#分类和回归区别" class="headerlink" title="分类和回归区别"></a>分类和回归区别</h1><ul>
<li><p>从输出上说，分类输出是离散值，回归输出是连续值。</p>
</li>
<li><p>从预测过程上说，分类是找寻分离超平面，回归是找寻一个超平面使得目标值是样本点到超平面距离？<br>显然不能如此理解，因为线性回归就不符合。</p>
</li>
</ul>
<h1 id="模型比较"><a href="#模型比较" class="headerlink" title="模型比较"></a>模型比较</h1><ul>
<li><p>CART<br>作为回归树，分类结果是叶节点y值均值。<br>作为分类树，分类结果是叶节点类别众数。  </p>
</li>
<li><p>线性回归<br>对于经典线性回归，是线性拟合结果。<br>对于logistic回归，是线性拟合结果的S型变换。</p>
</li>
<li><p>支持向量机<br>[TBC]SVR。<br>SVM则是将该距离使用符号函数改为分类结果。</p>
</li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/machine learning/machine learning/回归树/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/machine learning/machine learning/回归树/" class="post-title-link" itemprop="url">回归树</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/machine-learning/" itemprop="url" rel="index"><span itemprop="name">machine learning</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script></p>
<h1 id="CART"><a href="#CART" class="headerlink" title="CART"></a>CART</h1><p>ID3,C4.5都只能做分类，不能做回归。CART则采用了二叉树的形式，使用Gini系数构建分类树，使用均方误差构建回归树。</p>
<p>在构建回归树时，根据分裂后各子节点均方误差之和与父节点均方误差的差值来选择分裂条件进行分裂。</p>
<p>构建好后，新的测试样本的预测值是其所在叶节点中训练样本label的均值。<br>如果真是这样，那么回归树是没有办法进行拓展的，换言之对于不在训练集范围的y值它无法预测到。例如，他做不到线性回归的拓展性。</p>
<p>生成回归树之后，在各叶节点上建立线性回归模型，产生最终预测结果。换言之，可以理解为先通过分类选择临近样本点，利用临近样本点去进行回归学习。<br>也就是先分类缩小范围再回归。<strong>局部加权回归思想的一种变体</strong>。</p>
<p>[TBC]<br><a href="http://www.stat.wisc.edu/~loh/treeprogs/guide/wires11.pdf" target="_blank" rel="noopener">回归树</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/machine learning/machine learning/局部加权回归/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/machine learning/machine learning/局部加权回归/" class="post-title-link" itemprop="url">局部加权回归</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/machine-learning/" itemprop="url" rel="index"><span itemprop="name">machine learning</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script></p>
<h1 id="非参数学习方法"><a href="#非参数学习方法" class="headerlink" title="非参数学习方法"></a>非参数学习方法</h1><p><strong>参数学习方法</strong>：在训练完成所有数据后得到一系列训练参数，然后根据训练参数来预测新样本的值，不再依赖之前的训练数据，参数值是确定的。</p>
<p><strong>非参数学习方法</strong>：在预测新样本值时候每次都会重新训练数据得到新的参数值，也就是说每次预测新样本都会依赖训练数据集合，所以每次得到的参数值是不确定的。</p>
<h1 id="局部加权回归"><a href="#局部加权回归" class="headerlink" title="局部加权回归"></a>局部加权回归</h1><p>在普通的回归问题中，均方误差损失：<br>$$J(\theta) = \frac{1}{n} \sum_i (h_\theta(x_i) - y_i)^2$$</p>
<p>局部加权回归中，均方误差损失：<br>$$J(\theta) = \frac{1}{n} \sum_i \omega_i (h_\theta(x_i) - y_i)^2$$<br>$$\omega_i = \exp(- \frac{(x_i - x)^2}{2 \tau^2})$$<br>其中，$x$是待预测的样本点，按待预测点与样本点距离分配权重。<br>显然，对于每一个需要预测的样本点，都需要重新建立模型去预测，计算量会更大，但欠拟合问题会被削弱。</p>
<h1 id="references"><a href="#references" class="headerlink" title="references"></a>references</h1><p><a href="http://blog.csdn.net/acdreamers/article/details/44662753" target="_blank" rel="noopener">局部加权回归</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/machine learning/machine learning/广义线性模型/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/machine learning/machine learning/广义线性模型/" class="post-title-link" itemprop="url">广义线性模型</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/machine-learning/" itemprop="url" rel="index"><span itemprop="name">machine learning</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>[TBC]</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/machine learning/machine learning/生成模型与判别模型/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/machine learning/machine learning/生成模型与判别模型/" class="post-title-link" itemprop="url">生成模型与判别模型</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/machine-learning/" itemprop="url" rel="index"><span itemprop="name">machine learning</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>
          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/machine learning/machine learning/线性判别分析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/machine learning/machine learning/线性判别分析/" class="post-title-link" itemprop="url">线性判别分析</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/machine-learning/" itemprop="url" rel="index"><span itemprop="name">machine learning</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script></p>
<h1 id="LDA思想"><a href="#LDA思想" class="headerlink" title="LDA思想"></a>LDA思想</h1><p>将训练样例投影到一条直线上，使得同类样例尽可能近，异类样例尽可能远。在对新样例进行分类时，将其投影到同样的这条直线上，在根据投影点位置来确定样例类别。</p>
<p><img src="http://i1.piimg.com/588926/e3666f601ae4b470.png" alt><br>其中，$\omega$是直线方向向量，x是样例向量，两者内积就是样例在直线上投影。</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/machine learning/machine learning/高维稀疏特征建模/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/machine learning/machine learning/高维稀疏特征建模/" class="post-title-link" itemprop="url">高维稀疏特征建模</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/machine-learning/" itemprop="url" rel="index"><span itemprop="name">machine learning</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><script type"text javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><br>[TBC]为什么对于高维稀疏特征，很多算法无效。比如gbm？</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/machine learning/math/Jensen不等式/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/machine learning/math/Jensen不等式/" class="post-title-link" itemprop="url">Jensen不等式</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/math/" itemprop="url" rel="index"><span itemprop="name">math</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script></p>
<p>#凸函数定义与性质</p>
<p>#Jensen不等式证明</p>
<p>[TBC]</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/machine learning/optimization/EM算法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/machine learning/optimization/EM算法/" class="post-title-link" itemprop="url">EM算法</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/optimization/" itemprop="url" rel="index"><span itemprop="name">optimization</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script></p>
<h1 id="实际问题"><a href="#实际问题" class="headerlink" title="实际问题"></a>实际问题</h1><p>假设我们有一个样本集$\{x_1,x_2,…,x_n\}$，各样本独立。但是，各样本对应的分布$z_i$未知。换言之，该样本集并不是从同一分布中取出，而是从多个分布中的某一个取出。$z$ 是隐含变量，表示服从哪个分布。<br>在此种情况下，使用极大似然法，求使得似然概率最大的参数$\theta$（没有先验，也就谈不上后验概率）。</p>
<h1 id="极大似然法"><a href="#极大似然法" class="headerlink" title="极大似然法"></a>极大似然法</h1><p>依旧希望似然概率最大，即：<br>$$\arg \max_\theta \sum_{x_i} \log p(x_i;\theta)$$</p>
<blockquote>
<p><strong>由于无法直接求出似然函数解析解，EM算法通过不断寻找似然函数的紧密下界，然后寻找使下界最优的$\theta$（由于紧密，往往也可以优化似然函数），如此不断迭代至似然函数最优。正是因为这个想法，才会想到使用Jensen不等式去找寻下界。</strong></p>
</blockquote>
<p>其中,根据Jensen不等式可推得：<br>\begin{eqnarray} l(\theta) = \sum_{x_i} \log p(x_i;\theta) &amp;&amp; = \sum_{x_i} \log \sum_{z_j} p(x_i,z_j;\theta)  \tag{1} \newline<br>&amp;&amp; = \sum_{x_i} \log \sum_{z_j} p(z_j) \frac{p(x_i,z_j;\theta)}{p(z_j)} \tag{2} \newline<br>&amp;&amp; \geq \sum_{x_i} \sum_{z_j} p(z_j) \log \frac{p(x_i,z_j;\theta)}{p(z_j)} \tag{3}\end{eqnarray}</p>
<p>因此，可以通过不断优化（3）式来不断提高似然函数下界，最终使之收敛到最优$\theta$。  </p>
<blockquote>
<p>这里需要说明，$p(z)$是为了数学优化目的而出现的一个概率分布列，它和隐变量分布的参数并不等同。事实上，它是给定参数(包括隐变量参数和各分布参数)和样本情况下的后验概率。</p>
</blockquote>
<h1 id="EM算法"><a href="#EM算法" class="headerlink" title="EM算法"></a>EM算法</h1><p><img src="http://p1.bqimg.com/519918/5b876e7671bd61e7.png" alt><br>(图中Q(z)即指p(z))</p>
<blockquote>
<ol>
<li>首先固定$\theta$，寻找合适的$p(z)$，使（3）成为似然函数的合宜下界。显然，在（1）=（3）时最为合宜。因为合宜，故而在此时，我们可以理解为（3）和（1）有相近的性质;</li>
<li>然后固定求得的$p(z)$,求使得（3）式达到最大值的$\theta$。因为（3）和（1）有相近的性质，因此使得（3）式达到最大值的$\theta$应该可以让似然函数变大;</li>
<li>不断迭代最终得到最优解。<br>（严格证明见下一部分）</li>
</ol>
</blockquote>
<p>由于$\log x$严格凹，$\lambda_i &gt; 0$,当且仅当自变量为常数时取等号:<br>\begin{split}&amp;&amp; \sum_i \log \lambda_i x_i \geq \sum_i \lambda_i \log x_i \newline<br>&amp;&amp; \text{equality is true,if and only if } \quad x_i = c,i=1,2,3,…<br>\end{split}</p>
<p>因此，当（1）=（3）时：<br>\begin{split}\frac{p(x_i,z_j;\theta)}{p(z_j)} = c,i=1,2,3,…\end{split}<br>由于多个等式分子分母相加不变：<br>\begin{split}c = \frac{\sum_j p(x_i,z_j;\theta)}{\sum_j p(z_j)} = \sum_j p(x_i,z_j;\theta) = p(x_i;\theta)\end{split}<br>因此：<br>\begin{eqnarray} p(z_j) &amp;&amp;= \frac{p(x_i,z_j;\theta)}{c} \tag{4} \newline<br>&amp;&amp;= \frac{p(x_i,z_j;\theta)}{\sum_j p(x_i,z_j;\theta)} \tag{5} \newline<br>&amp;&amp;= \frac{p(x_i,z_j;\theta)}{p(x_i;\theta)}  \tag{6} \newline<br>&amp;&amp;= p(z_j|x_i;\theta) \tag{7} \end{eqnarray}</p>
<p>另一方面：<br>\begin{eqnarray} p(x_i;\theta) = \sum_j p(x_i,z_j;\theta) = \sum_j p(z_j;\theta) p(x_i|z_j;\theta) \tag{8} \end{eqnarray}</p>
<blockquote>
<p>这里需要作出一些重要说明，我所看到的部分EM讲解（references中已列出部分）将z的角标也用成i，我在这里区分为j。同时，它们往往给出（7）式就结束，并没有明确说明如何求出p(z)。我在这里说明下我对其求法的理解:</p>
<ol>
<li>$p(z)$一般是多项分布的概率分布列，z取值个数已知（[TBC]如果z是连续值呢？）;</li>
<li>$p(z_j)$应该是通过（6）式即贝叶斯公式求得。其中分母利用（8）式求得;</li>
<li>显见的，对于每一个$x_i$，都可以求出整体$p(z_j),j=1,2,3,…$,标记为$p_{x_i}(z_j)$。故而，最终应该有:<br>\begin{eqnarray} p(z_j) = \sum_{x_i} p_{x_i}(z_j),j = 1,2,3,… \tag{9}\end{eqnarray}<br>正是因为（9），E步叫做求期望。（我是这样理解的～但貌似不对？） </li>
</ol>
</blockquote>
<p>EM算法整体步骤：  </p>
<ol>
<li>给定参数初值(包括隐变量参数和各分布参数)，</li>
<li>（E步，求期望）根据上一步给定的$\theta$,计算后验概率$p(z)$  </li>
<li>（M步，最大化）根据计算出的$p(z)$，带回（3）式，求使之最大的$\theta$<br>循环往复，直至收敛。</li>
</ol>
<p>期望-最大算法不是指最大化期望！只是两个步骤而已。</p>
<h1 id="收敛性证明"><a href="#收敛性证明" class="headerlink" title="收敛性证明"></a>收敛性证明</h1><p>首先明确顺序问题：初始状态，给定初始$\theta^{(1)}$和$p^{(0)}(z)$;第一次迭代，E步求出$p^{(1)}(z)$，然后M步求出$\theta^{(2)}$;第t次迭代，给定$\theta^{(t)}$，E步求出$p^{(t)}(z)$，然后M步求出$\theta^{(t+1)}$。</p>
<p>那么，因为在t时刻是根据（1）=（3）求出$p^{(t)}(z)$，那么有：<br>$$ l(\theta^{(t)}) = \sum_{x_i} \sum_{z_j} p^{(t)}(z_j) \log \frac{p(x_i,z_j;\theta^{(t)})}{p^{(t)}(z_j)}$$<br>而$\theta^{(t+1)}$是对上式右边求最大值得到的，因此显然有：<br>$$\sum_{x_i} \sum_{z_j} p^{(t)}(z_j) \log \frac{p(x_i,z_j;\theta^{(t+1)})}{p^{(t)}(z_j)} \geq \sum_{x_i} \sum_{z_j} p^{(t)}(z_j) \log \frac{p(x_i,z_j;\theta^{(t)})}{p^{(t)}(z_j)} = l(\theta^{(t)})$$<br>另一方面：<br>\begin{eqnarray} l(\theta^{(t+1)}) = \sum_{x_i} \log p(x_i;\theta^{(t+1)}) &amp;&amp; = \sum_{x_i} \log \sum_{z_j} p(x_i,z_j;\theta^{(t+1)}) \newline<br>&amp;&amp; = \sum_{x_i} \log \sum_{z_j} p(z_j) \frac{p(x_i,z_j;\theta^{(t+1)})}{p(z_j)} \newline<br>&amp;&amp; \geq \sum_{x_i} \sum_{z_j} p(z_j) \log \frac{p(x_i,z_j;\theta^{(t+1)})}{p(z_j)} \newline<br>&amp;&amp; \geq \sum_{x_i} \sum_{z_j} p^{(t)}(z_j) \log \frac{p(x_i,z_j;\theta^{(t)})}{p^{(t)}(z_j)} \newline<br>&amp;&amp; = l(\theta^{(t)})\end{eqnarray}<br>如此就可以证明迭代过程中似然函数的单调增性。单调有界故而收敛。<br>似然函数是凸函数才能收敛到全局最优值。</p>
<h1 id="实例：三硬币模型"><a href="#实例：三硬币模型" class="headerlink" title="实例：三硬币模型"></a>实例：三硬币模型</h1><p>参 李航《统计学习方法——EM算法》</p>
<h1 id="PRML角度"><a href="#PRML角度" class="headerlink" title="PRML角度"></a>PRML角度</h1><p>[TBC]PRML角度<br><a href="https://mqshen.gitbooks.io/prml/Chapter9/general_em.html?q=" target="_blank" rel="noopener">PRML EM</a></p>
<h1 id="EM-amp-K-means"><a href="#EM-amp-K-means" class="headerlink" title="EM &amp; K-means"></a>EM &amp; K-means</h1><p>K-means的损失函数可以写成：<br>$$J(C,\mu) = \sum_i || x_i - \mu_C||^2$$<br>其中，C是类分配，$\mu$是类重心。因此可以将K-means视为坐标上升或者EM算法。</p>
<h1 id="高斯混合模型"><a href="#高斯混合模型" class="headerlink" title="高斯混合模型"></a>高斯混合模型</h1><p>[TBC]</p>
<h1 id="references"><a href="#references" class="headerlink" title="references"></a>references</h1><p><a href="http://blog.csdn.net/zouxy09/article/details/8537620" target="_blank" rel="noopener">从最大似然到EM算法浅解</a></p>
<p><a href="http://www.cnblogs.com/jerrylead/archive/2011/04/06/2006936.html" target="_blank" rel="noopener">The EM Algorithm</a></p>
<p>李航《统计学习方法》</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/machine learning/optimization/L1,L2正则化/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/machine learning/optimization/L1,L2正则化/" class="post-title-link" itemprop="url">L1,L2正则化</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/optimization/" itemprop="url" rel="index"><span itemprop="name">optimization</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script></p>
<h1 id="正则化形式"><a href="#正则化形式" class="headerlink" title="正则化形式"></a>正则化形式</h1><ul>
<li><p>$L_0$范数，指向量中非零元素个数</p>
</li>
<li><p>$L_1$正则化(Lasso regularization)：<br>$$<br>C = C_0 + \lambda\sum | \omega |<br>$$</p>
</li>
<li><p>$L_2$ 正则化（Ridge）：<br>$$<br>C = C_0 + \lambda\sum\omega^2<br>$$</p>
</li>
</ul>
<h1 id="L0-L1正则化"><a href="#L0-L1正则化" class="headerlink" title="L0/L1正则化"></a>L0/L1正则化</h1><p>都可以实现参数稀疏。但L0优化求解是NP难问题，而L1是L0的最优凸近似，比L0有更好的优化求解特性。<br>参数稀疏的好处：</p>
<ol>
<li><p>可以进行特征选择<br>自动完成特征选择，把没有信息的特征权重变为0。</p>
</li>
<li><p>可解释性<br>由特征稀疏（部分权重为0）可以带来更好的解释性。</p>
</li>
</ol>
<h1 id="L2正则化"><a href="#L2正则化" class="headerlink" title="L2正则化"></a>L2正则化</h1><ol>
<li><p>倾向于让特征参数接近0而非直接变为0,这会鼓励分类器将所有维度上的特征都用起来，而不是强烈依赖其中少数几个维度。从而可以防止过拟合，提升模型范化能力。</p>
</li>
<li><p>可以帮助逃离局部最优？加上L2后损失函数会更加平滑和强凸，从而抚平局部波谷？</p>
</li>
<li><p>加速迭代优化<br><img src="http://i1.piimg.com/567571/0035ef86693cdba9.png" alt><br>不加L2时，损失函数可能形如右图。因此，当参数离最优值还有很大距离时，由于梯度过小，而迭代学习缓慢。加入L2后，呈现强凸，可以快速迭代到最低点。</p>
</li>
</ol>
<h1 id="L1-L2正则化"><a href="#L1-L2正则化" class="headerlink" title="L1/L2正则化"></a>L1/L2正则化</h1><ol>
<li><p>下降速度？<br>L1比L2更快？</p>
</li>
<li><p>模型空间限制<br>代价函数可以改写成如下形式：<br>$$ L_1: \quad min_\omega C_0 \quad s.t.\quad |\omega|_1 \leq C$$<br>$$ L_2: \quad min_\omega C_0 \quad s.t.\quad |\omega|_2 \leq C$$<br><img src="http://i1.piimg.com/567571/54a116a4e57acf8b.png" alt><br>绘制登高线图后，可以看到L1倾向于权重为0,L2倾向于小权重</p>
</li>
</ol>
<h1 id="数学解释"><a href="#数学解释" class="headerlink" title="数学解释"></a>数学解释</h1><p>设：<br>$$f(x) = \delta(x;\omega) + \epsilon$$<br>其中$\epsilon$为误差。</p>
<ol>
<li><p>假设$\epsilon_i \thicksim \mathcal{N}(0,\sigma^2)$，则利用极大似然法可以推出最小二乘。</p>
</li>
<li><p>假设$\epsilon_i \thicksim \mathcal{N}(0,\sigma^2)$，$\omega_i \thicksim \mathcal{N}(0,\tau^2)$,各参数相互独立，则利用最大后验估计可以推出Ridge回归。</p>
</li>
<li><p>假设$\epsilon_i \thicksim \mathcal{N}(0,\sigma^2)$，$\omega_i \thicksim \mathcal{Laplace}(0,b)$,各参数相互独立，则利用最大后验估计可以推出Lasso回归。</p>
</li>
</ol>
<p><a href="https://www.zhihu.com/question/20447622" target="_blank" rel="noopener">推导过程</a> 给出了具体推倒，其中线性回归模型假设可以弱化。<br>需要注意先验分布是各参数联合分布。当误差不服从高斯分布时，就无法推出均方误差代价。</p>
<h1 id="权重结构角度"><a href="#权重结构角度" class="headerlink" title="权重结构角度"></a>权重结构角度</h1><p>以上分析强调控制有效参数数目从而抑制过拟合，这部分则从权重结构的角度来进行分析。资料源自<a href="https://zhuanlan.zhihu.com/p/20945670?refer=intelligentunit" target="_blank" rel="noopener">CS231n课程笔记翻译：线性分类笔记（中</a>。</p>
<p>考虑多类支持向量机损失：<br>\begin{split}L_i = \sum_{j \neq y_i} \max (0,\omega_j^T x_i - w_{y_i}^T x_i + \Delta) \end{split}</p>
<p>对于该损失函数，将会有很多的权重集可以正确分类数据。最简单的例子就是对于一个满足的权重集进行同比放大。因此，在这种情况下，施加正则项，可以控制权重结构，对某些特定权重添加一些偏好，对其他的则不添加，以此消除模糊性，使得模型更有效。</p>
<h1 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h1><p><a href="http://blog.csdn.net/zouxy09/article/details/24971995" target="_blank" rel="noopener">机器学习中的范数规则化之（一）L0、L1与L2范数</a><br><a href="https://www.zhihu.com/question/20447622" target="_blank" rel="noopener">bayes先验角度理解L1、L2</a><br><a href="https://zhuanlan.zhihu.com/p/20945670?refer=intelligentunit" target="_blank" rel="noopener">CS231n课程笔记翻译：线性分类笔记（中</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/machine learning/optimization/search algorithm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/machine learning/optimization/search algorithm/" class="post-title-link" itemprop="url">search algorithm</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/optimization/" itemprop="url" rel="index"><span itemprop="name">optimization</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

<h1 id="广度优先搜索"><a href="#广度优先搜索" class="headerlink" title="广度优先搜索"></a>广度优先搜索</h1><p>简言之，就是从起点开始，逐层往下全面搜索关联节点直到发现终点。</p>
<p><a href="http://blog.csdn.net/raphealguo/article/details/7523411" target="_blank" rel="noopener">广度/宽度优先搜索(BFS)</a></p>
<h1 id="深度优先搜索"><a href="#深度优先搜索" class="headerlink" title="深度优先搜索"></a>深度优先搜索</h1><p>从顶点出发选择其分支中的一个进行访问，直到达到分支终点。然后往上递推，遍历所有分支。</p>
<p><a href="https://www.cnblogs.com/skywang12345/p/3711483.html" target="_blank" rel="noopener"><a href="http://www.cnblogs.com/skywang12345/p/3711483.html" target="_blank" rel="noopener">图的遍历之 深度优先搜索和广度优先搜索</a></a></p>
<h1 id="beam-search"><a href="#beam-search" class="headerlink" title="beam search"></a>beam search</h1><p>利用启发函数从下层所有可能的搜索节点中选出最优的n个，n为beam width，由此来控制内存。启发函数可以根据实际情境来定义。</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/7/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><span class="page-number current">8</span><a class="page-number" href="/page/9/">9</a><span class="space">&hellip;</span><a class="page-number" href="/page/18/">18</a><a class="extend next" rel="next" href="/page/9/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">muzhen</p>
              <div class="site-description motion-element" itemprop="description"></div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">358</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">38</span>
                    <span class="site-state-item-name">categories</span>
                  
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">113</span>
                    <span class="site-state-item-name">tags</span>
                  
                </div>
              
            </nav>
          

          

          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">muzhen</span>

  

  
</div>


  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.0.1</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=7.0.1"></script>

  <script src="/js/src/motion.js?v=7.0.1"></script>



  
  


  <script src="/js/src/schemes/muse.js?v=7.0.1"></script>



  

  


  <script src="/js/src/next-boot.js?v=7.0.1"></script>


  
  



  




  

  

  
  

  
  
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  


  

  

  

  

  

  

  

  

  

  

</body>
</html>
