<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">


























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.0.1">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.0.1">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.0.1">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.0.1">


  <link rel="mask-icon" href="/images/logo.svg?v=7.0.1" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '7.0.1',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false,"dimmer":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta property="og:type" content="website">
<meta property="og:title" content="the Home of MuZhen">
<meta property="og:url" content="http://www.muzhen.tk/page/19/index.html">
<meta property="og:site_name" content="the Home of MuZhen">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="the Home of MuZhen">






  <link rel="canonical" href="http://www.muzhen.tk/page/19/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>the Home of MuZhen</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">the Home of MuZhen</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/pansee/essay/关于历史、事实、宗教/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/pansee/essay/关于历史、事实、宗教/" class="post-title-link" itemprop="url">关于历史、事实、宗教</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/essay/" itemprop="url" rel="index"><span itemprop="name">essay</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>关于历史、事实、宗教</p>
<p>今次读书会所谈到的《贵妃的红汗》《天工开物·栩栩如真》都涉及历史。如何看待过往的历史呢？特别是中国有长期的循环历史特点。关于历史部分我将在历史类书评中详讨，这里就不再赘述。更贴近现实的，这里涉及如何看待自身过往经历、错误的问题。也就可以谈谈施舍的问题。这一部分内容将放在下文论宗教部分。</p>
<p>同时，会上引出了对HISTORY（第一历史）、History（第二历史）的讨论。其实，HISTORY和History的关系有些类似于柏拉图理型世界和现实世界的关系，更进一步的，这里存在一个认识论和本体论上的问题。不妨回顾一下休谟的怀疑主义。同时，它存在一个经由人的过滤而带来的主观性和纯然客观性的分野问题。我在这里直接引用我在《科学发现的逻辑》书评中所谈到的内容：</p>
<p>在马克思主义哲学中，本体论问题在于物质与意识何者为第一性的问题，并据此区分唯物主义与唯心主义。窃以为，本体论问题的解答无法离开人的认识过程。自大陆理性主义与英国经验主义的争论以来，休谟以怀疑主义的视角进行了逻辑归纳法的批判，并表明了本体的不可知性。止于此，绝对化的谈论唯物和唯心已经没有太大的价值，毕竟任何的唯物客观终归要经由人这一过程，这也就势必无法确定性的剔除主观性。这也造成了对形而上学的价值的怀疑，及其与经验科学的差别分野。（《科学发现的逻辑》书评）</p>
<p>这里牵涉到逻辑归纳法的批判和理性的局限性问题。这里引用我在其他书评中所谈到的内容：</p>
<p>开篇进行了归纳法批判，首先是单称陈述推导出全称陈述的不合理性，其次是妄图将归纳法建基于经验之上势必导致无穷后退，并表明了归纳法无法保证理论的正确性。止于此，经验科学的可证实性特征遭到挑战。我们可以很轻松的列出一个反例来否决理论，却无法通过罗列与归纳来证实理论。当然，此处的理论是一个关乎普遍概念的理论，若是局限于某一可数范围，自然可以穷尽之证明之，此类缺乏普遍性，也不被称之为理论。以此表明了以归纳方法作为经验科学的特征所存在的问题。（《科学发现的逻辑》书评）</p>
<p>最后，是关于真理的问题。理性不等于真理！人的理性是有其局限性的。休谟与波普尔对于归纳法的批判已经说明了这个问题。过分的强调理性而忽略非理性过程或者把非理性过程置于次要地位都是没有依凭的，正如福柯在《疯癫与文明》中对于理性的批判。而灵性修养则是非理性过程中一个重要部分，这也正是希伯来精神与中国部分传统文化所重视的方面。至于绝对真理，或者用一个不至于引起误解的说法，绝对准则是否存在，这又牵涉到后现代性的解构主义的问题。容后详述。（《书中之书讲演录》书评）</p>
<p>这里又牵涉到绝对与相对，虚无与解构的问题。不妨先谈一下人性和道德问题，以便提供一个新的视角给那些过于相信“光明意识”者。直接引用如下：</p>
<p>一直视求诸于神的“外在超越”实在是一种怯懦与缺乏勇气的行为，而更崇尚“两刃相交”的直面与魄力。故而初识尼采被被其所论酒神精神所折服。在人生的永恒悲剧长流之上用轻盈的足舞蹈。这是直视生死离合的大勇气，是不屈的精神抗争与追求。中国传统文化所谓“小人求诸人，君子求诸己”也是如此。</p>
<p>但是，在牵涉到终极价值的问题上，这样的思想是否能够给出一个满意的解答呢？我一直以来拒绝承认自己是一个虚无主义者，尽管我的很多想法带有虚无主义的特质。我经常用禅宗“真空妙有”来谈空与虚无的区别。甚至于曾经几度以为自己已然深明禅意，只是随之而来的现实却让我发现空口谈玄甚是容易，实践行动甚是困难。故而有所谓“悟道前砍柴挑水,悟道后砍柴挑水”，如何在悟道之后把握住何者当为何者不当为，将解构之后的分崩离析重新合成一个坚实的根底与方向呢？</p>
<p>“空”也好，“自然”也好，都容易陷入绝对主观主义的圈子里。到了最后，也就是无可无不可的绝对自由状态。当然，不是说这样的观念就不对了，恰恰相反，我以为这样的“空”是能够解释终极问题的一个可接受答案。关于这点，先悬置不表，且先论“光明意识”与“泛道德化”。</p>
<p>“‘光明意识’是一种深刻觉悟到的‘道德意识’，这种主张认为哪怕再顽劣的本性，仍然可以用道德努力去完成自我圣化的这一过程。”（书33页）对于这一观念，齐老师提到，“‘内向超越’论和‘泛道德化’的最大问题还不在此，而是出在其人性预设上，对人性过于乐观的预设使‘内向超越’和‘泛道德化’论者过于忽略了人性的幽暗面”（书33页），“在批评人家‘外在超越’过于悲观之前，我们先要反思自己‘内在超越’是否过于乐观了”（书35页），“万一陷入‘真诚的自欺’并‘自欺’到自以为‘真诚’怎么办”（书35页）。</p>
<p>这里提到一个人性问题，《第四讲 人性善，还是人性恶》也专门谈到了这一问题。除了“光明意识”外，还有“幽暗意识”，“所谓幽暗意识是发自对人性中与生俱来的阴暗面和人类社会中根深蒂固的黑暗势力的正视和警惕”。（书34页，张灏《幽暗意识与民主传统》）对于人性问题，这里不再赘述。仅仅指明，我喜欢如此评价李安导演《少年派的奇幻漂流》：In me the tiger sniffs the rose.（<in me,past,present,future meet>by Siegfried Sasson）</in></p>
<p>相较之人性问题，我更关注的是道德问题，确切的说，何以证明道德本身是合乎道德的？除了宗教视角之外，可能更多的是从人与人的关系，从伦理、社会视角来界定道德。那么，最终也就要回归到人的社会属性上去。但是，至少我很难接受简单的用人的社会属性去解答人从何而来、人的价值与意义的终极问题，而对更古远的历史，宇宙的生成等问题弃置不表或排除出“人的问题”之外。其次，通过人来解释人，各种准则也就不可避免的带来了人的主观性与随意性，甚至于认为“此亦一是非，彼亦一是非”。“于是，‘内向超越’论的‘内向’就有吞噬掉‘超越’的危险。”（书35页）更极端的作法便是消解“人”的概念，消解意义与价值，视这世界为偶发的随机的，本无什么价值与意义可言，也就无可无不可，这样一来人即可以选择强力意志也可以选择谦逊道德，不过是凭着个人的意愿而已，也就近于尼采的“人神”精神。故而，在我看来，这是可以解决人的归属的一种可能。（《书中之书讲演录》书评）</p>
<p>我是这样理解相对这个观念的。相对主义有两层水平。一种是视外物为相对的，这里其实存在一个人的劣根性，就是看待外在事物的时候非常超然，可以自如的说这个东西可能存在可能不存在，这件事可以做可以不做，视立场不同而定。</p>
<p>还有一种则是把相对主义印到内心之中。这件事从这个角度该做那个角度不该做，我到底是做还是不做呢？如此一来，也就陷入了一种无立场徘徊彳亍状态。诸位，你们不妨自问一下，你们真的是相对主义么？你们在行为做事的时候难道不是依凭着一个显而易见的绝对准则么？你们真的是处于流浪无根的状态中么？</p>
<p>需要说明的是，这样的流浪状态和佛的境界是不同的。佛是窥视了这样的相对本质，又从其中走出来，也就是出世然后入世。我由于长期陷入这样一种流浪状态中，在佛学之中虽是明白些许，但又无法落实到生活实践中去，故而开始接触基督教。当然，这绝不是为了逃避，如果那是一种该然的状态，我愿意欣然领受。那么，是什么原因令我选择了基督教而放弃了那样一种流浪状态呢？这里引用如下：</p>
<p>“人其实都知道有神，即使他没有神他也一定要制造神来崇拜，他是不可能忍受真正无神的生活。”（书81页）</p>
<p>前文已经谈到了虚无主义问题。对一个非虚无主义者，活着就必须要遵循一定的准则与价值。而此准则若是由人本身来制定，就缺失了绝对权威。故而，必须有一个外在的神来定下一个道德律。一个无神的生活，一个缺乏准则的生活，人将在其中迷失，流浪。</p>
<p>对于虚无主义者，当你们在陈述世界及人的存在的无价值无目的时何不反问一句，虚无何以证明其自身的虚无呢？也就是一个无穷后退的逻辑。当然，最终可以归结为一个虚无的虚无，也就是不可再论的恒常的空，但这空本身也是一个绝对准则，而非是一般的所谓虚无。</p>
<p>至于何以选择上帝而不选择空，这已经不是理性所能论述的。不妨回到事实上来，事实告诉世人有过那么一个死而复活的耶稣基督，有过一个行诸般神迹的耶稣基督，有过这么一个非人力所能及的耶稣基督，既然有这样明朗的事实，何以不去选择信仰上帝呢？</p>
<p>或许有人会反问，难道释迦摩尼不是真实存在的么，佛不是真实存在的一种境界么？是的，在我一开始的思考中，存在这样一个误区，无意之中将神的地位拔高了，故而才能在上帝和佛之间选择出上帝。承认耶稣的死而复活不过是确证了对上帝的信仰是对人终极问题的一个合理解答罢了。那么佛和上帝的地位是同等的么？不妨进行一下上帝和佛的对比：</p>
<p>基督教通过耶稣复活确立上帝的合理性，而耶稣复活则是在一定预设下可以接受证实和证伪的；释迦摩尼是否达到那样的境界既不可知（在他人眼中的达到与否根本不具有意义，唯其自身知道）也无知的必要，佛的境界是否能够达到必须归结到自身的体认。</p>
<p>对上帝的信仰可以立时达到，具有简单性（排除美学的和实用的，波普尔证伪主义意义上的）的特点；佛的境界耗时耗力，甚至于苦参一生而只余苦。</p>
<p>可以看出，信仰上帝类似于一条合理的捷径，而修佛则是前途难测的攀登。上帝所包含的信息与真实较之佛的境界更大，更确实。但对于一个负隅顽抗者而言，这样的量的区别怕是还不足以让其承认上帝的独一性。我想，问题的关键根本不在于在上帝和佛之间做出选择，因为不管选择哪个都已经承认了两者具有同等的地位，至少是抹杀了上帝的威权。问题的核心在于，必须证明上帝是高于佛的，上帝是独一的，根本不该存在选择问题。否则那样一个上帝也不过是人自造的上帝罢了。</p>
<p>上帝和佛是矛盾的么？还是说，佛只是上帝智慧的一个映射？如果上帝包容佛，那么上帝就是独一的了，也是我该信的了！这样的对比有教内言教的嫌疑，怕是没有太大意义。</p>
<p>没有死而复活的耶稣的上帝和佛已然是对等的了，加入了耶稣死而复活这一筹码的上帝确实更具有诱惑力。但是，上帝代表的是目的性，佛代表的是无目的性，人在考虑的时候存在肯定力量与否定力量的不对等，但是原初的事实到底如何呢？这实在无法用人的视角去解读。当我带着迫切的寻求归属的目的去查考上帝时，势必带有自身的偏见，从而无法见到真实的上帝。</p>
<p>还是回到事实吧！一个混沌原初的人，一个不带主观偏见的人，当他看到了一系列悖逆规则的事，当他看到了一个死而复活的耶稣基督，但仅仅是一个叫做耶稣的人死而复活还不够，必须是一个作为传道者和规则建立者的耶稣基督的死而复活，如此来，他有什么理由不相信基督是真实存在的规则的创造者呢？！！！而佛从头到尾也仅仅是揭露规则罢了。</p>
<p>为什么一定需要一个规则的创造者呢？为什么一定要有规则呢？当然不必须有，但又为什么不能有呢？问题的核心不在于规则，应该做的是“回归事实”。</p>
<p>或许又要质疑了，何以见得事实便是真的事实（这一事实是本质意义上的，不是事件发生意义上的）呢？肉眼所见都可能不过是虚假的表象而已。依旧是那样的思路，是不是本质的事实并不重要，因为事实可能是虚假，也可能是真实。因此只需要“回归事实”（这里的事实既非本质意义上的也非事件发生意义上的）就好了！</p>
<p>但必然又有人要质疑了，那样的“回归事实”有多大的可靠性呢？我自己在这个问题上都未必能坚定的如此解释：这样的“回归事实”就好像佛家所谓真空妙有的空的境界一样，是只可意会不可言传的。但至少我目前是如此理解我所谓的“回归事实”的。</p>
<p>另外，我以为，信仰可以和怀疑并行，在虔诚信仰的同时也可保有理性。如此一来，当有证据证明上帝是个骗局，也就可以清醒地脱身，方不为盲信。（《书中之书讲演录》书评）</p>
<p>上面谈到回归事实时做了三种区分，一种是本质意义上的即柏拉图理型概念，一种是事件发生意义上的即HISTORY概念，一种是回归事实的事实，只可意会不可言传大有圣灵与我同证的意思。</p>
<p>前文《书中之书讲演录》书评的节段也回答了如下两个问题：</p>
<p>其一，“人神”精神（近于尼采的而非中国传统的）与“神人”精神之间的选择问题。</p>
<p>其二，世界上不仅有基督教，还有伊斯兰教，犹太教，诸多中小宗教，那么在这些“神”之间应该选择哪一个呢？纵然把各个宗教研究透彻，也不过是证明各宗教之间哪个更合理而已。如果再突然的通过考古挖掘发现更为古老的宗教与神祇又当如何？若是如此，岂非从生至死都在无归属的研究之中？更何况，不可能要求每个信众都是伟大的神学家，对神的领悟也不与理性直接相关。（《书中之书讲演录》书评）</p>
<p>最后，我再谈一下舍己的问题。其实，这个问题和博爱的问题又有关联。具体内容我也就将放在弗洛姆《爱的艺术》书评中去论，此处不再赘述。</p>
<p>今次的通讯有些偷懒，尚望诸君多多担待。关于我以上书评节录有兴趣看完整版的直接去我QQ空间就好。</p>
<p>2013年12月16日星期一    文/鷇音</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/pansee/film review/南京，南京——观《南京，南京》有感/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/pansee/film review/南京，南京——观《南京，南京》有感/" class="post-title-link" itemprop="url">南京，南京——观《南京，南京》有感</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/film-review/" itemprop="url" rel="index"><span itemprop="name">film review</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>南京，南京</p>
<p>——观《南京，南京》有感</p>
<p>在灰暗的氛围下看灰暗的《南京，南京》，看出灰暗的思绪与灰暗的心情。</p>
<p>从头至尾，我似乎只从影片中看出了灰暗。</p>
<p>没有当时的世界背景，没有当时日本侵华的背景，也没有当时中国的时代与社会背景。</p>
<p>没有日军进行南京大屠杀的完整而具体的描画，没有屠杀前后南京的实际情况，也没有屠杀之后日本的反应。</p>
<p>一段斩头去尾的历史不叫历史，一段连过程都不清晰的史实不叫史实。</p>
<p>如果说《南京，南京》的看点在于以角川——一个参加了南京大屠杀的日本军人为视角进行描画的话，我也认为这是此片的最失败之处。</p>
<p>主人公角川，给我的印象是一个迫于形势，却又在心中埋藏着爱与仁慈的被士兵者。</p>
<p>看着血流成河，尸骨成山，角川在良心的谴责中崩溃，为了逃避这样的残酷现实，为了将自己双手上的血渍洗去，他选择了用生命换取救赎。</p>
<p>我却不禁要发问，是什么使得角川被士兵，是什么使得角川被染血，是什么使得这样一个残酷的现实被出现？</p>
<p>用一个日本军人作主体，明明是最便于分析当时日本的社会情况，明明是最便于透视当时一个日本军人的心理状态和精神信仰，明明是最便于展露当时进行南京大屠杀的日本军人的内心活动和屠杀原因，导演却对这些视而不见，或者说将这些要素埋藏得好深好深，使之被置于迷雾下的灰暗里。</p>
<p>看完影片，我认为导演是考虑到这些的，可却有意将这些次要化，而突出一个日本军人的良心救赎，这又是为什么？</p>
<p>为了迎合观众，迎合主流，为了迎合利益！</p>
<p>既然是为了利益，那我也就不难理解日本为何侵华了。</p>
<p>在日本东京，以荀子“游必就士”命名的战争博物馆——游就馆里的十一个展室里，炫耀着日本明治之后在他国土地上的辉煌战绩，供奉着各式杀人武器，同时以“资料短缺，生存空间狭隘”为由为一场场侵略战争作解释，东条英机等人的照片高悬墙上。</p>
<p>每个人的生命只有一次，没有人愿意用可贵的生命来体验战争的刺激。当没有等同的利益乃至于更高层的利益时，战争与流血绝不会发生。同样的，没有必要的利益，南京大屠杀也不会悲哀地发生。</p>
<p>惨剧的发生，源于人类对利益的趋之若鹜。滚滚长江东逝水，鲜血可以被稀释乃至于分解，尸骨可以被腐蚀乃至于归于黄土，时间的长河中，利益却是可以永恒存在的。</p>
<p>我可以清晰的记得，蒙古的铁骑开拓下了一片又一片的沃土，却难以想起中亚的寸草不生，近两亿人的头颅被悬挂在马脖子上。我可以清晰的记得，太平天国的奋起反抗，立志创出一片新天地，却难以想起其所过之城，人民的惨象。我可以清晰的记得，一代名儒曾国藩的种种丰功伟绩，却难以想起南京城五十万市民遭屠的史实。</p>
<p>一幕又一幕的惨剧，一次又一次的反思，换来的不过是一起又一起的悲哀。这样的反思，到底反思出了什么呢？</p>
<p>靖国神社，依旧伫立。相当一部分日本人乃至于首相，都在参拜靖国神社。如果我是日本人，我同样会去参拜靖国神社。</p>
<p>甲级战犯？胜者王侯败者寇，历史同样要被权力和利益左右。成吉思汗，不是杀人魔王，而是一代天骄。难道说东条英机与成吉思汗有什么不同？他们同样在侵略，他们同样在屠杀，他们同样在追求利益。</p>
<p>今天的世界，我们倡导和平，那是因为可以用战争以外的方式追求所需的利益。不管是个人与个人之间，团体与团体之间，还是国家与国家之间，明争暗斗何曾止歇，利益之争何曾消停？相同的目的，不同的方法与过程，就能够避免惨剧的发生？</p>
<p>既然利益是人类永恒的主题，那么将自己置身于利益圈之外，从所谓人性的角度去批判这些所谓战犯，去批判这些追求利益的失败者，岂不是彻头彻尾的伪善？！</p>
<p>遑论这些“战犯”还是在为国家利益，为了心中的信仰在拼搏。所以对于一个日本国民来说，这些“战犯”乃是在为国家做贡献，乃是在健全自己的个体人生意义，就应当是英雄与神灵，就应当值得参拜！</p>
<p>那么我们能做些什么呢？还是白自己练的铁石心肠，冷血无情，从而方便自己去追求利益？</p>
<p>勃兰特在最寒冷的日子里向死于德国纳粹之手的犹太人下跪，普金在卡廷为当年的遭难者下跪，可是这样的行为能挽回什么？如果说跪完之后继续去不加节制的追求利益，那他们也不过是披着羊皮的狼罢了！</p>
<p>君子爱财，取之有道。纵然人有原罪，也同样可以杜绝本罪的发生。人之为人，在于神性与兽性的兼有并融合性。君子与小人的区别，不在于一个趋于义，一个趋于利，而在于君子是神性的趋于利，小人是兽性的趋于利。</p>
<p>和谐社会，所谓和谐，不在于存天理，灭人欲，不在于摒弃兽性，只留神性，而在于神性与兽性的制衡，善与恶的平均。</p>
<p>诚如海德格尔所言：善时恶的善。在时间的长河里，还有一样东西是永恒存在的，那便是对于利益的理性批判。</p>
<p>东条英机之所以会惹来千古骂名，首先在于它是一个失败者，本源在于他的所作所为僭越了一个人类共同的尺度。</p>
<p>其实人是残忍而自私的。我们在餐桌上大鱼大肉，同时大声怒骂着那些吃食死婴的“禽兽”。不管是哪一种族，永远都不会对其他种族施以仁慈，而所谓的怜悯亦不过是鳄鱼的眼泪。而人类今日的残忍与自私在于可以为了自己的利益而去枉顾他人的生命，竟是连同类亦可相残，无怪乎梁启超要感叹：但闻虎吃人，不闻虎吃虎。而平静社会下的相残要比动荡与战火中的更让人痛心。</p>
<p>当火焰熊熊的燃烧，一个美丽的女人如斯凋零，当事者却是满口的国家利益至上，只去感到惋惜，而不曾有一丝悔恨。这不得不说是一个情盲，乃至于一群情盲的悲剧。（《城管局长钟昌林如是说：唐福珍自焚是一个法盲的悲剧》。《南方周末》第一千三百六十四期）</p>
<p>人非草木，孰能无情。人与动物的区别便是在于情之有无。正是因为有情，人方能为五行之秀，实天地之心。不敢想象，如果一个的心中只充盈着利益，丧失了人的本性后，又该是什么？魔，实为人魔！</p>
<p>当我们每日吃食着地沟油的饭菜，提心吊胆着血铅是否超标，青嫩的蔬菜又要担心有毒，于是在这毒素蔓延中，人被失去了一颗鲜活的红心，失去了对天地，对自然，对生命的敬畏。</p>
<p>回顾汶川大地震与玉树地震的不同，它们的区别绝不仅仅在于死亡人数与震级上的差异，一个是血泪布撒，一个是平和而略带忧伤。原来死亡从不曾是终结，不过是另一个开始。不是在生者长戚戚，反过去担心死者将会幸福么。有了信仰，不死的灵魂得以成为实在。</p>
<p>也正因此，如果我是一个日本人，我会去参拜靖国神社，仅仅是去表示一种缅怀，一种敬意，对他们为了信仰而能付出一切的敬意。</p>
<p>可惜的是，恶魔的信仰会让他们也成为恶魔。军国主义绝不应当再起，尽管知道，这仅仅是一种奢望。只希望，能让心中有些许敬畏，不至让曾经的惨剧再度发生。</p>
<p>可谈天不如人意。躲猫猫死，撞墙死，喝水死，死的人数少了。死的悲惨却是更增。无意去指责些什么，知道每个人都是在摸着石头过河，每个国家也是在摸着石头过河。只希望，官员们能够去敬畏权力，唯有如此，在使用权力时方会如履薄冰。</p>
<p>从来都认为，读历史是为了更好地去生活于现实。与其再去纠缠于曾经的悲哀与纠葛，倒不如去做些实在而有意义的小事。而所谓反思，也只在具体而微的事中方能体现，一如丰田召回门。</p>
<p>仅仅呓语，随行为之。</p>
<p>2010年5月10日星期一上午 多云</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/pansee/film review/告白/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/pansee/film review/告白/" class="post-title-link" itemprop="url">告白</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/film-review/" itemprop="url" rel="index"><span itemprop="name">film review</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>告白</p>
<p>2012年1月5日星期四——2012年1月7日星期六</p>
<p>应该讲，这部电影有其成功的一方面，只是个人认为它的部分成功是建立在它的最终失败之上的。</p>
<p>告白——森田悠子</p>
<p>开场便是老师森田悠子的告白。和艾滋病人樱宫正义结合，为了孩子不受异样的眼光而独自抚养女儿爱美的悠子，不可避免的将主要的精力放在孩子身上，而忽略了作为班导对班上一群13岁学生应有的爱和付出。因为有女学生陷害男老师的事件发生，悠子对于进入派出所的班上男生也只是摆脱其他男老师去接，实在是伤透了孩子们的心。</p>
<p>如何在工作和家庭之中求得平衡，尤其是在这两方面产生矛盾的时候？不妨将这个问题放大一点，如何在个人与社会之间求得平衡，尤其是在个人价值与社会价值产生矛盾的时候？儒教（不是儒家！）喜欢讲，先天下之忧而忧，后天下之乐而乐。但是也正因为儒教的礼，让得人们反感，它不仅仅是一套等级森严的礼法制度，它更在压力个人价值的实现，或者说是对个人价值的漠视！其实，时至如今，中国人依旧没有摆脱这样的思想。为了国，为了社会，个人是可以牺牲的，个人是应该牺牲的，个人是自愿牺牲的。只是这样一来，个人到底是社会的个人还是个人的个人，社会到底是社会的社会，还是个人的社会？</p>
<p>另一方面，儒家讲忠恕之道。推己及人曰忠，己所不欲勿施于人曰恕。如果学生能多为老师想想，老师也能多体谅学生，又何至于发生那样的惨剧。只是，必须注意的是，一群不满14岁的学生们，是难以有如此的思想与宽容的，那么森田悠子的过错就是显而易见的了。其实，通过班长北原美月的一句告白，“悠子老师走后，班上洋溢着开朗的笑容”，便可以预见到悠子在这部电影中所扮演的角色了。</p>
<p>便是在老师与学生的矛盾中，修哉和小直杀害了爱美。紧接着的，便是悠子一连串的报复？</p>
<p>因为未满14岁，根据少年法，修哉和小直并不会受到伤害，正如用化学药剂毒杀全家人的露娜希一样，最终将逍遥法外。也正因此，悠子在两人的牛奶中加入了樱田的鲜血，并言称生命的珍贵，要两人用以后的日子来慢慢体悟与理解。</p>
<p>不妨谈谈艾滋病。时下的中国，对于艾滋病这一话题也有了更多的关注。就是昨天，还看到一则电视广告，是通过两个艾滋病小孩来呼吁给予艾滋病人以关怀。让我不解的是，艾滋病人是畸形的么？为什么广告中那两个小孩要笑的那样畸形，希望以此来博取正常人的同情心？难道这样的广告，不是对艾滋病人的侮辱？需知道，艾滋病人与正常人的生活并没有多大差别。正常人也并不比艾滋病人高贵。艾滋病人需要的不是正常人的怜悯，而是尊重和认同。脱下虚伪的外衣吧，口口声声喊着关怀艾滋病人，心底里不过是充满了自身的优越感以及对于艾滋病人的鄙夷罢了！</p>
<p>对待一个人，最可贵的是尊重，而不是同情，因为只有这样，才能让他人有尊严的活着。对待一个人，最可贵的是宽容，而不是理解，没有人可以理解世界上的所有人事物，说理解只能表明个人的虚伪，只有去宽容，去将他视为和自身一样高贵的抑或低贱的生命，才是一种真正诚挚的感情。</p>
<p>告白——下村直树</p>
<p>下村直树，运动和学习都显得乏力的小男孩。上进心？从他积极的参加锻炼和补习班来判断，应该是有上进心的。只是，既然如此，又为什么放学后要去游戏厅打游戏呢？孩子总是贪玩的。或许只是一个很好的解释，可以说明直树的上进心是真实的。</p>
<p>不妨先来谈谈“玩”。什么才能叫做游戏呢？给人快乐的应该就是游戏吧？如果这样定义，杀人对于杀人狂而言是不是游戏呢？相信除了杀人狂自己及其同类人，一般人是绝不会认同杀人乃是一种游戏的。如此一来，游戏首先应该是一种社会性的东西了。不在这个问题上纠结，毕竟只是一个看事情的立场问题罢了。我们发现，随着年龄的增加，从统计的角度来说，玩游戏的时间是越来越少了，玩的游戏更加倾向于高级智力、体力或者是博弈类，而很少再去玩魂斗罗，拳皇之类的相对而言显得小白的游戏。虽然有成年人反过来去追捧这样的游戏，但那也只是对于童年的追忆而已，他们该是不可能从点点鼠标，看看动画之中来获得真正的满足吧？故而，我们是不是能够从游戏的角度去为一个人的心理年龄的断定提供信息呢？</p>
<p>另一方面，角色扮演类和竞技类游戏占有很大的份额。那么，沉迷于其中的人会不会乃是在现实生活中显得失意或者达不到他所期望的高度，转而在这样的游戏中获得胜利与成功的快感呢？再者，沉迷于游戏是不是对于现实的一种逃避呢？还有一个可能，就是游戏可以提供给我们在现实生活中所不能有的经历，譬如暴力和杀戮。人是有潜藏的杀戮欲望的，通过游戏便可以得到释放。正如通过A片和类似游戏，人的情欲可以得到释放。</p>
<p>下村直树在明知爱美没有死的情况下依旧将她抛进游泳池，导致溺毙。被修哉所看不起的直树这样做，便是为了证明自己的所谓价值。是的，作为主谋的修哉没有成功杀掉爱美，作为从谋的直树却是成功了，这对于修哉该是一种打击与讽刺，同时是对自己能力的证明。</p>
<p>仅仅因为悠子没有去警察局接他便令他有了这么大的恨意么？仅仅因为修哉是唯一一个请他看电影，拿他当朋友的人，就可以为之死心塌地么？仅仅因为修哉的虚情假意与冷然漠视，便让他有了行凶杀人的勇气么？</p>
<p>直树有一个过分宠溺他的母亲，这让他无法受气。而另一方面，天子骄子一样的家庭生活和他在学校不被重视的剧烈反差势必导致了他对于学校对于老师的愤恨。需要注意的是，直树的家庭只有他的母亲出现，父亲和姐姐从来不曾出现在镜头，或者可以怀疑一下直树缺乏父爱，那样的话他的心理不健全就更容易解释了。</p>
<p>有一个细节是需要注意的。直树喝下含有艾滋病人血液的牛奶后休学在家。凡是他用过的厕所等都势必要亲自仔细擦拭干净，但它本身却完全不洗澡洗漱，以至于身上肮脏黑暗。如果说自身不清洁是在自暴自弃，那么擦拭使用过的器具是一种防止家人染上艾滋的责任使然么？</p>
<p>此处，确有深究之必要。不妨结合后期用血涂染超市的食物，以及在家吞食带血食物来做个分析。</p>
<p>最后我们还是来看看直树妈妈的行为吧。写下遗书，拿上刀，要先杀死直树，再自杀，结束这段痛苦。这就很有意思了。直树是她的儿子，丈夫不是她的丈夫，女儿不是她的女儿？在得知爱美之死因时她也不曾给过一句抱歉，只是不断强调直树是个可怜的孩子。她的自私也是显而易见的了。对于直树妈妈，其实还是很有可谈之处的，只是本人愚鲁懒惰，就不展开了。</p>
<p>爱，有的时候真的很盲目。对于悠子而言如是，对于直树妈妈而言亦如是。孩子蒙蔽了他们的眼。</p>
<p>告白——樱宫正义、池田寺辉</p>
<p>樱宫正义，爱美的父亲，曾经少年浪荡，后来幡然醒悟，将自己的一生奉献在教育事业上。直到生命的最后一刻，他也要阻止悠子的报复，使得悠子没有成功将血放入修哉和直树的牛奶。其实，即使放入，感染的几率也近乎为零。</p>
<p>由此可见，杯弓蛇影实在是拥有强大的杀伤力。有这样一则案例。某女孩为了减肥，就每天都让自己有厌食症，觉得吃东西恶心，最后肉体换上厌食症，无法吃下任何东西而死亡。很可惜，心理因素可以让肉体真的崩溃，但是却不能让崩溃的肉体复原，至少厌食症是不可逆的。素还真吞吃沙人畏无毒的至毒之药而心中惴惴，天下第一智者尚且如此，常人又能如何呢？</p>
<p>自己的心有的时候反而会欺骗自己。在心理学上有一个实验。两组实验者，一组走过危险的独木桥，一组走过安稳的木板桥，走过独立桥的实验者过半数认为是自己喜欢桥对面的异性。有的时候，我们往往将自己的情感混成一团，一旦发生刺激性事件，便认为全部是由其导致。如果让剪不断，理还乱的情感和感觉能够纹路清晰，那么我们就可以减少意气用事，也不至于做出个别重要的错误决定了吧，尤其在男女感情上。只是这样一来，或许就少了一份意外或是一段好姻缘。</p>
<p>另一方面，不该人言亦言，尤其对待一些令自己感到恐惧的事情，往往第一印象就成为了真理。</p>
<p>如何让心如明镜台一般澄明，照出万物的本来面目呢？如果真的可以看清事物的本来面目，也未必是种智慧吧？</p>
<p>池田寺辉，激情负责的年轻男教师，尽力去当学生们的大哥哥，让同学们影印笔记，制作祝福卡，每周都去送给直树，希望他能重返课堂。作为樱宫正义的狂热崇拜者，不知内情的他受悠子利用，无形中促成了悠子的报复计划。</p>
<p>想到倒扶事件，小悦悦事件，好人免责立法被广泛提出。只是，这样的立法真的适应中国当前的社会状况么。好心并不一定能做成好事，甚至于因为一时好心的盲目救助，可能让一个伤者死亡。当下的中国，教育的普及程度，尤其是紧急救助知识的普及，怕是还没有达到可以让每个好心人都不犯错误的程度吧？同时，这实际上也给恶人创造了机会，不是么？好人免责立法的确立，是好是坏也绝不是简简单单说说就可以的。</p>
<p>看到池田寺辉最后雨中没落的背影，不禁痛心。我们所欲为的，却偏偏走向了相反的方向。人生中有太多的无奈，有太多的遗憾，我们倾尽心力，却只能最后感叹，红酥手，黄腾柳，满园春色宫墙柳。</p>
<p>告白——渡边修哉</p>
<p>天才小博士——渡边修哉。获得全国大奖，本该万众瞩目的他，却因为获奖之日的露娜希事件而被遮掩了光彩。作为物理学者的母亲，从他幼年开始就采用批评打骂的方式对他进行电机学教育，对他寄予了厚望。父母离异后，母亲重回研究所，再也不曾见过他一面。</p>
<p>或许，对于一个全身心迷恋其研究领域的学者而言，让他将心力分给其他方面，哪怕是他自己的孩子，可能也很难。在模糊的记忆中读过这样一篇文章，约翰逊博士回忆年轻时埋头于书本，而忽略了对于老父的关心与爱，言辞中尽显了他的懊悔与遗恨。在知识与感情之间，到底更加更加重要呢？其实，人可以对人有感情，也同样可以将感情投注于知识。我是一个极端主义者，爱一个人，便爱的彻底，同时彻底的忽略其他人，投入一件事，就全身心的投入，而不再关心其他。我不认为人有限的感情和时间可以分给许多事物。如果可以这样，那么又为何不可以三妻四妾，不可以同时爱着两个乃至于更多的女人或男人呢？</p>
<p>修哉虽然是在母亲的打骂声中度过他的童年，但是他内心深处却是爱着他的母亲。不，不应该这样说，应该说他内心深处渴望着母亲的爱。对于一个自小缺少母爱的孩子，当他在他的父亲和继母身边无法赶到关怀，自然会投向他那已经远去的母亲，从中寄予自己的一丝希望和坚持。只是，这样的希望，或者只是在自欺欺人而已。</p>
<p>借北原美月之口，说出了修哉具有恋母情结。佛洛依德所提出的俄狄浦斯情结，便说道每个人对于母亲都有一种依恋与性欲望。只是，对于修哉而言，当真如此么？个人认为，修哉的恋母情结只是假象，不论他做的多好，得到的只是母亲的批评，从他一出生，母亲就宣判了他这一生的失败，因此他千方百计要获得母亲的承认，以此走出心里阴影。</p>
<p>我们常说血浓于水，两个自出生就不曾相见的母子，在二十年后可以抱头痛哭，母子关系较之一般人更加深厚。只是，这样的母子亲情从何而来，只是因为体内的血液与DNA？哈，或者，仅仅因为我们从一开始就被灌输了母子亲情的观念，这样无根之观念早已深深扎根于潜意识之中了吧？原来，所谓感情，不过是如此荒谬的社会造物。又想到心理学上的单纯接触效应。一对男女，仅仅因为每日见面，就可以互生好感，也即是所谓日久深情。这个世界是如此让我恐惧，哪里有什么是非她不可的，哪里有什么是非我不可的，哪里有什么感情是货真价实命中注定的。只是一种机缘巧合，只是一种随机现象，相互串合而成了这个世界。或许在这一片地域之内，我是独一无二的，因为没有人可以取代我。难道是我自己陷入了自己制造的陷阱？</p>
<p>本意是在修哉和美月这里大书特书，只是写到现在，确实是不想再写下去，而所写的也实在不成其为影评了，不过是几日来的日志串烧而已。</p>
<p>告白——北原美月</p>
<p>这样的角色，一直是我所喜欢的。带有几分妖艳，却是不妨碍她的真实与纯美。</p>
<p>自称为是第二个露娜希，唯一一个能够理解修哉的人，被称之为美呆，很贴合的外号。“呆”，什么才叫做呆呢？呆有很多种。有的是不论善恶一味包容的呆，有的是傻头傻脑无忧无虑的呆，有的是胡思乱想迷惘困惑的呆，有的是情根深种不能自拔的呆，有的是自欺欺人求真向觉的呆……有的人呆的痛苦，有的人呆的快乐。其实，每个人都是呆子，浑噩噩的在这苦难世上挣扎。</p>
<p>告白——鬼如来</p>
<p>开头说，这部电影的部分成功是建立在他的最终失败之上的。之所以如此说，虽然他的剧情却是有些出人意料之处，但是它却彻底颠覆了一个老师形象，这样做实在是太过冒险。拿电锯惊魂比较之，电锯的成功之处在于它所预留的一线生机，以及警察、凶犯、有罪者的圈子控制了其不良影响，这样就使得其可以达到警醒之目的。而此片虽然新奇，所营造的阴影个人认为有些过了。</p>
<p>鬼如来之名，取自霹雳布袋戏。曾经仁慈悲悯，救众生苦难的帝如来，为了消灭魔族，残杀亲友，血染犀角，潜伏进入魔族内部。怎料得，灭魔之后反受正道追杀，不得承认，又知这一切都是为凶残的厉族布局利用，使得如来成鬼的大意念不过是危害天下。至于此，正邪皆不能容，只好孑然独行，于那混沌难明的善恶之中求得己心澄明。</p>
<p>我亦希望在这茫茫浊世之中，求得不二法门，得到大自在。只是，可以求得么？</p>
<p>这篇影评本是对人之承诺，却不能完成。又欠小丹两个小时，其他不知凡几，我所欠的太多，我所负的太多，或许沉默寡言才可以不愧于人，只是这样一来，难道不是不敢担当么？</p>
<p>《礼记·缁衣》中说道：君子道人以言而禁人以行，故言必虑其所终，而行必稽其所敝，则民谨于言而慎于行。</p>
<p>以往的我，太嚣狂妄语，当戒之！</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/pansee/film review/津渡几曾迷/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/pansee/film review/津渡几曾迷/" class="post-title-link" itemprop="url">津渡几曾迷</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/film-review/" itemprop="url" rel="index"><span itemprop="name">film review</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>津渡几曾迷</p>
<p>——《12怒汉》观感</p>
<p>女法官与圣母像重合，黑暗中的道路亮起了明灯，于是乎：</p>
<p>愤怒的士兵倒下，巨大的车轮滚动，“自由，劳动，幸福，向着人民光明的未来前行”！</p>
<p>民主即专制</p>
<p>——不得不说，你的想法有点……</p>
<p>——犹太。</p>
<p>12怒汉，实则是12使徒，来自不同职业，不同阶层，不同民族与地区，有着不同的经历，不同的生活习惯，不同的文化与思维方式，他们以12——这个基督教的完满之数包容了一个社会，所有的人民。</p>
<p>当人类能够直立起来，人类共生关系的相互依存性也同时被决定。如果说过去的人类社会还可以存在不同民族间的相互杀戮，上层阶级和下层阶级民众之间还可以存在压迫与反抗，在今天这个生产力高度发展，全球化的经济依赖与文化交融的情况下，每个人，乃至于每个民族都无法脱离整个社会而单独生存。</p>
<p>显然，一个无序混乱的社会无法满足要求，少数人专制的社会也必然会被意识觉醒，要求平等的被统治的大多数所推翻，人类对生存的越来越高要求，一个有序民主的社会必将出现。在此民主的社会之中，“人人生而平等，每个人一出生便拥有上帝所赋予的权利，包括生命权，财产权，自由权等”。</p>
<p>你相信么，人类是为了国家而存在？或者国家是为了个人而存在。</p>
<p>每个人为了实现其有效的最大利益，不得不放弃部分利益互相集结成国家与社会。橱窗造出的社会不是“一个他人”，并不存在凌驾于个人利益之上的“集体利益”。民主的价值在于通过每个人都有被才觉得可能从而理性的保护每个人有效的最大利益。正是每个人被裁决的等可能性要求着人与人间的平等，无视财富，无视民族。“如果他没有杀人，他俄语讲得好与不好又有什么区别呢？”每个人都是一个独立的个体，有与众不同的个性，如果不能包容不同的文化习俗，不同的生活方式，矛盾不能得到调和，争端持续出现，平等只是空谈，民主不过幻梦。</p>
<p>但如果乌玛确实杀了他的养父呢？宽容与接受依旧存在限度，海只能纳百川，而不能容沙石。道德的拥有便是宽容与接受的标准，异己者需要消灭，民主不过是多数人更确切的说是强力者所遵循与认同的道德的专制。民主即专制的成立条件乃是上帝赋予了不道德者相同与道德者的权利，不然专制无从谈起。虽然说存在即有理由，但上帝说人要向善，有趣的是上帝惨遭厄运，一切化为乌有。成熟的社会在动荡中获取类人格，摆脱工具身份，一跃而上上帝的宝座，订立宣扬善恶之分界，专制即民主！</p>
<p>法律即罪行</p>
<p>法律的目的乃是为了维护正义从而实现社会的全道德，消灭不正义及至不道德的可能。而正义乃是过往人类的造物，现如今只隶属于道德社会。显然，符合社会道德的乃是正义，不道德的乃是罪恶，故而傻人有罪，当受刑罚。</p>
<p>刑法之合理性何在？基于同意主义，报应主义抑或威慑主义？然而人类怎么能自欺欺人的相信犯罪者在犯罪时保有绝对的理性？“放下屠刀，立地成佛”，如果正有这样的屠夫，等待他的也只能是死刑或终身监禁。报应主义是如此之可笑！杀人者应当受到报应，被杀者难道不是已经受到了报应？法律有是否可以充当上帝之手，做出完美的调节与冲抵呢？扼杀可能与威慑主义才是真正的直接目的。“法律已经死了，我可对他没有偏见，不接触法律的俄罗斯人是空壳，他不会偷也不会保护自己。”想想那个哈佛人在恐惧之下的决定，刑法的目的乃是排除威胁，排除实在之后不再实在的可能甚至于不曾实在过的可能，以此保障大多数人的安全有效最大利益。在侵害部分人的利益之时，又不曾让另一部分人的利益有所增广，刑法是如此低效，甚至于是自私的罪行！幸运的是人类的法律行将就木，道德社会的公证法律愈加强势，人数人的专制，强权者的意志，将无处容身，自私，利益，不道德的行为，消亡！</p>
<p>“你们有权决定，凶手犯下的罪行，危害社会的行为，是否可以受到最严厉的惩罚。”问题在于，既然已经确定人的社会性事实，是否杀人者该为起杀人行为完全埋单？是否处死杀人者即可消灭罪恶确切的说不道德的可能？如果承认人性之恶，专制之民主再一次得到证明，异己的不道德只能被灭亡，只有基于共同道德的不同者之间才能有平等可言。如果承认环境因素之影响，犯罪者之罪行又如何能够由其一身承受？更重要的，如果说人一旦脱离了他人与他物，就无法证得自身的存在，那么人的独立个性何在？或者说，个性并不能独立存在，乃是他人与他物所赋予。正在装修的法院，已不再是孩子的小学生的学校，多么巧妙的位置关系。人从一出生就开始受到框定，道德坚定稳固的植根于人心，从而社会其自身可以达到天下人皆知美之为美，善善恶恶的完美道德境界。“好人就该受到帮助，坏人就该……”于是乎，每个道德社会的个人，都以社会道德为立场生存甚至于思想，每个人的个性也将基于道德共性之上。因而学生们离开学校之时，不道德的可能即被消灭，法院在建成的同时成为历史的建筑，又随着历史消逝于无形。然而，法律难道没有扼杀不道德的个性，确乎不是罪行！</p>
<p>还有更怪异的事情发生。城市化的发展，新居住地的筑建，已然开始侵损大多数人的利益。但又是什么保证它的合法性，是之不必受到法律的制裁？是少数专制独裁，是强权者的意志，还是一个美好道德的未来？可惜，现在的人类只存在于现在，人类不仅仅被丧失了自然个性，还丧失了自然的现在存在！</p>
<p>可是，难道说永久不止歇的纷争与残杀为人类所期冀？“法律是强势而稳定的，但是当宽容比法律更有强制力时，我们能做什么呢？”以刑去刑，利益被消融，代之以美德和公义，被消亡了罪恶可能的每个人再次得到道德的净化。银戒的光芒，12次的闪动，戴在残破的右手上。人类虽然是自然的自由思想和现在存在者，但却被法律以杀戮的罪行扬弃了甚至于一出生就扬弃了不道德的个性与现在存在，凭借道德之光的指引走向永恒的未来。在全道德的社会中，罪行即法律！</p>
<p>真理即谬误</p>
<p>回忆一下那些特写镜头，轻柔的羽毛，残破的书本，死亡的尸身。人，不过是一根能思想的苇草。人是软弱而无力的，在宇宙与自然面前，在大风的席卷之下，除了像羽毛一样顺从及至被毁灭，还能做些什么呢？死亡是如此之临近，或许明天，或许今天，思想凝结的书本与客观真理，又如何能够通达真理与永恒？</p>
<p>“如果你想飞走就飞走吧。道路通畅。如果你想留下就留下吧。但是做个决定，完全自主决定，没有人能帮你做这个决定，你该骄傲。”鸟儿飞入了寒冬，等待他的将是死亡。一叶扁舟，漂流在苦海上，风浪起，唯有相互连结以抵御。“1,2,3,4,5……1,2,3,4,5……”机械，习惯，重复，钢铁的锁链以道德为基连环，木制小舟本身倒显得无力，与强势的稳定同时而来的是单一的方向，不可更逆。偏向者与弱势者都将被无情的粉碎，不是风浪，而是钢铁的伟力！乌玛和维达亚的死亡不过是前进途中的必然，不是为了私利，不是为了权益，乃是道德与正义的奠基。巨大的质量，巨大的惯性，巨大的前进！如果不相信逻辑的花言巧语，不拿现实与纯粹虚构的绝对的，永恒的世界相比较，不持续不断的通过数字来扭造这个世界，人便没法生存——拒绝错误的判断将意味着拒绝生活，否定人生。“寻求真理，不能在日常生活的细节之中，而应在生命本身。”可悲的是，正是对生命本身的谎言构筑了道德的真理与人生的意义。如果可以选择，是在监狱中长生还是在监狱外死亡？是在黑夜的海上独自摸索还是欢聚前行？出创造出的社会乃是当时人类的自主选择，一次摆脱迷惘与无所依从，克服生命不能承受之轻。恐怖的是，选择的道路产生自然的巨大引力，社会以谬误的真理创造出封锁其他道路选择的法律，当全道德实现，法律消融，大道坦途，谬误即真理！</p>
<p>难道有善，难道有非善？遁去的一，杳无踪迹，虚无之路，同样不可求取。九天明月不可揽觅，其实对镜流连看花影。于是乎：</p>
<p>津渡几曾迷？</p>
<p>2010年11月11日星期四</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/machine learning/NN/Neural Networks for Applied Sciences and Engineering--Chapter 8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/machine learning/NN/Neural Networks for Applied Sciences and Engineering--Chapter 8/" class="post-title-link" itemprop="url">Neural Networks for Applied Sciences and Engineering--Chapter 8</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/NN/" itemprop="url" rel="index"><span itemprop="name">NN</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Chapter-8-Discovering-Unknown-Clusters-in-Data-with-Self-Organizing-Maps"><a href="#Chapter-8-Discovering-Unknown-Clusters-in-Data-with-Self-Organizing-Maps" class="headerlink" title="Chapter 8 Discovering Unknown Clusters in Data with Self-Organizing Maps"></a>Chapter 8 Discovering Unknown Clusters in Data with Self-Organizing Maps</h1><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

<h2 id="8-1-Introduction-and-Overview"><a href="#8-1-Introduction-and-Overview" class="headerlink" title="8.1 Introduction and Overview"></a>8.1 Introduction and Overview</h2><h2 id="8-2-Structure-of-Unsupervised-Networks"><a href="#8-2-Structure-of-Unsupervised-Networks" class="headerlink" title="8.2 Structure of Unsupervised Networks"></a>8.2 Structure of Unsupervised Networks</h2><h2 id="8-3-Learning-in-Unsupervised-Networks"><a href="#8-3-Learning-in-Unsupervised-Networks" class="headerlink" title="8.3 Learning in Unsupervised Networks"></a>8.3 Learning in Unsupervised Networks</h2><blockquote>
<p>Rosenblatt proposed a model of competitive learning between neurons.In his model that<br> attempts to mimic this brain function,neurons inhibit each other<br> by sending their activation as inhibitory signals,the goal being to<br> win a competition for the maximum activation corresponding to an input pattern.<br> <strong>The neuron with the maximum activation then represents the input pattern</strong> that<br> led to its activation. This neuron alone becomes the winner and is allowed to<br> <strong>adjust its weight vector by moving it closer to that input vector</strong>;however,the neurons that<br> lose the competition by succumbing to the inhibition are not allowed to change their weights.</p>
</blockquote>
<h2 id="8-4-Implementation-of-Competitive-Learning"><a href="#8-4-Implementation-of-Competitive-Learning" class="headerlink" title="8.4 Implementation of Competitive Learning"></a>8.4 Implementation of Competitive Learning</h2><blockquote>
<p>In many cases,the number of data clusters is unknown.When there is uncertainty,<br> it is better to <strong>have a larger number</strong> of output neurons than the possible number of clusters<br> <strong>because redundant neurons can be eliminated</strong>.<br> After the number of input variables and output neurons has been set,the next step is to<br> <strong>initialize the weights</strong>.These may be set to <strong>small random values</strong>,as was done in the MLP networks.<br> Another possibility is to <strong>randomly choose some input vectors and use their values for the weights</strong>.<br> This has the potential to speed up learning.</p>
</blockquote>
<h3 id="8-4-1-Winner-Selection-Based-on-Neuron-activation"><a href="#8-4-1-Winner-Selection-Based-on-Neuron-activation" class="headerlink" title="8.4.1 Winner Selection Based on Neuron activation"></a>8.4.1 Winner Selection Based on Neuron activation</h3><blockquote>
<p>Once each output neuron has computed its activation,competition can begin.There are several ways<br> this can happen;a simple way is for each neuron to <strong>send its signal</strong> in an inhibitory manner,<br> with <strong>an opposite sign to other neurons</strong>.Once each neuron has received signals from the others,<br> each neuron can compute its <strong>net activation</strong> by simply summing the incoming inhibitory signals and<br> its own activation.If the activation drops below a threshold(or zero),that neuron drops out of the competition.<br> As long as more than one neuron remians,the cycle of inhibition continues until one winner emerges;<br> its output is set to one.This neuron is declared the winner because it has the highest activation<br> and it alone represents the input vector.</p>
</blockquote>
<p><span style="color:blue"><em>Is the opposite sign only the sign,not the opposite activation?</em></span></p>
<h3 id="8-4-2-Winner-Selection-Based-on-Distance-to-Input-vector"><a href="#8-4-2-Winner-Selection-Based-on-Distance-to-Input-vector" class="headerlink" title="8.4.2 Winner Selection Based on Distance to Input vector"></a>8.4.2 Winner Selection Based on Distance to Input vector</h3><blockquote>
<p>Once the distance between an input vector and all the weights has been found,<br> the neuron with <strong>the smallest distance</strong> to the input vector is chosen as the winner,<br> and its weights are updated so that it <strong>moves closer to the input vector</strong>,as<br> \(\Delta\omega_j = \beta(x - \omega_j) = \beta{}d_j\).<br><img src="http://omdhuynsr.bkt.clouddn.com/17-3-6/13980399-file_1488786922883_a440.png" alt title="weight update"></p>
</blockquote>
<h4 id="8-4-2-1-Other-Distance-Measures"><a href="#8-4-2-1-Other-Distance-Measures" class="headerlink" title="8.4.2.1 Other Distance Measures"></a>8.4.2.1 Other Distance Measures</h4><h3 id="8-4-3-Competitive-Learning-Example"><a href="#8-4-3-Competitive-Learning-Example" class="headerlink" title="8.4.3 Competitive Learning Example"></a>8.4.3 Competitive Learning Example</h3><h4 id="8-4-3-1-Recursive-Versus-Batch-Learning"><a href="#8-4-3-1-Recursive-Versus-Batch-Learning" class="headerlink" title="8.4.3.1 Recursive Versus Batch Learning"></a>8.4.3.1 Recursive Versus Batch Learning</h4><blockquote>
<p>In the batch learning,the weight update for each input vector is noted,<br> but the weights are not changed until all the input patterns have been presented.<br> Training terminates when the mean distance between the winning neurons and<br> the inputs they repersent is at a minimum across the entire set of clusters,<br> or when this distance stops changing.</p>
</blockquote>
<h4 id="8-4-3-2-Illustration-of-the-Calculations-Involved-in-Winner-Selection"><a href="#8-4-3-2-Illustration-of-the-Calculations-Involved-in-Winner-Selection" class="headerlink" title="8.4.3.2 Illustration of the Calculations Involved in Winner Selection"></a>8.4.3.2 Illustration of the Calculations Involved in Winner Selection</h4><blockquote>
<p>The training criterion is the mean distance(the sum of the squared distance)<br> between all the inputs and their respective winning neuron weights which<br> represent the cluster centers.<br> The objective of training is to <strong>minimize the mean distance</strong> over iterations.<br> The mean distance \(D\) can be expressed as<br> $$D = \sum_{i=0}^k \sum_{n\in C_i}(x^n - \omega_i)^2$$</p>
</blockquote>
<h4 id="8-4-3-3-Network-Training"><a href="#8-4-3-3-Network-Training" class="headerlink" title="8.4.3.3 Network Training"></a>8.4.3.3 Network Training</h4><h2 id="8-5-Self-Organizing-Feature-Maps"><a href="#8-5-Self-Organizing-Feature-Maps" class="headerlink" title="8.5 Self-Organizing Feature Maps"></a>8.5 Self-Organizing Feature Maps</h2><blockquote>
<p>In SOMs,not only the winner neuron but also neurons in <strong>the neighborhood</strong> of the winner<br> <strong>adjust</strong> their weights together so that a neighborhood of neurons becomes sensitive to a specific input.<br> This neighborhood feature helps to preserve <strong>topological characteristics of inputs</strong>.<br> Therefore,inputs that are spatially closer together must be represented in close proximity<br> in the output layer or map of a network.</p>
</blockquote>
<h3 id="8-5-1-Learning-in-Self-Organizing-Map-Networks"><a href="#8-5-1-Learning-in-Self-Organizing-Map-Networks" class="headerlink" title="8.5.1 Learning in Self-Organizing Map Networks"></a>8.5.1 Learning in Self-Organizing Map Networks</h3><h4 id="8-5-1-1-Selection-of-Neighborhood-Geometry"><a href="#8-5-1-1-Selection-of-Neighborhood-Geometry" class="headerlink" title="8.5.1.1 Selection of Neighborhood Geometry"></a>8.5.1.1 Selection of Neighborhood Geometry</h4><blockquote>
<p>There are several ways to define a neighborhood.<br> <img src="http://omdhuynsr.bkt.clouddn.com/17-3-6/15425123-file_1488797380352_ba79.png" alt><br> If only the most immediate neighbors of the winer are considered,the distance,<br> also called <strong>radius r</strong>,is 1.If two levels of adjacent neighbors are considered,then the radius is 2.</p>
</blockquote>
<h4 id="8-5-1-2-Training-of-Self-Organizing-Maps"><a href="#8-5-1-2-Training-of-Self-Organizing-Maps" class="headerlink" title="8.5.1.2 Training of Self-Organizing Maps"></a>8.5.1.2 Training of Self-Organizing Maps</h4><blockquote>
<p>$$\omega_j^{‘} = \omega_j + \beta NS<em>[x - \omega_j]$$<br> where \(NS\) is the <em>*neighbor strength</em></em> that varies with the distance to a neighbor neuron from the winner.<br> Neighbor strengh defines the strength of weight adjustment of the neighbors with respect to that of the winner.</p>
</blockquote>
<h4 id="8-5-1-3-Neighbor-Strength"><a href="#8-5-1-3-Neighbor-Strength" class="headerlink" title="8.5.1.3 Neighbor Strength"></a>8.5.1.3 Neighbor Strength</h4><blockquote>
<p>The winning neuron update is the most pronounced and the farther away a neighbor neuron is,<br> the less its weight update.The \(NS\) function determines how the weight adjustment<br> <strong>decays</strong> with distance from the winner.There are several possibilities for this function and<br> some commonly usedd functions are <strong>linear,Gaussian,and exponential</strong>.<br> The Gaussian form of the \(NS\) function makes the weight adjustments decay smoothly with distance,<br> and is given by \(NS = Exp[\frac{-d_{i,j}^2}{2\delta^2}]\)<br> The exponential decay \(NS\) function is given by \(NS = Exp[-kd_{i,j}]\)</p>
</blockquote>
<h4 id="8-5-1-4-Example-Training-Self-Organizing-Networks-with-a-Neighbor-Feature"><a href="#8-5-1-4-Example-Training-Self-Organizing-Networks-with-a-Neighbor-Feature" class="headerlink" title="8.5.1.4 Example:Training Self-Organizing Networks with a Neighbor Feature"></a>8.5.1.4 Example:Training Self-Organizing Networks with a Neighbor Feature</h4><h4 id="8-5-1-5-Neighbor-Matrix-and-Distance-to-Neighbors-from-the-Winner"><a href="#8-5-1-5-Neighbor-Matrix-and-Distance-to-Neighbors-from-the-Winner" class="headerlink" title="8.5.1.5 Neighbor Matrix and Distance to Neighbors from the Winner"></a>8.5.1.5 Neighbor Matrix and Distance to Neighbors from the Winner</h4><blockquote>
<p>When the map is large,an efficient method is required to determine the distance of a neighbor<br> from the winner to compute neighor strength.<br> Use a neighbor matrix(\(NM\),also called distance matrix) for a two-dimensional map as a example.<br> For a map of 12 neurons arranged in three rows and four columns,the neighbor matrix for a<br> rectangular neighborhood is<br> $$NM = \begin{bmatrix}<br> 3 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 3 \\\\<br> 3 &amp; 2 &amp; 1 &amp; 1 &amp; 1 &amp; 2 &amp; 3 \\\\<br> 3 &amp; 2 &amp; 1 &amp; 0 &amp; 1 &amp; 2 &amp; 3 \\\\<br> 3 &amp; 2 &amp; 1 &amp; 1 &amp; 1 &amp; 2 &amp; 3 \\\\<br> 3 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 3<br> \end{bmatrix}_{5\times7}$$<br> Suppose that the horizontal and vertical coordinates of the winner neuron on the two-dimensional map<br> are indicated by (\(i_{win},j_{win})\).Then the distance between the winner and<br> any neighbor neuron at position \((i,j)\) is<br> $$d = NM[\begin{bmatrix} c_1-i_{win}+i,c_2-j_{win}+j \end{bmatrix}]$$<br> where \({c_1,c_2}\) is the position of the winner in the neighbor matrix \(NM\).For this case,<br> \(c_1 = 3\) and \(c_2 = 4\)</p>
</blockquote>
<h4 id="8-5-1-6-Shrinking-Neighborhood-Size-with-iterations"><a href="#8-5-1-6-Shrinking-Neighborhood-Size-with-iterations" class="headerlink" title="8.5.1.6 Shrinking Neighborhood Size with iterations"></a>8.5.1.6 Shrinking Neighborhood Size with iterations</h4><blockquote>
<p><strong>A larger initial neighborhood is necessay because smaller initial neighborhoods can lead to<br> metastable states corresponding to local minima</strong>.However,subsequent <strong>shrinking</strong> of neighborhood<br> is required to further <strong>refine</strong> the representation of the input probability distribution by the map.<br> The equation below shows a linear function commnonly used for this purpose:$$\delta_t = \delta_0(1-t/T)$$<br> Exponential decay is another form used for adjusting neighborhood size with iterations,as given by<br> $$\delta_t = \delta_0Exp[-t/T]$$<br> And the decay in neighborhood size is integrated into the NS function as<br> $$NS(d,t) = Exp[-d_{i,j}^2/2\delta_t^2] = Exp[-d_{i,j}^2/2\\{\delta_0Exp(-t/T)\\}^2]$$<br> where \(T\) is a constant that allows the decay function to decay to zero with iterations.<br> A recommendation is  that the neighborhood size should initially cover almost all neurons in the network<br> when centered on a winning neuron and then shrink slowly with iterations.</p>
</blockquote>
<h4 id="8-5-1-7-Learning-Rate-Decay"><a href="#8-5-1-7-Learning-Rate-Decay" class="headerlink" title="8.5.1.7 Learning Rate Decay"></a>8.5.1.7 Learning Rate Decay</h4><blockquote>
<p>The step length,or the learning rate \(\beta\),is also reduced with iterations in<br> self-organizing learning and a common form of this function is the linear decay,given by<br> $$\beta_t = \beta_0(1-t/T)$$<br> Another form is the exponential decay of the learning rate given by<br> $$\beta_t = \beta_0Exp[-t/T]$$<br> where \(T\) is a time constant that brings the learning rate to a very small value with iterations.<br> A general guide is to start with a relatively high learning rate and let it decrease gradually but<br> remain above 0.01.</p>
</blockquote>
<h4 id="8-5-1-8-Weight-Update-Incorporating-Learning-Rate-and-Neighborhood-Decay"><a href="#8-5-1-8-Weight-Update-Incorporating-Learning-Rate-and-Neighborhood-Decay" class="headerlink" title="8.5.1.8 Weight Update Incorporating Learning Rate and Neighborhood Decay"></a>8.5.1.8 Weight Update Incorporating Learning Rate and Neighborhood Decay</h4><blockquote>
<p>Thus,the weight update after presenting an input vector \(\mathbf{x}\) to a SOM incorporating both<br> neighborhood size and learning rate that decrease with the number of iterations can be expressed as<br> $$\omega_j(t) = \omega_j(t-1) + \beta(t)NS(d,t)[\mathbf{x}(t)-\omega_j(t-1)]$$</p>
</blockquote>
<h4 id="8-5-1-9-Recursive-and-Batch-Training-and-Relation-to-K-Means-Clustering"><a href="#8-5-1-9-Recursive-and-Batch-Training-and-Relation-to-K-Means-Clustering" class="headerlink" title="8.5.1.9 Recursive and Batch Training and Relation to K-Means Clustering"></a>8.5.1.9 Recursive and Batch Training and Relation to K-Means Clustering</h4><blockquote>
<p>In batch mode,the unsupervised algorithm without neighbor feature becomes <strong>equivalent to</strong> K-means clustering.<br> When the neighbor feature is incorporated,it allows <strong>nonlinear projection</strong> of the data as well as<br> the very attractive feature of <strong>topology preservation</strong>,by which regions closer in input space are<br> represented by neurons that are closer in the map.<strong>For this reason it is called a feature map.</strong></p>
</blockquote>
<h4 id="8-5-1-10-Two-Phases-of-Self-Organizing-Map-Training"><a href="#8-5-1-10-Two-Phases-of-Self-Organizing-Map-Training" class="headerlink" title="8.5.1.10 Two Phases of Self-Organizing Map Training"></a>8.5.1.10 Two Phases of Self-Organizing Map Training</h4><blockquote>
<p>Training is usually performed in two phases:ordering and convergence.<br> In the ordering phase,learning rate and neighborhood size are reduces with iterations until<br> the winner or a few neighbors around the winner remain.<br> In the convergence phase,the feature map is fine tuned with the shrunk neighborhood so that<br> it produces an accurate representation of the input space.<br> In this phase,<strong>learning rate is maintained at a small value</strong>,on the order of 0.01,<br> to achieve convergence with good statistical accuracy.Haykin states that the learning rate<br> must not become zero because the network can get stuck in a metastable state that<br> corresponds to a feature map configuration with a topological defect.The \(NS\) function should<br> <strong>contain only the nearest neighbors</strong> of the winning neuron and may <strong>slowly reduce to one or zero neighbors</strong>(i.e.,only the winner remains).</p>
</blockquote>
<h4 id="8-5-1-11-Example-Illustrating-Self-Organizing-Map-Learning-with-a-Hand-Calculations"><a href="#8-5-1-11-Example-Illustrating-Self-Organizing-Map-Learning-with-a-Hand-Calculations" class="headerlink" title="8.5.1.11 Example:Illustrating Self-Organizing Map Learning with a Hand Calculations"></a>8.5.1.11 Example:Illustrating Self-Organizing Map Learning with a Hand Calculations</h4><h4 id="8-5-1-12-SOM-Case-Study-Determination-of-Mastitis-Health-Status-of-Dairy-Herd-from-Combined-Milk-Traits"><a href="#8-5-1-12-SOM-Case-Study-Determination-of-Mastitis-Health-Status-of-Dairy-Herd-from-Combined-Milk-Traits" class="headerlink" title="8.5.1.12 SOM Case Study:Determination of Mastitis Health Status of Dairy Herd from Combined Milk Traits"></a>8.5.1.12 SOM Case Study:Determination of Mastitis Health Status of Dairy Herd from Combined Milk Traits</h4><h3 id="8-5-2-Example-of-Two-Dimensional-Self-Organizing-Maps-Clustering-Canadian-and-Alaskan-Salmon-Based-on-the-Diameter-of-Growth-Rings-of-the-Scales"><a href="#8-5-2-Example-of-Two-Dimensional-Self-Organizing-Maps-Clustering-Canadian-and-Alaskan-Salmon-Based-on-the-Diameter-of-Growth-Rings-of-the-Scales" class="headerlink" title="8.5.2 Example of Two-Dimensional Self-Organizing Maps:Clustering Canadian and Alaskan Salmon Based on the Diameter of Growth Rings of the Scales"></a>8.5.2 Example of Two-Dimensional Self-Organizing Maps:Clustering Canadian and Alaskan Salmon Based on the Diameter of Growth Rings of the Scales</h3><h4 id="8-5-2-1-Map-Structure-and-Initialization"><a href="#8-5-2-1-Map-Structure-and-Initialization" class="headerlink" title="8.5.2.1 Map Structure and Initialization"></a>8.5.2.1 Map Structure and Initialization</h4><h4 id="8-5-2-2-Map-Training"><a href="#8-5-2-2-Map-Training" class="headerlink" title="8.5.2.2 Map Training"></a>8.5.2.2 Map Training</h4><blockquote>
<p>For example,the map was trained using a square neighborhood with learning rate \(\beta\) expressed as<br> $$\beta = \left\\{\begin{array}{ll}<br>    0.01&amp;{t &lt; 5} \\\\<br>    \frac{2}{3+t}&amp;{t &gt; 5}\end{array}\right.$$<br> Learning rate is a <strong>samll constant value</strong> in the first four iterations so that the codebook vectors<br> <strong>find a good orientation</strong>(this is not always done).<br> The neighbor strength function used was<br> $$NS = \left\\{\begin{array}{ll}<br>        Exp[-0.1d]&amp;if \quad t &lt; 5 \\\\<br>        Exp[-\frac{(t-4)}{10}d]&amp;otherwise\end{array}\right.$$<br> During the first four iterations,<strong>all neurons on the map are neighbors</strong> of a winning neuron and<br> <strong>all neighbors are <em>strongly</em> influenced</strong>.The stronger influence on the neighbors in the initial iterations<br> makes the network conform to a nice structure and avoids knots.<br> <strong><em>Ordering phase</em></strong>.The map was trained using <strong>recursive update</strong>.<br> <strong><em>Convergence phase</em></strong>.To finetune and make sure that the map has converged,the trained map was trained further in <strong>batch mode</strong>.<br> Because the network in this case appears to have approached <strong>convergence</strong>,the learning rate<br> has been <strong>set to 1.0</strong> because there will be only small or straightforward adjustments to<br> the position of the codebook vectors with further training.The neighbor strength is <strong>limited to<br> the winning neuron</strong>.If,however,the network has <strong>not approached convergence</strong> in the ordering phase,<br> further training with a smaller constant learning rate on <strong>the order of 0.01</strong> may be appropriate.<br> The neighbor strength then may be <strong>limited to a few neighbors</strong> and decrease to the winner<br> or the nearest neighbors towards the end of training.<br> The final map has reached more data in the outlying regions compared to the map formed<br> at the end of the ordering phase,is expressed as below figure:<br> <img src="http://omdhuynsr.bkt.clouddn.com/17-3-7/10981036-file_1488895472789_17ff2.png" alt><br> <strong>We can set larger number of codebook vectors than the number of classes.</strong><br> So,a cluster of codebook vectors,not a single vector,defines each class.<strong>This gives the map its<br> ability to form nonlinear cluster boundaries.</strong>This cluster structure can be used to<br> discover unknown clusters in data.The map can also be used for subsequent supervised classification.<br> For example,when class labels are known,the codebook vectors that represent corresponding<br> input vectors can <strong>be used as input</strong> to train a feedforward classification network to obtain<br> the calss to which a particular unknown input vector belongs.This is called <strong>learning vector quantization</strong>.<br> Each codebook vector represents the center of gravity of a cluster of inputs that it represents and<br> therefore approximates <strong>the average or point density</strong> of the original distribution in a small cluster region.<br> <strong>Therefore,the magnitude(length) of the codebook vectors should reflect this.</strong> A properly ordered map<br> should show evenly varying length of the codebook vectors on the map.</p>
</blockquote>
<p><span style="color:red">It is a good example of model designment and parameters adjustment.</span><br><span style="color:blue">why the magnitude could relect the point density of the original distribution?</span></p>
<h4 id="8-5-2-3-U-Matrix"><a href="#8-5-2-3-U-Matrix" class="headerlink" title="8.5.2.3 U-Matrix"></a>8.5.2.3 U-Matrix</h4><blockquote>
<p>The distance between the neighboring codebook vectors can highligh different cluster regions<br> in the map and can be a useful visualization tool.The average of the distance to the nearest neighbors<br> is called unified distance,and the matrix of these values for all neurons is called the U-matrix.<br> Thus the map has not only orientated itself in the principal directions of the data,but has also<br> learned to represent the density distribution of the input data,like the figure below:<br> <img src="http://omdhuynsr.bkt.clouddn.com/17-3-8/37014593-file_1488941605615_b781.png" alt></p>
</blockquote>
<p><span style="color:blue">I can understand the figure,but I can’t understand why the distance is average<br>and how to plot the figure.Does the average of the distance mean the average of all input in related cluster regions?</span></p>
<h3 id="8-5-3-Map-Initialization"><a href="#8-5-3-Map-Initialization" class="headerlink" title="8.5.3 Map Initialization"></a>8.5.3 Map Initialization</h3><blockquote>
<p><strong>Random initialization</strong> clusters the initial vectors near the center of gravity of inputs and assigns<br> random values in this cener region.<br> <strong>Deterministic initialization</strong> is another approach,where some input vectors from the dataset<br> are used as initial vectors.This can accelerate map training.<br> Yet another approach is to train a map with random initialization for a few iterations and<br> use the resulting vectors as initial vectors(<strong>random-derministic</strong>).<br> Another possible approach to initialization is to find the first two<br> <strong>principal directions</strong> of data using principal component analysis and<br> use these two directions for map directions.</p>
</blockquote>
<h3 id="8-5-4-Example-Training-Two-Demensional-Maps-on-Multidimensional-Data"><a href="#8-5-4-Example-Training-Two-Demensional-Maps-on-Multidimensional-Data" class="headerlink" title="8.5.4 Example:Training Two-Demensional Maps on Multidimensional Data"></a>8.5.4 Example:Training Two-Demensional Maps on Multidimensional Data</h3><blockquote>
<p>The SOMs can be used not only to cluster input data,but also to <strong>explore the relationship<br> between different attributes of input data.</strong></p>
</blockquote>
<h4 id="8-5-4-1-Data-Visualization"><a href="#8-5-4-1-Data-Visualization" class="headerlink" title="8.5.4.1 Data Visualization"></a>8.5.4.1 Data Visualization</h4><blockquote>
<p>It is a good example for EDA with iris datasets:<br> <img src="http://omdhuynsr.bkt.clouddn.com/17-3-8/91990443-file_1488956403117_5fd3.png" alt><br> Where use color distinct different clusters.</p>
</blockquote>
<p><span style="color:red">It is a good example for EDA.</span></p>
<h4 id="8-5-4-2-Map-Structure-and-Training"><a href="#8-5-4-2-Map-Structure-and-Training" class="headerlink" title="8.5.4.2 Map Structure and Training"></a>8.5.4.2 Map Structure and Training</h4><blockquote>
<p><img src="http://omdhuynsr.bkt.clouddn.com/17-3-8/3745649-file_1488961989125_16d9f.png" alt><br> <img src="http://omdhuynsr.bkt.clouddn.com/17-3-8/88751501-file_1488962053638_139d5.png" alt><br> <img src="http://omdhuynsr.bkt.clouddn.com/17-3-8/50439332-file_1488962099950_d395.png" alt></p>
</blockquote>
<h4 id="8-5-4-3-U-matrix"><a href="#8-5-4-3-U-matrix" class="headerlink" title="8.5.4.3 U-matrix"></a>8.5.4.3 U-matrix</h4><p><span style="color:blue">8.5.4 should be inspection again.It provides many tricks of EDA.</span></p>
<h4 id="8-5-4-4-Point-Estimates-of-Probability-Density-of-Inputs-Caotured-by-the-Map"><a href="#8-5-4-4-Point-Estimates-of-Probability-Density-of-Inputs-Caotured-by-the-Map" class="headerlink" title="8.5.4.4 Point Estimates of Probability Density of Inputs Caotured by the Map"></a>8.5.4.4 Point Estimates of Probability Density of Inputs Caotured by the Map</h4><blockquote>
<p>From the trained map,we can also determine the number of input vectors represented by each neuron.<br> Each neuron represents the local probability density of inputs.In the below figure,the lighter the color,<br> the larger the number of inputs falling onto thar neuron.<br> <img src="http://omdhuynsr.bkt.clouddn.com/17-3-8/29639643-file_1488963168903_8ffa.png" alt></p>
</blockquote>
<h4 id="8-5-4-5-Quantization-Error"><a href="#8-5-4-5-Quantization-Error" class="headerlink" title="8.5.4.5 Quantization Error"></a>8.5.4.5 Quantization Error</h4><blockquote>
<p>Quantization error is a measure of the distance between codebook vectors and inputs.<br> If for an input vector \(\mathbf{x}\),the winner’s weights vector is \(\pmb{\omega}_c\),<br> then the quantization error can be described as a distortion error,\(e\),expressed as<br> $$e = d(\mathbf{x},\pmb{\omega}_c)$$</p>
</blockquote>
<blockquote>
<p>which is the distance from the input to the closet codebook vector.<br> It may be more appropriate to define the distortion error in terms of neighborhood function<br> because the neighbor featuer is central to SOM.With the neighbor feature,<br> the distortion error of the map for an input vector \(\mathbf{x}\) becomes<br> $$e = \sum_{i}NS_{ci}d(\mathbf{x},\pmb{\omega_i})$$<br> where \(NS_{ci}\) is the neighbor strength,\(c\) is the index of the winning neuron closest to input vector \(\mathbf{x}\),<br> and \(i\) is any neuron in the neighborhood of the winner,including the winner.<br> Computing the distortion measure for all input vectors in the input space,the average distortion error \(E\)<br> for the map can be calculated from<br> $$E = \frac{1}{N}\sum_n\sum_iNS_{ci}d(\mathbf{x}^n,\pmb{\omega}_i)$$<br> When the neighbor feature is not used,equation above simplifies to<br> $$E = \frac{1}{N}\sum_nd(\mathbf{x}^n,\pmb{\omega}_i)$$<br> Thus the goal of SOM can alternatively be expressed as finding the set of codebook vectors \(\pmb{\omega}_i\)<br> that <strong>globally minimizes the average map distortion error \(E\)</strong>.<br> The information from figure below can be used to refine the map to obtain a more uniform distortion error measure<br> if a more faithful reproduction of the input distribution from the map is desired.<br> <img src="http://omdhuynsr.bkt.clouddn.com/17-3-8/32153453-file_1488971907071_18164.png" alt></p>
</blockquote>
<p><span style="color:blue">The format of Latex here has some problems,so I split the words to two parts.How could fix it?</span></p>
<h4 id="8-5-4-6-Accuracy-of-Retrieval-of-Input-Data-from-the-Map"><a href="#8-5-4-6-Accuracy-of-Retrieval-of-Input-Data-from-the-Map" class="headerlink" title="8.5.4.6 Accuracy of Retrieval of Input Data from the Map"></a>8.5.4.6 Accuracy of Retrieval of Input Data from the Map</h4><blockquote>
<p>If the dataset is sent through the map,it identifies the best matching codebook vector.The resulting codebook vector<br> can be thought of as the retrieved input because it is the closest to that input.<br> If a neighborhood of neurons is used in the retrieval,more than one codebook vector can be activated and<br> these codebook vectors can be interpolated to obtain a recalled match of the input to the map.Then the retrieved inputs<br> are not the codebook vectors,but <strong>fall between them due to <em>interpolation</em></strong>.<br> The retrieval error is the average distance between the actual data vectors and their corresponding interpolated<br> codebook vectors defining the best position for those input vectors in the trained map.Thus,a neighborhood provides<br> a <strong>better approximation</strong> to this input distribution than a single codebook vector.</p>
</blockquote>
<h3 id="8-5-5-Forming-Clusters-on-the-Map"><a href="#8-5-5-Forming-Clusters-on-the-Map" class="headerlink" title="8.5.5 Forming Clusters on the Map"></a>8.5.5 Forming Clusters on the Map</h3><h4 id="8-5-5-1-Approaches-to-Clustering"><a href="#8-5-5-1-Approaches-to-Clustering" class="headerlink" title="8.5.5.1 Approaches to Clustering"></a>8.5.5.1 Approaches to Clustering</h4><h4 id="8-5-5-2-Example-Illustrating-Clustering-on-a-Trained-Map"><a href="#8-5-5-2-Example-Illustrating-Clustering-on-a-Trained-Map" class="headerlink" title="8.5.5.2 Example Illustrating Clustering on a Trained Map"></a>8.5.5.2 Example Illustrating Clustering on a Trained Map</h4><h3 id="8-5-6-Validation-of-a-Trained-Map"><a href="#8-5-6-Validation-of-a-Trained-Map" class="headerlink" title="8.5.6 Validation of a Trained Map"></a>8.5.6 Validation of a Trained Map</h3><h4 id="8-5-6-1-n-Fold-Cross-Validation"><a href="#8-5-6-1-n-Fold-Cross-Validation" class="headerlink" title="8.5.6.1 n-Fold Cross Validation"></a>8.5.6.1 n-Fold Cross Validation</h4><h2 id="8-6-Evolving-Self-Organizing-Maps"><a href="#8-6-Evolving-Self-Organizing-Maps" class="headerlink" title="8.6 Evolving Self-Organizing Maps"></a>8.6 Evolving Self-Organizing Maps</h2>
          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/machine learning/NN/Time Series Prediction with LSTM Recurrent Neural Networks in Python with Keras/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/machine learning/NN/Time Series Prediction with LSTM Recurrent Neural Networks in Python with Keras/" class="post-title-link" itemprop="url">Time Series Prediction with LSTM Recurrent Neural Networks in Python with Keras</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/NN/" itemprop="url" rel="index"><span itemprop="name">NN</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script></p>
<h1 id="来源"><a href="#来源" class="headerlink" title="来源"></a>来源</h1><p>此文为 <a href="http://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/" target="_blank" rel="noopener">Time Series Prediction with LSTM Recurrent Neural Networks in Python with Keras</a> 的翻译。</p>
<h1 id="翻译"><a href="#翻译" class="headerlink" title="翻译"></a>翻译</h1><p>时序预测问题是预测问题中的一个困难类型。</p>
<p>不像回归预测模型，时序问题存在输入变量中序列依赖的复杂性。</p>
<p>一种强大的神经网络的类型被设计来处理序列依赖，它被称作RNN。LSTM是一种RNN的类型，由于它可以成功训练大型结构，因此被用于深度学习中。</p>
<p>在这篇post中，你将发现如何在python中使用keras深度学习库运用lstm网络去处理一个可示范性的时序预测问题。</p>
<p>在完成这篇教程之后你应该知道如何使用lstm处理自己的时序预测问题和其他更多的通用序列问题。你将知道：</p>
<ul>
<li><p>关于国际航线顾客量的时序问题</p>
</li>
<li><p>怎样使用lstm对时序问题进行回归，窗口和基于时序的框架。</p>
</li>
<li><p>怎样使用长序列下维持state的lstm进行预测</p>
</li>
</ul>
<p>在这个教程中，我们将要发展许多lstm类型进行一个标准时序的预测。</p>
<blockquote>
<p>问题及其选择的lstm配置仅仅只是为了示范目的而不是最优的。</p>
</blockquote>
<p>这些例子将会精确的向你展示你可以怎样发展不一样的lstm结构进行时序预测。</p>
<p>让我们开始吧！</p>
<ul>
<li><p>2016/10更新：每个样本rmse的计算有一个问题。原先的rmse是错误的。现在，rmse</p>
</li>
<li><p>2017/03更新：在keras 2.0.2 tensorflow 1.0.1 和theano 0.9.0 下更新例子</p>
</li>
</ul>
<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>我们在本post中将要研究的问题是国际航班顾客量预测问题。</p>
<p>给定年月，任务是预测国际航班顾客量，以1000为单位。数据范围从1949年1月到1960年12月，12年，144个观察值。</p>
<p>数据集免费可用，来自于 <a href="https://datamarket.com/data/set/22u3/international-airline-passengers-monthly-totals-in-thousands-jan-49-dec-60#!ds=22u3&amp;display=line" target="_blank" rel="noopener">DataMarket webpage as a CSV download</a> ,文件名是<br>“international-airline-passengers.csv“。</p>
<p>下面是文件头几行的一个样本。</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"Month"</span>,<span class="string">"International airline passengers: monthly totals in thousands. Jan 49 ? Dec 60"</span>  </span><br><span class="line"><span class="string">"1949-01"</span>,<span class="number">112</span>  </span><br><span class="line"><span class="string">"1949-02"</span>,<span class="number">118</span>  </span><br><span class="line"><span class="string">"1949-03"</span>,<span class="number">132</span>  </span><br><span class="line"><span class="string">"1949-04"</span>,<span class="number">129</span>  </span><br><span class="line"><span class="string">"1949-05"</span>,<span class="number">121</span></span><br></pre></td></tr></table></figure>
<p>我们可以轻易的使用pandas库导入这个数据集。在观察值是一个月等间隔分割的情况下，我们不需要关心具体date。因此，当我们导入数据的时候我们排除第一列。</p>
<p>下载的数据集也包含页脚信息。我们可以将pandas.read_csv的skipfooter参数设置为3排除最后三行页脚信息。一旦导入数据我们可以轻易的绘制整个数据集图形。导入并绘图的代码在下面给出。</p>
<figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">dataset = pandas.read_csv(<span class="string">'international-airline-passengers.csv'</span>, usecols=[<span class="number">1</span>], engine=<span class="string">'python'</span>, skipfooter=<span class="number">3</span>)</span><br><span class="line">plt.plot(dataset)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>你可以看到数据集随着时间的上升趋势。</p>
<p>你也可以看到一些数据集的周期性，可能和北半球的节假日周期有关。</p>
<p>我们将保持事情的简单性并处理数据集。</p>
<p>正常的，调查各种各样的数据预处理技术进行数据转换，并使之平稳是个好主意。</p>
<h1 id="长短期记忆网络（LSTM）"><a href="#长短期记忆网络（LSTM）" class="headerlink" title="长短期记忆网络（LSTM）"></a>长短期记忆网络（LSTM）</h1><p>lstm是一个循环神经网络，它使用后向传播进行训练并且克服了消失的梯度问题。</p>
<p>因此，他可以被用来创造大型循环网络，并反过来被用于处理机器学习中困难的序列问题并获得了目前最佳结果。</p>
<p>代替神经元，lstm网络使用通过层被连接的记忆块。</p>
<p>记忆块（memory block）有一些成分使得它比经典的神经元更加聪明。block包含了管理block状态和输出的门（gates）。block操作一个输入序列，其中的每一个门使用sigmoid激活函数控制其自身触发与否，进行状态改变和信息流的选择性增加。</p>
<p>一个单元中的门有三种类型：</p>
<ul>
<li>forget gate：条件性的选择什么信息从记忆块中剔除</li>
<li>input gate：条件性的选择输入中的什么值用于更新记忆状态</li>
<li>output gate：条件性的决定基于输入和记忆状态输出什么</li>
</ul>
<p>每个单元类似于一个小型状态机。单元中门的权重在训练中被学习。</p>
<p>你可以看到你怎样从一个lstm层中获得一个复杂的学习和记忆。想象基于多个层的高阶抽象也并不困难。</p>
<h1 id="LSTM-进行回归"><a href="#LSTM-进行回归" class="headerlink" title="LSTM 进行回归"></a>LSTM 进行回归</h1><p>我们可以将问题解析为一个回归问题。</p>
<p>那就是，给定这个月的顾客数量，下个月的顾客数量是多少？</p>
<p>我们可以写一个简单的函数把我们单列数据集转换成两列：第一列包含了这个月的顾客数，第二列包含了需要被预测的下个月的顾客数。</p>
<p>在我们开始之前，首先让我们导入所有需要使用的函数和类。这个假定已经安装了scipy和keras环境。</p>
<figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="title">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="title">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="title">from</span> keras.layers <span class="keyword">import</span> LSTM</span><br><span class="line"><span class="title">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"><span class="title">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br></pre></td></tr></table></figure>
<p>在我们做任何事之前，固定随机数种子确保我们的结果可以复现是个好主意。</p>
<figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># <span class="built_in">fix</span> <span class="built_in">random</span> seed <span class="keyword">for</span> reproducibility</span><br><span class="line">numpy.<span class="built_in">random</span>.seed(<span class="number">7</span>)</span><br></pre></td></tr></table></figure>
<p>我们也可以使用先前的代码加载数据集形成一个dataframe。接着我们从dataframe中抽取numpy数组，并将整型转化为浮点型，这个类型更加适合神经网络模型。</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># load the dataset</span></span><br><span class="line"><span class="attr">dataframe</span> = pandas.read_csv(<span class="string">'international-airline-passengers.csv'</span>, usecols=[<span class="number">1</span>], engine=<span class="string">'python'</span>, skipfooter=<span class="number">3</span>)</span><br><span class="line"><span class="attr">dataset</span> = dataframe.values</span><br><span class="line"><span class="attr">dataset</span> = dataset.astype(<span class="string">'float32'</span>)</span><br></pre></td></tr></table></figure>
<p>lstm对于输入数据的尺度是敏感的，特别是当使用sigmoid或者tanh激活函数的时候。把数据缩放到0-1之间是一个好的方法，叫做规范化。我们可以使用sklearn的MinMaxScaler预处理类轻松的进行数据缩放。</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># normalize the dataset</span></span><br><span class="line"><span class="attr">scaler</span> = MinMaxScaler(feature_range=(<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line"><span class="attr">dataset</span> = scaler.fit_transform(dataset)</span><br></pre></td></tr></table></figure>
<p>在我们对数据建模并估计其在训练集上的表现后，我们需要估计模型在未知数据上的表现。对于一个正常的分类或者回归问题，我们通过交叉验证来处理。</p>
<p>时序数据中，值的序惯性很重要。我们可以使用的一个简单方法是将有序数据分裂为训练和测试集。下面的代码计算了分裂点的索引，将67%的数据分为了训练集用于建模，留下了33%的数据用于测试模型。</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># <span class="keyword">split</span> into train <span class="built_in">and</span> test sets</span><br><span class="line">train_size = <span class="keyword">int</span>(<span class="built_in">len</span>(dataset) * <span class="number">0.67</span>)</span><br><span class="line">test_size = <span class="built_in">len</span>(dataset) - train_size</span><br><span class="line">train, test = dataset[<span class="number">0</span>:train_size,:], dataset[train_size:<span class="built_in">len</span>(dataset),:]</span><br><span class="line"><span class="keyword">print</span>(<span class="built_in">len</span>(train), <span class="built_in">len</span>(test))</span><br></pre></td></tr></table></figure>
<p>现在我们可以定义一个函数去创造一个新的数据集，如上面所述的那样。</p>
<p>函数有两个参数：<strong>数据集</strong>，它是一个numpy数组，我们想将它转换为一个数据集。 <strong>look_back</strong>,它是预测下一刻的输入变量的时间窗口，这个例子中默认为1。</p>
<p>它默认将创造一个数据集，X是给定时间的顾客数，Y是下一时刻的顾客数。</p>
<p>它可以被配置参数，我们将会在下一部份构造一个不一样的数据集。</p>
<figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># <span class="built_in">convert</span> an <span class="built_in">array</span> of <span class="built_in">values</span> into a dataset <span class="built_in">matrix</span></span><br><span class="line">def create_dataset(dataset, look_back=<span class="number">1</span>):</span><br><span class="line">	dataX, dataY = [], []</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(len(dataset)-look_back-<span class="number">1</span>):</span><br><span class="line">		a = dataset[i:(i+look_back), <span class="number">0</span>]</span><br><span class="line">		dataX.<span class="built_in">append</span>(a)</span><br><span class="line">		dataY.<span class="built_in">append</span>(dataset[i + look_back, <span class="number">0</span>])</span><br><span class="line">	<span class="built_in">return</span> numpy.<span class="built_in">array</span>(dataX), numpy.<span class="built_in">array</span>(dataY)</span><br></pre></td></tr></table></figure>
<p>让我们通过数据集的前几行来看看这个函数的效果</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X		Y</span><br><span class="line"><span class="number">112</span>		<span class="number">118</span></span><br><span class="line"><span class="number">118</span>		<span class="number">132</span></span><br><span class="line"><span class="number">132</span>		<span class="number">129</span></span><br><span class="line"><span class="number">129</span>		<span class="number">121</span></span><br><span class="line"><span class="number">121</span>		<span class="number">135</span></span><br></pre></td></tr></table></figure>
<p>如果你可以就这前五行数据跟前一部分所列出的进行对比，你可以从中发现X=t 和T=t+1的模式。</p>
<p>让我们使用这个函数去准备模型的训练和测试数据集。</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># reshape into X=t and Y=t+1</span></span><br><span class="line"><span class="attr">look_back</span> = <span class="number">1</span></span><br><span class="line">trainX, <span class="attr">trainY</span> = create_dataset(train, look_back)</span><br><span class="line">testX, <span class="attr">testY</span> = create_dataset(test, look_back)</span><br></pre></td></tr></table></figure>
<p>lstm需要输入数据通过一种特殊的数组结构被提供，这个形式是：[samples，time steps，features]</p>
<p>当前，我们的数据形式是：[samples，features]，我们需要为每个样本构造1 time steps。我们可以使用 numpy.reshape() 转换训练和测试集成为我们需要的结构。</p>
<figure class="highlight fortran"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># <span class="built_in">reshape</span> input to be [samples, time steps, features]</span><br><span class="line">trainX = numpy.<span class="built_in">reshape</span>(trainX, (trainX.<span class="built_in">shape</span>[<span class="number">0</span>], <span class="number">1</span>, trainX.<span class="built_in">shape</span>[<span class="number">1</span>]))</span><br><span class="line">testX = numpy.<span class="built_in">reshape</span>(testX, (testX.<span class="built_in">shape</span>[<span class="number">0</span>], <span class="number">1</span>, testX.<span class="built_in">shape</span>[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure>
<p>我们现在准备为这个问题设计并拟合一个lstm网络。</p>
<p>网络有一个1维输入的可见层，一个包含4个lstm block的隐藏层，一个单值输出层。默认的sigmoid激活函数被用于lstm block。网络按照100个epoch和1的batch size进行训练。</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create and fit the LSTM network</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.<span class="builtin-name">add</span>(LSTM(4, input_shape=(1, look_back)))</span><br><span class="line">model.<span class="builtin-name">add</span>(Dense(1))</span><br><span class="line">model.compile(<span class="attribute">loss</span>=<span class="string">'mean_squared_error'</span>, <span class="attribute">optimizer</span>=<span class="string">'adam'</span>)</span><br><span class="line">model.fit(trainX, trainY, <span class="attribute">epochs</span>=100, <span class="attribute">batch_size</span>=1, <span class="attribute">verbose</span>=2)</span><br></pre></td></tr></table></figure>
<p>一旦模型拟合，我们可以在训练和测试集上估计模型的效果。这将给我们的新模型一个比较的基准。</p>
<p>注意到我们在计算误差得分前将预测值进行了转换，以确保模型效果是在和原数据单位一致的情况下进行评估的。</p>
<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># make predictions</span></span><br><span class="line">trainPredict = model.predict(trainX)</span><br><span class="line">testPredict = model.predict(testX)</span><br><span class="line"><span class="comment"># invert predictions</span></span><br><span class="line">trainPredict = scaler.inverse_transform(trainPredict)</span><br><span class="line">trainY = scaler.inverse_transform([trainY])</span><br><span class="line">testPredict = scaler.inverse_transform(testPredict)</span><br><span class="line">testY = scaler.inverse_transform([testY])</span><br><span class="line"><span class="comment"># calculate root mean squared error</span></span><br><span class="line">trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))</span><br><span class="line">print('Train Score: %.2f RMSE' % (trainScore))</span><br><span class="line">testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))</span><br><span class="line">print('Test Score: %.2f RMSE' % (testScore))</span><br></pre></td></tr></table></figure>
<p>最后，我们使用模型在训练和测试集上产生了预测值，得到了模型效果的可视化指标。</p>
<p>在以下的绘图中，蓝色是原始数据，绿色是训练集上的拟合数据，红色是在测试集上的拟合数据。</p>
<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># shift train predictions for plotting</span></span><br><span class="line">trainPredictPlot = numpy.empty_like(dataset)</span><br><span class="line"><span class="section">trainPredictPlot[:, :] = numpy.nan</span></span><br><span class="line"><span class="section">trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict</span></span><br><span class="line"><span class="comment"># shift test predictions for plotting</span></span><br><span class="line">testPredictPlot = numpy.empty_like(dataset)</span><br><span class="line"><span class="section">testPredictPlot[:, :] = numpy.nan</span></span><br><span class="line"><span class="section">testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict</span></span><br><span class="line"><span class="comment"># plot baseline and predictions</span></span><br><span class="line">plt.plot(scaler.inverse_transform(dataset))</span><br><span class="line">plt.plot(trainPredictPlot)</span><br><span class="line">plt.plot(testPredictPlot)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>我们可以看到模型在训练和测试集上都有很好的效果。</p>
<p>为了完整性，下面是例子所用的全部代码。</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># LSTM for international airline passengers problem with regression framing</span></span><br><span class="line"><span class="built_in">import</span> numpy</span><br><span class="line"><span class="built_in">import</span> matplotlib.pyplot as plt</span><br><span class="line">from pandas <span class="built_in">import</span> read_csv</span><br><span class="line"><span class="built_in">import</span> math</span><br><span class="line">from keras.models <span class="built_in">import</span> Sequential</span><br><span class="line">from keras.layers <span class="built_in">import</span> Dense</span><br><span class="line">from keras.layers <span class="built_in">import</span> LSTM</span><br><span class="line">from sklearn.preprocessing <span class="built_in">import</span> MinMaxScaler</span><br><span class="line">from sklearn.metrics <span class="built_in">import</span> mean_squared_error</span><br><span class="line"><span class="comment"># convert an array of values into a dataset matrix</span></span><br><span class="line">def create_dataset(dataset, <span class="attr">look_back=1):</span></span><br><span class="line">	dataX, <span class="attr">dataY</span> = [], []</span><br><span class="line">	for i <span class="keyword">in</span> range(len(dataset)-look_back-<span class="number">1</span>):</span><br><span class="line">		<span class="attr">a</span> = dataset[i:(i+look_back), <span class="number">0</span>]</span><br><span class="line">		dataX.append(a)</span><br><span class="line">		dataY.append(dataset[i + look_back, <span class="number">0</span>])</span><br><span class="line">	return numpy.array(dataX), numpy.array(dataY)</span><br><span class="line"><span class="comment"># fix random seed for reproducibility</span></span><br><span class="line">numpy.random.seed(<span class="number">7</span>)</span><br><span class="line"><span class="comment"># load the dataset</span></span><br><span class="line"><span class="attr">dataframe</span> = read_csv('international-airline-passengers.csv', <span class="attr">usecols=[1],</span> <span class="attr">engine='python',</span> <span class="attr">skipfooter=3)</span></span><br><span class="line"><span class="attr">dataset</span> = dataframe.values</span><br><span class="line"><span class="attr">dataset</span> = dataset.astype('float32')</span><br><span class="line"><span class="comment"># normalize the dataset</span></span><br><span class="line"><span class="attr">scaler</span> = MinMaxScaler(<span class="attr">feature_range=(0,</span> <span class="number">1</span>))</span><br><span class="line"><span class="attr">dataset</span> = scaler.fit_transform(dataset)</span><br><span class="line"><span class="comment"># split into train and test sets</span></span><br><span class="line"><span class="attr">train_size</span> = int(len(dataset) * <span class="number">0.67</span>)</span><br><span class="line"><span class="attr">test_size</span> = len(dataset) - train_size</span><br><span class="line">train, <span class="attr">test</span> = dataset[<span class="number">0</span>:train_size,:], dataset[train_size:len(dataset),:]</span><br><span class="line"><span class="comment"># reshape into X=t and Y=t+1</span></span><br><span class="line"><span class="attr">look_back</span> = <span class="number">1</span></span><br><span class="line">trainX, <span class="attr">trainY</span> = create_dataset(train, look_back)</span><br><span class="line">testX, <span class="attr">testY</span> = create_dataset(test, look_back)</span><br><span class="line"><span class="comment"># reshape input to be [samples, time steps, features]</span></span><br><span class="line"><span class="attr">trainX</span> = numpy.reshape(trainX, (trainX.shape[<span class="number">0</span>], <span class="number">1</span>, trainX.shape[<span class="number">1</span>]))</span><br><span class="line"><span class="attr">testX</span> = numpy.reshape(testX, (testX.shape[<span class="number">0</span>], <span class="number">1</span>, testX.shape[<span class="number">1</span>]))</span><br><span class="line"><span class="comment"># create and fit the LSTM network</span></span><br><span class="line"><span class="attr">model</span> = Sequential()</span><br><span class="line">model.add(LSTM(<span class="number">4</span>, <span class="attr">input_shape=(1,</span> look_back)))</span><br><span class="line">model.add(Dense(<span class="number">1</span>))</span><br><span class="line">model.compile(<span class="attr">loss='mean_squared_error',</span> <span class="attr">optimizer='adam')</span></span><br><span class="line">model.fit(trainX, trainY, <span class="attr">epochs=100,</span> <span class="attr">batch_size=1,</span> <span class="attr">verbose=2)</span></span><br><span class="line"><span class="comment"># make predictions</span></span><br><span class="line"><span class="attr">trainPredict</span> = model.predict(trainX)</span><br><span class="line"><span class="attr">testPredict</span> = model.predict(testX)</span><br><span class="line"><span class="comment"># invert predictions</span></span><br><span class="line"><span class="attr">trainPredict</span> = scaler.inverse_transform(trainPredict)</span><br><span class="line"><span class="attr">trainY</span> = scaler.inverse_transform([trainY])</span><br><span class="line"><span class="attr">testPredict</span> = scaler.inverse_transform(testPredict)</span><br><span class="line"><span class="attr">testY</span> = scaler.inverse_transform([testY])</span><br><span class="line"><span class="comment"># calculate root mean squared error</span></span><br><span class="line"><span class="attr">trainScore</span> = math.sqrt(mean_squared_error(trainY[<span class="number">0</span>], trainPredict[:,<span class="number">0</span>]))</span><br><span class="line">print('Train Score: %.<span class="number">2</span>f RMSE' % (trainScore))</span><br><span class="line"><span class="attr">testScore</span> = math.sqrt(mean_squared_error(testY[<span class="number">0</span>], testPredict[:,<span class="number">0</span>]))</span><br><span class="line">print('Test Score: %.<span class="number">2</span>f RMSE' % (testScore))</span><br><span class="line"><span class="comment"># shift train predictions for plotting</span></span><br><span class="line"><span class="attr">trainPredictPlot</span> = numpy.empty_like(dataset)</span><br><span class="line">trainPredictPlot[:, :] = numpy.nan</span><br><span class="line">trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict</span><br><span class="line"><span class="comment"># shift test predictions for plotting</span></span><br><span class="line"><span class="attr">testPredictPlot</span> = numpy.empty_like(dataset)</span><br><span class="line">testPredictPlot[:, :] = numpy.nan</span><br><span class="line">testPredictPlot[len(trainPredict)+(look_back*<span class="number">2</span>)+<span class="number">1</span>:len(dataset)-<span class="number">1</span>, :] = testPredict</span><br><span class="line"><span class="comment"># plot baseline and predictions</span></span><br><span class="line">plt.plot(scaler.inverse_transform(dataset))</span><br><span class="line">plt.plot(trainPredictPlot)</span><br><span class="line">plt.plot(testPredictPlot)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>运行例子代码会产生如下输出。</p>
<figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">Epoch 95/100</span><br><span class="line">0s - loss: 0.0020</span><br><span class="line">Epoch 96/100</span><br><span class="line">0s - loss: 0.0020</span><br><span class="line">Epoch 97/100</span><br><span class="line">0s - loss: 0.0020</span><br><span class="line">Epoch 98/100</span><br><span class="line">0s - loss: 0.0020</span><br><span class="line">Epoch 99/100</span><br><span class="line">0s - loss: 0.0020</span><br><span class="line">Epoch 100/100</span><br><span class="line">0s - loss: 0.0020</span><br><span class="line">Train Score: 22.93 RMSE</span><br><span class="line"><span class="keyword">Test </span>Score: 47.53 RMSE</span><br></pre></td></tr></table></figure>
<p>我们可以看到模型在训练集上有23个顾客作用的平均误差，在测试集上有52个顾客左右的平均误差。并不算坏。</p>
<h1 id="使用窗口方法进行lstm回归"><a href="#使用窗口方法进行lstm回归" class="headerlink" title="使用窗口方法进行lstm回归"></a>使用窗口方法进行lstm回归</h1><p>我们也可以使用过往多个时刻的数据来预测下一时刻顾客量。</p>
<p>这个叫做窗口，窗口的尺寸是需要进行调整的参数。</p>
<p>例如，给定当前时刻，我们希望预测下一时刻数据，我们可以使用当前时刻，以及上一时刻，上上时刻作为输入变量。</p>
<p>作为一个回归问题，输入变量是t-2,t-1,t，输出变量是t+1。</p>
<p>我们前面写的 create_dataset() 函数允许我们可以构造出这样形式的数据集，只需要把 look_back 参数调整为3。</p>
<p>新构造的数据集前几行如下：</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X1	X2	X3	Y</span><br><span class="line"><span class="number">112</span>	<span class="number">118</span>	<span class="number">132</span>	<span class="number">129</span></span><br><span class="line"><span class="number">118</span>	<span class="number">132</span>	<span class="number">129</span>	<span class="number">121</span></span><br><span class="line"><span class="number">132</span>	<span class="number">129</span>	<span class="number">121</span>	<span class="number">135</span></span><br><span class="line"><span class="number">129</span>	<span class="number">121</span>	<span class="number">135</span>	<span class="number">148</span></span><br><span class="line"><span class="number">121</span>	<span class="number">135</span>	<span class="number">148</span>	<span class="number">148</span></span><br></pre></td></tr></table></figure>
<p>我们可以使用这个新的窗口数据重新预测。完整代码如下，这有窗口做了改变。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># LSTM for international airline passengers problem with window regression framing</span></span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> read_csv</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> LSTM</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="comment"># convert an array of values into a dataset matrix</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_dataset</span><span class="params">(dataset, look_back=<span class="number">1</span>)</span>:</span></span><br><span class="line">	dataX, dataY = [], []</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(len(dataset)-look_back<span class="number">-1</span>):</span><br><span class="line">		a = dataset[i:(i+look_back), <span class="number">0</span>]</span><br><span class="line">		dataX.append(a)</span><br><span class="line">		dataY.append(dataset[i + look_back, <span class="number">0</span>])</span><br><span class="line">	<span class="keyword">return</span> numpy.array(dataX), numpy.array(dataY)</span><br><span class="line"><span class="comment"># fix random seed for reproducibility</span></span><br><span class="line">numpy.random.seed(<span class="number">7</span>)</span><br><span class="line"><span class="comment"># load the dataset</span></span><br><span class="line">dataframe = read_csv(<span class="string">'international-airline-passengers.csv'</span>, usecols=[<span class="number">1</span>], engine=<span class="string">'python'</span>, skipfooter=<span class="number">3</span>)</span><br><span class="line">dataset = dataframe.values</span><br><span class="line">dataset = dataset.astype(<span class="string">'float32'</span>)</span><br><span class="line"><span class="comment"># normalize the dataset</span></span><br><span class="line">scaler = MinMaxScaler(feature_range=(<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">dataset = scaler.fit_transform(dataset)</span><br><span class="line"><span class="comment"># split into train and test sets</span></span><br><span class="line">train_size = int(len(dataset) * <span class="number">0.67</span>)</span><br><span class="line">test_size = len(dataset) - train_size</span><br><span class="line">train, test = dataset[<span class="number">0</span>:train_size,:], dataset[train_size:len(dataset),:]</span><br><span class="line"><span class="comment"># reshape into X=t and Y=t+1</span></span><br><span class="line">look_back = <span class="number">3</span></span><br><span class="line">trainX, trainY = create_dataset(train, look_back)</span><br><span class="line">testX, testY = create_dataset(test, look_back)</span><br><span class="line"><span class="comment"># reshape input to be [samples, time steps, features]</span></span><br><span class="line">trainX = numpy.reshape(trainX, (trainX.shape[<span class="number">0</span>], <span class="number">1</span>, trainX.shape[<span class="number">1</span>]))</span><br><span class="line">testX = numpy.reshape(testX, (testX.shape[<span class="number">0</span>], <span class="number">1</span>, testX.shape[<span class="number">1</span>]))</span><br><span class="line"><span class="comment"># create and fit the LSTM network</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(LSTM(<span class="number">4</span>, input_shape=(<span class="number">1</span>, look_back)))</span><br><span class="line">model.add(Dense(<span class="number">1</span>))</span><br><span class="line">model.compile(loss=<span class="string">'mean_squared_error'</span>, optimizer=<span class="string">'adam'</span>)</span><br><span class="line">model.fit(trainX, trainY, epochs=<span class="number">100</span>, batch_size=<span class="number">1</span>, verbose=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># make predictions</span></span><br><span class="line">trainPredict = model.predict(trainX)</span><br><span class="line">testPredict = model.predict(testX)</span><br><span class="line"><span class="comment"># invert predictions</span></span><br><span class="line">trainPredict = scaler.inverse_transform(trainPredict)</span><br><span class="line">trainY = scaler.inverse_transform([trainY])</span><br><span class="line">testPredict = scaler.inverse_transform(testPredict)</span><br><span class="line">testY = scaler.inverse_transform([testY])</span><br><span class="line"><span class="comment"># calculate root mean squared error</span></span><br><span class="line">trainScore = math.sqrt(mean_squared_error(trainY[<span class="number">0</span>], trainPredict[:,<span class="number">0</span>]))</span><br><span class="line">print(<span class="string">'Train Score: %.2f RMSE'</span> % (trainScore))</span><br><span class="line">testScore = math.sqrt(mean_squared_error(testY[<span class="number">0</span>], testPredict[:,<span class="number">0</span>]))</span><br><span class="line">print(<span class="string">'Test Score: %.2f RMSE'</span> % (testScore))</span><br><span class="line"><span class="comment"># shift train predictions for plotting</span></span><br><span class="line">trainPredictPlot = numpy.empty_like(dataset)</span><br><span class="line">trainPredictPlot[:, :] = numpy.nan</span><br><span class="line">trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict</span><br><span class="line"><span class="comment"># shift test predictions for plotting</span></span><br><span class="line">testPredictPlot = numpy.empty_like(dataset)</span><br><span class="line">testPredictPlot[:, :] = numpy.nan</span><br><span class="line">testPredictPlot[len(trainPredict)+(look_back*<span class="number">2</span>)+<span class="number">1</span>:len(dataset)<span class="number">-1</span>, :] = testPredict</span><br><span class="line"><span class="comment"># plot baseline and predictions</span></span><br><span class="line">plt.plot(scaler.inverse_transform(dataset))</span><br><span class="line">plt.plot(trainPredictPlot)</span><br><span class="line">plt.plot(testPredictPlot)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h1 id="使用time-steps进行lstm回归"><a href="#使用time-steps进行lstm回归" class="headerlink" title="使用time steps进行lstm回归"></a>使用time steps进行lstm回归</h1>
          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/pansee/book review/《娱乐至死》/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/pansee/book review/《娱乐至死》/" class="post-title-link" itemprop="url">《娱乐至死》</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/book-review/" itemprop="url" rel="index"><span itemprop="name">book review</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="总评"><a href="#总评" class="headerlink" title="总评"></a>总评</h1><p>本书所论述的乃是电视时代对于印刷术时代的冲击。是支离破碎的话语结构对于严肃逻辑话语结构的冲击。作者认为支离破碎的话语结构将会使得生活娱乐化，思想娱乐化。更确切的说，只剩下娱乐，而无生活和思想。</p>
<p>然而，窃以为虽然该书很好的抓住了话语结构的转变，以及价值倾向上的转变。但是对其逻辑实难认可。</p>
<ol>
<li><p>作者在论述上列举了大量的例子来说明印刷术时代民众的严肃性以及与之形成强烈对比的电视时代的娱乐性。但是，首先举例子从来都没法证明逻辑或观点，至多不过是增强读者对其所欲证明观点的理解罢了。而该书缺乏足够的逻辑论证，甚为遗憾。其次，其所举例子的偏向性实在太过明显，不得不让人怀疑其客观性。</p>
</li>
<li><p>表面的因果并不一定是真实的因果。这个问题在统计学中有一个专有名词“伪回归”。也就是说，娱乐化表面上看起来是随着电视而发展的，但或许这只是表面而已。我个人更认为娱乐化不过是一个典型的“饱暖思淫欲”的过程。同时，难道电视时代之前娱乐就不像现下这样嚣张了么？只是缺少传播媒介，娱乐只是在小范围内形成。而现下借助于网络形成了一个足以引起大范围共鸣的娱乐形式，使得娱乐可以触及生活的边边角角并被推波助澜而已。</p>
</li>
<li><p>作者并没有掺杂过多的个人观点，而是希望安静的描述事实。这个动机至少是值得赞扬的，尽管无可避免的带来了一定事实上我认为是相当程度的误导性。很克制的没有在明面上作出自己的猜想和推断，让读者自己去感受“部分事实”。</p>
</li>
<li><p>印刷术时代真的有想像的那么美好么？这样的美好即使存在，也很难归因于书面话语结构。印刷初期的高昂成本以及他所面对的精英受众都使得娱乐很难出现。至于书本如果能够在底层传播，那也相对部分是由国家公权力或者教会这样的庞大势力所推动的。一旦大众有更多的自由选择权利，一旦印刷成本降低，读书认字不再成为精英特权，书本的庸俗化是可以想见的，并且已经被今天的社会所证明，一如大半个书架的言情，玄幻，以及各种以文字修辞和精美修饰包之以文艺外衣来进行推销的娱乐读物。部分所谓“文青”亦如是。但是不可否认的，相较于书面话语结构，电视这样的影像结构更加容易使人娱乐并诱人娱乐。</p>
</li>
<li><p>影像结构具有哪些好处呢？书本的表现力是很受限制的。直接的视觉冲击和听觉冲击至少在某些方面是要远远强于书本的。作者却对此几乎不提，实在偏颇。纵然“隐晦”的提了，比如在论述教育娱乐化时所举的鲸鱼习性录制的例子，竟然还要以成本高昂作为批评。虽然成本过高会带来商业化偏向，但至少影像结构本身的价值是显而易见的。另外，真理不等于逻辑。有很多美好的东西是不依赖于逻辑的。同样，作者对于印刷术时代的回忆更多的在于民众对于公共事务的热衷。很遗憾的，这并不是生活的全部。又将诗歌音乐等至于何地呢？作者更多的使用了线性结构一词来描述印刷术时代的话语结构特点。我以为这是不恰当的。至少我们可以看到《尤利西斯》等作品对于线性结构的突破。当然，或许作者看到的确乎只有线性结构，诗歌音乐等在他看来其实并不比电视好多少。不知是否确乎如此，似乎书中对此是暗含批评态度的。好像一个严肃的人的生活，就只能是关心身边的事，积极参与公共事务一样。</p>
</li>
<li><p>影像结构的高成本带来的盈利诉求以及其受众广泛的潜在可能性带来的资本涌入，导致了娱乐化。实际上，对于前者而言，现下独立电影的成本已经很低了，并不构成盈利诉求。资本涌入已经成了影像结构娱乐化最主要的根源。那么，到了这里我们是否可以说，真正导致娱乐化的不是电视，而是资本呢！只是电视的形式能够更好的实现商业盈利目的，从而成为资本重点关注的对象。</p>
</li>
<li><p>电视为何会构成一个支离破碎，缺少上下文的话语结构？作者对此的批评至少有以下两个方面：电视节目着力于场景的呈现与感受，而不是严密的逻辑语辞;为了吸引受众而降低门槛，节目片段之间也保持相对独立性，不再完整。对于前者，我觉得这恰恰是影像结构的优势。不是通过枯燥而又不一定站的住脚的逻辑，而是通过感同身受的生活场景的呈现来打动你，引起共鸣，这实在是没有什么非说不可的坏处吧？至于后者，难道不是古以有之么？要不然哪里来的“且听下文分解”？更何况，就完整的一个电视节目而言，纵然被切分成了很多小块，也不至于彻底的不需要依赖上下文吧？同样，一个可以得到赞同的电视节目，也不可能只是毫无逻辑和中心的梦人呓语吧？至于如果有人想要拿电视节目的深度说事，那么我只能说印刷物中的垃圾作品也实在不少。</p>
</li>
<li><p>电视时代真正的威胁应当是以下两点。一是信息过剩与信息不足之下的麻木，更确切的说，一方面将过剩信息当作思想而不再需要思考，一方面被过剩的信息淹没，进一步忽略了个人生活本身。同样也是因为信息源源不断的汹涌而来，才导致了话语结构的碎片化。因为信息太多，已经无法驻足停留了。另一方面，为了迎合大众而进行信息的扭曲和重塑，使得问题本身被掩盖，真实被表演所替代。人可以在自己虚幻的城堡里醉生梦死。只是，如果这个梦可以一直持续，又为什么需要醒来呢？更何况，一个可以一直持续的梦是梦还是真实？其实可以构建一个风险博弈模型来看看是否有醒来的必要，此处不做引申。</p>
</li>
<li><p>这里有一个重要的问题需要讨论。借用作者的话，“媒介构成了真理的一部分”。当真如此么？以电视为代表的技术，资本，价值三者的关系是怎样的呢？技术暂且放到一边吧，至少我不相信有什么技术一被发明出来就带上了恶的属性。那么，资本有没有可能凭空创造一种恶的价值呢？我是不大相信的，但我相信撒旦可以引导出人性恶的部分并加以放大直至完全侵蚀。请注意，我对资本不报恶意，这仅仅是一个不甚恰当的比方罢了！人是软弱的，不堪诱惑。然而，如果因此要归罪于技术或者资本就未免卑劣了。</p>
</li>
<li><p>最后，我不得不说，作者或许无形之中接近了《一九八四》的文化专制。漠视普通大众的诉求，对娱乐嗤之以鼻，高举精英主义文化的大旗。不难猜想，如果所谓正统学人窃居高位，自以为掌握了文化精髓，随着而来只能是文化专制。大众话语权的增长应该是件好事。当然我们更应该努力的乃是大众意识的觉醒。否则很容易沦为暴民政治，庸俗文化。不管是否精英主义者，不管是否相信民众可以教化，至少对于娱乐对于大众应当抱有更多的宽容。</p>
</li>
</ol>
<p>最后，不要消费苦难！能够躺着赚钱，为什么要去风吹日晒。对于娱乐，对于金钱嗤之以鼻，实在不能彰显思想者的格调！</p>
<h1 id="第一章-媒介即隐喻"><a href="#第一章-媒介即隐喻" class="headerlink" title="第一章 媒介即隐喻"></a>第一章 媒介即隐喻</h1><p>18世纪后期——波士顿——独立战争的序幕——民兵雕像</p>
<p>19世纪中叶——纽约——大熔炉式国家——自由女神像</p>
<p>20世纪早期——芝加哥——工业发展中心——屠夫雕像</p>
<p>20世纪后期——拉斯维加斯——娱乐之城——老虎机图片和歌舞女演员</p>
<blockquote>
<p>以总统竞选举例，智慧让位于化妆术。</p>
</blockquote>
<p>今日之境况同样如此。颜值已经堂而皇之的成为一种资产和凭证，遍布于职业选择，婚姻嫁娶，公众舆论方方面面，不论是否合宜或有必要。</p>
<blockquote>
<p>与其说经济学是一门学科，还不如说它是一种表演艺术  </p>
</blockquote>
<p>广告和外包装虽然可以部分解决信息不对称的问题，但现下确实更多的只是奇技淫巧，而没有花更多精力去提升产品质量本身。真是囚凸困境啊。大数据，共享单车的创投也是如此。</p>
<blockquote>
<p>宗教和学术也以取悦人为目的</p>
</blockquote>
<p>高校的娱乐化，阅读的低俗化，文青化何尝不是，部分所谓心理学之幼稚可笑空谈感受自不必谈。</p>
<blockquote>
<p>媒介即信息……某个文化中交流的媒介对于这个文化精神重心和物质重心的形成有着决定性的影响</p>
</blockquote>
<p>明确的指出了交流形式对于交流内容的反制。</p>
<blockquote>
<p>虽然文化是语言的产物，但是每一种媒介都会对它进行再创造</p>
</blockquote>
<p>文化真的只是语言的产物么？我承认语言或者其他交流媒介对于文化的形成有影响，但我很难接受文化内容本身完全受制于媒介。应当存在更为根本的决定性的东西才对。</p>
<h1 id="第二章-媒介即认识论"><a href="#第二章-媒介即认识论" class="headerlink" title="第二章 媒介即认识论"></a>第二章 媒介即认识论</h1><blockquote>
<p>我们衡量一种文化，是要看其中自认为重要的东西，而不是看那些毫无伪装的琐碎小事</p>
</blockquote>
<p>我们读书，也应当是汲取书中精华，而不是把时间浪费在对着书中的错误大加批判。当然，如果一本书，或者一个人他所带来的负面影响极为严重不可规避，那么也只好不要为了所谓精华而去接近了。进步的机会很多，而堕落只在于瞬间。</p>
<blockquote>
<p>任何一种媒介都有共鸣，因为共鸣就是扩大的隐喻。不管一种媒介原来的语境是怎样的，他都有能力越过这个语境并延伸到新的未知的语境中。</p>
</blockquote>
<blockquote>
<p>对于真理的认识是同表达方式密切相联的。真理不能、也从来没有，毫无修饰地存在。它必须穿着某种合适的外衣出现，否则就可能得不到承认，这也正说明了”真理“是一种文化偏见。</p>
</blockquote>
<p>认识论的发展：</p>
<p>神话宗教语言——科学语言</p>
<p>逻辑推理——回归事实</p>
<p>谚语俗语——书面语言</p>
<p>印刷术——电视</p>
<blockquote>
<p>任何认识论都是某个媒介发展阶段的认识论</p>
</blockquote>
<h1 id="第三章-印刷机统治下的美国"><a href="#第三章-印刷机统治下的美国" class="headerlink" title="第三章 印刷机统治下的美国"></a>第三章 印刷机统治下的美国</h1><blockquote>
<p>不可记录汝等之教义，更不可将其印刷成文，否则汝等将永远受其束缚</p>
</blockquote>
<blockquote>
<p>这种情形的造成只有一部分是受新教传统的影响……美国是一个由知识分子建立的国家，这在现代历史上是罕见的<br>新教传统的影响体现在哪里？真的只有一部分么？</p>
</blockquote>
<p>本章主要叙述了美国初期的人员构成，大部分都是知识分子或者具有阅读习惯的人。</p>
<h1 id="第四章-印刷机统治下的思想"><a href="#第四章-印刷机统治下的思想" class="headerlink" title="第四章 印刷机统治下的思想"></a>第四章 印刷机统治下的思想</h1><p>”阐释年代“——”娱乐业时代“</p>
<p>本章则是通过实例描绘了初期美国人民的真实生活境况，方便进一步论述其观点。</p>
<h1 id="第五章-躲躲猫的世界"><a href="#第五章-躲躲猫的世界" class="headerlink" title="第五章 躲躲猫的世界"></a>第五章 躲躲猫的世界</h1><p>或许可以从信息获取难易的角度去分析这一转变。人倾向于闲谈放松，只是过往难以获得谈资，只好严肃阅读？同样也因为精英阶层衰弱，平民庸俗文化兴起，使得娱乐大行其道。</p>
<p>美国初期的人口结构或许是知识分子占大多数，但随着后期移民，兼容土著，人口繁衍，这样的人口结构显然会发生变化。因此阐释年代的消亡或许是必然的。或者说阐释年代本来就只可以存在于小部分精英知识分子中间，对于占据社会大部分的工农阶层或许从来就没有过阐释年代。一如古中国一边是记录在案的谈笑有鸿儒，一边是隐匿消失却占据大部分的汗滴禾下土。</p>
<blockquote>
<p>有一些媒介，例如电影，从本质上就具有这样的潜能。</p>
</blockquote>
<p>窃以为作者对于摄影，电影等的认知存在偏差。“电影将人的生命延长了十倍”，我们有什么理由不通过他人的著述，经历去吸取经验教训，从而使得自己能够更高效的生活思考？当然，无可否认的，相较于少量的优秀电影作品，更多的是大量的娱乐电影而已。然而，这并不由电影这一媒介所决定。事实上，即使是印刷书籍不也明显的是如此的优劣比例分配么。至于过往时代，书籍大多优质，不过是因为书籍的写作权被掌控在精英阶层手上而已。拜偶像，著书立说真正带来的坏影响更本不是影响上帝教义，受印刷物之束缚。而是在这一过程之中，上帝的神圣话语权会被破坏！而现下，任何一个人都可以去写作，则是人本的另一极端。甚至于一个人竟然可以狂妄谈论涉及一个他完全缺乏知识的领域，也就是所谓民哲所为。这样的庸俗个人主义又将让社会走向何方呢？</p>
<p>我完全不能认同作者的根本前提与立意。我严重质疑作者犯了类似于幸存者偏差的错误！选择作为特例的美国来进行论述从一开始就是不合宜的！</p>
<p>即使回过头来看作者自己所举的初期美国民众热衷听演讲参与社会事务的例子，我也不经要怀疑那些民众当真不怀抱着一种娱乐的目的么？这叫好像学生热烈的考证难道真的是怀抱着一种学术的或者求知的目的么？</p>
<h1 id="第六章-娱乐业时代"><a href="#第六章-娱乐业时代" class="headerlink" title="第六章 娱乐业时代"></a>第六章 娱乐业时代</h1><blockquote>
<p>印刷术从来没有被专用于、或大量用于复制图像</p>
</blockquote>
<p>初期印刷术有用于复制图像的能力么？即使有能力，难道有复制图像的需求么？我完全接受印刷术是为了书面文字服务的，但应当是有需求推进技术革新，而不是相反！需求是本来就有的！</p>
<blockquote>
<p>我们的问题不在于电视为我们展示具有娱乐性的内容，而在于所有的内容都以娱乐的方式表现出来，这就完全是另一回事了。</p>
</blockquote>
<p>并不是所有的内容吧？难道初期就没有纪录片？没有好电影？深感作者看问题缺乏公正。</p>
<blockquote>
<p>播音员也会对观众说“明天用一时间再见”。为什么要再见？照理说，几分钟的屠杀和灾难应该会让我们整整一个月难以入眠，但现在我们却接受了播音员的邀请，因为我们知道“新闻”是不必当真的，是说着玩的。</p>
</blockquote>
<p>这倒是很有意思，值得细思。</p>
<blockquote>
<p>我们从来没有听说过，一种媒介的表现形式可以和这种媒介本身的倾向相对抗。</p>
</blockquote>
<p>我依旧无法理解，作者是如何论证出电视的娱乐倾向的。</p>
<h1 id="第七章-“好……现在“"><a href="#第七章-“好……现在“" class="headerlink" title="第七章 “好……现在“"></a>第七章 “好……现在“</h1><blockquote>
<p>它已经成为当今美国公众话语支离破碎的一种象征。</p>
</blockquote>
<p>支离破碎，很关键的一个词，对于此书的理解。</p>
<blockquote>
<p>难道电视为了迎合观众的喜好可以是非不分吗？</p>
</blockquote>
<p>当然不至于是非不分，但至少为了迎合观众换掉一个播演员真的没有其合理性么？可以展开思考。</p>
<blockquote>
<p>电视告诉杂志”新闻是一种娱乐“，杂志转而告诉电视”只有娱乐才是新闻“</p>
</blockquote>
<p>难道严肃印刷物的娱乐化也要怪罪与电视，或者怪罪于印刷这一媒介么？显然作者的观点站不住脚。</p>
<blockquote>
<p>广播本身的特点使它非常适合传播理性而复杂的语言</p>
</blockquote>
<p>没感觉，我觉得同时调动视觉和听觉从而可以看到肢体语言听到口头语言的电视更可以传播复杂语言。</p>
<blockquote>
<p>但历史从来没有证明过，一个自认为可以在22分钟内评价整个世界的文化还会有生存的能力。除非，新闻的价值取决于它能带来多少笑声。</p>
</blockquote>
<p>现在不就证明给你看了么？有为何要视而不见，过度修正？而不是直面问题？</p>
<h1 id="第八章-走向伯利恒"><a href="#第八章-走向伯利恒" class="headerlink" title="第八章 走向伯利恒"></a>第八章 走向伯利恒</h1><p>电视的魔力使信徒不堪诱惑，走向撒旦。然而并非只有电视是撒旦的代表而已。</p>
<h1 id="第九章-伸出你的手投上一票"><a href="#第九章-伸出你的手投上一票" class="headerlink" title="第九章 伸出你的手投上一票"></a>第九章 伸出你的手投上一票</h1><blockquote>
<p>如果政治真的像娱乐业，那么它的目的就不是追求一目了然、公正诚实和超越平凡，而是要做到看上去像这样。</p>
</blockquote>
<blockquote>
<p>电视广告把企业从哦你生产有价值的产品引向了设法使消费者感觉产品有价值，这意味着企业的业务已经成为一种伪疗法，消费者成了信赖心里表演疗法的病人。</p>
</blockquote>
<p>价值和使用价值的关系貌似并不是资本主义的问题。就使用价值而言，如果真的能够让消费者感到有价值，那么就足够了，并不能说就是伪疗法。那是更深一层的价值取向的问题。</p>
<blockquote>
<p>在这些广告里，他运用了类似麦当劳广告的视觉手段把自己表现成一个经验丰富、正直虔诚的人。</p>
</blockquote>
<blockquote>
<p>那些想当上帝的人把自己塑造成观众期望的形象。</p>
</blockquote>
<blockquote>
<p>在一个本身结构就是偏向图像和片段的媒介里，我们注定要丧失历史的视角。</p>
</blockquote>
<blockquote>
<p>公司国家通过电视控制了美国公众话语的流动。……我们要担心的是电视信息的过剩，而不是政府的限制……（公司国家：认为国家是一台巨大的机器，完全不受人的控制并置人的价值于不顾）</p>
</blockquote>
<blockquote>
<p>她想尽一切办法使信息变得没有内容、没有历史、没有语境，也就是说，信息被包装成为娱乐。</p>
</blockquote>
<h1 id="第十章-教学是一种娱乐活动"><a href="#第十章-教学是一种娱乐活动" class="headerlink" title="第十章 教学是一种娱乐活动"></a>第十章 教学是一种娱乐活动</h1><blockquote>
<p>电视对教育哲学的主要贡献是它提出了教学和娱乐不可分的理念。</p>
</blockquote>
<p>不是不可分，而是可以在娱乐中学。</p>
<blockquote>
<p>获得知识是一件困难的事情……教育的目的是让学生们摆脱现实的奴役，而现在的年轻人正竭力作着相反的努力——为了适应现实而改变自己</p>
</blockquote>
<p>算不上适应现实，人本性难道会自找苦吃么？电视教育提供了虚假的捷径？培训班也是相同？</p>
<p>将电视教育一棒子打死，论证有偏。</p>
<blockquote>
<p>在观看了两个30s长的商业电视节目和广告之后，只有3.5%的观众可以正确回答和节目相关的12个判断对错的问题。</p>
</blockquote>
<p>难道看书正确率就会提高？作者误导性论证太过！再者，总长60s，是如何设计出12个问题的？或者说这12个问题是不是过于细节刁难？<br>再者，印刷和电视作为两种不同媒介，怎么能够这样直接对比？何况还是拿广告和书籍对比？那么不妨换一种对比媒介，网络新闻或者其他类似印刷物。<br>不可否认，传统纸质书籍确实需要凝神细看，强调注意力，但是又有多少人看的下去？它的使用门槛带来的坏处就可以无视么？电视本来就不是作为印刷书的替代品而存在的！至于在电视出现之后，印刷书式微，难道不是因为它自己的缺陷原因？</p>
<blockquote>
<p>为什么“鲸鱼和它们的生活环境”会成为一个如此有趣的话题，值得人们花上一整年的时间来制作这个节目？……盲目而无形地花掉了365万美元……但这些他们也完全可以通过其他途径获得。最重要的的是，他们知道了学习是一种娱乐方式</p>
</blockquote>
<p>好吧，作者开始抨击动物世界了？请问有多少人看书也不过就是抱着这样的获取生活中用不到的知识的目的呢？为何对此你却不加批判？<br>何况有的情况下视频图像比印刷有好的多的教学效果，就比如对于鲸鱼的习性，海上航行。</p>
<p>电视的出现难道不是科技进步解决人类需求？就好像电话使得写信不再需要。于是乎有人站出来说丢失了写信的诗意。然而事实上呢？对于写信的漫长回复不加批评。对于写信的门槛漠视。更何况，又有几个人能写的出来明月几时有，把酒问青天？大部分还不是落于家常俗套？根源根本不再电视好么！</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/pansee/book review/《浪潮之巅》/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/pansee/book review/《浪潮之巅》/" class="post-title-link" itemprop="url">《浪潮之巅》</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/book-review/" itemprop="url" rel="index"><span itemprop="name">book review</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>《浪潮之巅》——作者：吴军</p>
<h1 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h1><p>正如我第一次知道作为业界成功人士的李开复竟然是语音识别的顶级科学家一样，当我看完《浪潮之巅》，不得不惊叹一个计算机领域的工程师竟然对企业管理与运作有如此深刻的洞察。更何况，书中还展露出吴军博士对经济、金融的理解、对历史（对欧洲封建社会变革的论述）、人文（对海明威作品的引用）领域的熟悉。最为难能可贵的是，这些知识与思考是如此自然的流于笔端，无比的真实与贴近生活。而不是生硬机械的硬搬概念、强行关联，刻意堆砌。</p>
<p>读书何为？难道是为了知道一些高大上的概念然后到人前炫耀么？以此来展现自己的博学多才而收获仰慕之眼光？写作何为？难道是为了词藻华丽，为了用一堆似是而非的引用和例子，配合上貌似气势高昂的排比修辞来揭示空中浮萍般的可笑“真理”？交流何为？难道是为了用空洞而无根底的言辞，空想而无逻辑的语言来交流思想？</p>
<p>那么，读《浪潮之巅》又有什么意义？</p>
<p>事实上，对于类似形式的书目，即书写一个恢宏大世或者一个领域思想，每一个章节通过聊聊几十页就妄图说清楚其中一个思想流派这样的概述书我是相当抵制的。这就好像以亚当斯密为代表的古典经济学到了最后只剩下看不见的手五个字，看起来精简概括，实则丢掉了太多细节，甚至于引入了谬误。如此书目往往只能从中学到概念，而对其真正的思维过程一无所知。当然，借这样的书来先行建立一个整体框架和概念有利于后期深入研究倒是尚有可取之处，可惜大部分人的所谓“研究”也就止步于这样的概述了。</p>
<p>但《浪潮之巅》不同，或许书本身就并不是想要向读者说清每家科技公司的盛衰兴亡，而是用各家公司的发展与衰落来说明一场场浪潮的发展趋势，并从中抽离出共性，“世界上失败者的失败各有各的不同，而成功者的成功却具有惊人的相似之处”。其实，失败者的病痛也往往相似。</p>
<p>然而，我依旧不建议不在科技行业之内或者对计算机科技不敢兴趣的读者给予此书过高的阅读优先级。跨领域的阅读往往痛苦，而一本书如果不能感同身受或者怀有极大的兴趣，读完之后不过束之高阁，了不起作为茶余饭后无意义的谈资。至于所谓广度的延展与知识的积累，恕我偏狭之眼光，很多人收获的只有肤浅。广度当然很重要，可以开阔视野和思路，但其只应该作为一种补充。如果一个人连在一个特定领域的深度都没有，不过一事无成，又有什么资格谈思想之丰满。科幻小说本该带来对于宇宙的敬畏，有人反而从中读出了量子力学，岂不可笑。</p>
<p>回归本书，我并不做管理，很难在具体的企业运作细节上有太大的感触。但也简单总结下。</p>
<p>成功或者失败大体出于以下几点：</p>
<ul>
<li>是否顺应潮流，把握机遇</li>
<li>是否能够平衡长短期利益、公司股东利益。克制贪婪，甚至于短期让利</li>
<li>是否有优秀的管理层和领导者</li>
<li>是否具有技术优势，以及找到合适的商业模式</li>
</ul>
<p>最后，想要屹立不倒还需要做到：</p>
<ul>
<li>有坚实的”群众基础“，或者说营收不依赖于泡沫。</li>
<li>扬弃。一方面不断创新，不断寻找新的增长点;另一方面对于旧的不再盈利或者江河日下的部门需要果断处理。避免机构冗余和旧体制妨碍新部门的发展。</li>
</ul>
<p>对于不是创业者的我而言，以上诸点或许除了知道之外很难有进一步的作用，也很难真正知道其中痛点。</p>
<p>那么，本书对我更为真实的意义在哪里呢？</p>
<ol>
<li><p>让我对近百年来对科技发展（主要是计算机领域）有了一个相对清晰的认识，从最初的有线电话到PC到互联网再到云计算的脉络有了一定了解。</p>
</li>
<li><p>书中展示了一个个科技公司的发展兴衰。</p>
</li>
</ol>
<p>如此一来，至少在找工作时不至于被各种打着大数据、人工智能名号的创业公司忽悠，能够自身对于公司业务的靠谱性有一个评判。再者，可以一定程度上培养科技、商业、业务上的嗅觉，还可以和面试官扯淡，以此来加点分。</p>
<p>我无意于将贪婪、平衡、稳健这些公司或成或败的因素与个人生活相结合，以便于长篇大论，各种感触深刻。这些东西其实早已知道，然而翻来覆去也不曾有所大的改变。</p>
<p>正如尼采的强力意志或者海德格尔的存在主义，如果仅仅是归纳成那么两三句话，就会发现其实有太多的人早已有相似想法。可惜的是，尼采和海德格尔终究都只有一个。真正高贵而丰满的东西显然不会只是犀利深刻的那么几句话。回归细节和真实，才是真正的困难也是真正的珠宝。正如苹果的每一款产品都并非完全的原创，但它做到了极致，并从中产生了独属于它的亮点和创新。虽然我完全不看好苹果软硬件一体的封闭式发展。</p>
<p>本书中揭示的另一个现象也让我惊诧。复杂指令集打败了更先进的精简指令集，DOS通过持久战坚持到了windows的出现。这样两个以弱胜强的案例乍看起来无法理解，其实是充分利用用户依赖或者说”群众基础“所营造的的商业优势来打败技术优势。但更基本的前提应当是：”够用“。厂家是否应该花精力去制造更先进的产品，消费者是否应该去追求过剩的性能？当一个对于产品的公正统一而客观的标准丧失，市场又可以相对轻易的进入时，只好通过各种性能指标或其他来进行质量宣示，营造壁垒，很多时候门槛的存在不再是追求良币，而是为了排除劣币。这不仅体现在商品市场，还体现在人才市场的学历门槛以及其他。</p>
<p>思科支持雇员创业并回购的管理与创新模式实在精彩。华为曾经也尝试发动高管和干部自立门户，进行创新，然而最后却是勾心斗角，反目成仇。何以如此？</p>
<p>雅虎虽然没有什么技术上的革新与贡献，但是杨致远和菲洛所开创的互联网免费模式却足以让他们英明不朽。</p>
<p>斯坦福的校园文化亦让我心向往之。确切的说，我所向往的是洪堡式的研究型教育和纽曼式的大行之道（学生间的交流学习）的结合。然而，如何真正有益的交流而不沦为聚众扯淡实在很难，当然最容易的做就是找靠谱的人。</p>
<p>那么，这本书是否对得起我所花去的阅读时间呢？以及什么样的书才是值得读的好书呢？</p>
<p>其实，很多情况下，与其谈怎么利用时间，不如想办法不浪费时间更为实在。所以，与其谈什么书值得花时间去读，不如少读点毫无价值的书，少做些毫无价值的事。也就是争取机会成本最小化而已。</p>
<h1 id="第一章-帝国的余晖——AT-amp-T公司"><a href="#第一章-帝国的余晖——AT-amp-T公司" class="headerlink" title="第一章 帝国的余晖——AT&amp;T公司"></a>第一章 帝国的余晖——AT&amp;T公司</h1><p>由发明电话的贝尔所创立，传统电话通信行业的巨头。贝尔实验室的拥有者。</p>
<p>没有被美国反垄断法所打败，却死于贪婪。为了获得资本运作所产生的短期既得利益，多次进行拆分，导致拆分后的各个公司无法共享资金和技术优势，最终死亡。</p>
<p>反垄断法诉讼也导致了AT&amp;T的拆分，但是那更多的是修剪枝干，使得公司管理组织结构更合理而不臃肿。但是其自行拆分导致资金和技术的分离使其无法保有并发展其创新优势却是致命的。最终被互联网浪潮所吞没。</p>
<h1 id="第二章-蓝色巨人——IBM公司"><a href="#第二章-蓝色巨人——IBM公司" class="headerlink" title="第二章 蓝色巨人——IBM公司"></a>第二章 蓝色巨人——IBM公司</h1><p>紧紧抓住了大型政企客户。</p>
<p>小沃森抓住了时代的潮流，领导了电子技术革命的浪潮。将计算机从政府部门和军方推广到民间。将它的功能由科学计算变成商用。</p>
<p>没有能够重视PC市场。当微机性能不断提升开始危险大型计算机时，IBM在80年代末出现了第一次严重亏损，有史以来第一次开始大规模裁员。原因主要有三个：</p>
<ol>
<li>由于开始阶段微机利润远远无法和IBM传统的大型机市场相比（第一年pc营业额只占IBM总营业额1%）,因此没有上升到战略高度</li>
<li>反垄断的限制，使得其他小公司可以比较容易的入场竞争</li>
<li>盖茨的长远眼光。不管是以版权费的方式卖DOS（从每台PC中收取版权费而非一次性卖断）还是独立开发windows（而非和IBM合作研发）都是明智之举，尤其是前者</li>
</ol>
<p>危机时刻郭士纳的救场：</p>
<ol>
<li>裁掉冗余部门和毫无前途的项目以节流</li>
<li>变卖一些资产获取资金以开源</li>
<li>买回曾经分离出去的服务公司，将硬件制造，软件开发，服务合成一体</li>
<li>公司内部引入竞争机制，将员工退休金和整个公司（以前是和部门）效益挂钩，从而加强部门间合作</li>
<li>削减研发经费，砍掉一些偏理论而无效益的研究，将研究和开发结合起来。研究人员的部分工资直接和产品项目挂钩</li>
<li>为了弥补由此带来的长线研究和基础研究方面的损失，加强了和大学的合作</li>
</ol>
<p>IBM将用户群定位为企业级客户，最终放弃了终端消费市场。IBM实验室不断创新，但是在产品与市场上相当保守，创新更多的是一种自我保护而非开拓。</p>
<p>为什么IBM能够在2000年后的两次金融危机中屹立不倒？</p>
<ol>
<li>核心业务是IT服务业，和金融关系不大。即使其企业终止产品采购，对已有产品的服务需求依旧存在</li>
<li>由于其内部不断的优胜劣汰，不断淘汰低利润服务，使得其毛利润一直很高。虽然存在机构臃肿，但是危机时裁员并不会影响公司运转。更进一步的，工作岗位开始永久性向印度转移，降低人力成本</li>
<li>全球化背景下跨国公司抗打击能力提升</li>
</ol>
<p>保守和谨慎是其鲜明特质。</p>
<h1 id="第三章-“水果”公司的复兴——乔布斯和苹果公司"><a href="#第三章-“水果”公司的复兴——乔布斯和苹果公司" class="headerlink" title="第三章 “水果”公司的复兴——乔布斯和苹果公司"></a>第三章 “水果”公司的复兴——乔布斯和苹果公司</h1><blockquote>
<p>公平的讲，现在苹果的每一款产品都并非它的原创……但是，苹果把每一款产都做到了极致，这很大程度上是乔布斯达到了一个将技术和艺术结合的炉火纯青的境界……如果要问什么是创新，这就是创新！</p>
</blockquote>
<blockquote>
<p>乔布斯送给年轻人两句话：永远渴望、大智若愚（Stay Huntry，Stay Foolish）</p>
</blockquote>
<p>无中生有的创新太难，能把已有的东西做好就已经领先于人。</p>
<h1 id="第四章-计算机工业的生态链"><a href="#第四章-计算机工业的生态链" class="headerlink" title="第四章 计算机工业的生态链"></a>第四章 计算机工业的生态链</h1><ul>
<li><p>摩尔定律：每18个月硬件性能翻一番或者说旧产品价格降低一半，远超传统行业的更新速度</p>
</li>
<li><p>安迪-比尔定律：软件更新把硬件提升带来的好处几乎全部占光了</p>
</li>
<li><p>反摩尔定律：每18个月，同样产品营业额要降一半。因此逼着硬件设备公司必须赶上摩尔定律规定的的更新速度。由于过不了多少年，量变潜力就会被挖掘光，因此为了跟上摩尔定律的更新速度还需要质变。反摩尔定律使得新兴小公司有希望和大公司站在同一起跑线上。创新更容易被迅速接受，赢得市场。</p>
</li>
</ul>
<p>IT行业，犹如逆水行舟，不进则退。处于上游的是软件和IT服务业，下游才是硬件和半导体。而非相反！</p>
<h1 id="第五章-奔腾的芯——英特尔公司"><a href="#第五章-奔腾的芯——英特尔公司" class="headerlink" title="第五章 奔腾的芯——英特尔公司"></a>第五章 奔腾的芯——英特尔公司</h1><p>专心只作一件产品，这样的孤注一掷让它在微机处理器上不断进步</p>
<p>市场依赖和市场选择让intel没有被RISC的高性能所迷惑，也最终让处于性能劣势的复杂指令集打败了精简指令集</p>
<p>没有新的增长点将会让它在新的浪潮中老去</p>
<h1 id="第六章-IT领域的罗马帝国——微软公司"><a href="#第六章-IT领域的罗马帝国——微软公司" class="headerlink" title="第六章 IT领域的罗马帝国——微软公司"></a>第六章 IT领域的罗马帝国——微软公司</h1><p>DOS对苹果和IBM OS/2的胜利，为windows的诞生赢得了时间，又是利用市场依赖以弱胜强。单单技术的先进并不是决定性的。<strong>利用人民的力量和市场的依赖却导致先进的技术难以快速普及，这实在是一个有趣的现象，值得深思。</strong></p>
<p>苹果在兼容性上的失误，选择了封闭式发展，导致更新换代软硬件的成本巨大。</p>
<p>同时，苹果在一定程度上违反了信息领域的摩尔定律和安迪比尔定律。软硬件全部抓在手上，导致很难平衡硬件和软件的研发速度。选择性舍弃反而会铸就更大的成功。</p>
<p>微软的成功：</p>
<ol>
<li>保守和冒险的平衡;</li>
<li>心比天高却又脚踏实地。</li>
</ol>
<p>在互联网和浏览器窗口上的战略失误。</p>
<p>在家庭娱乐中心战场的失利。</p>
<h1 id="第七章-互联网的金门大桥——思科公司"><a href="#第七章-互联网的金门大桥——思科公司" class="headerlink" title="第七章 互联网的金门大桥——思科公司"></a>第七章 互联网的金门大桥——思科公司</h1><p>合适时间点出现的多协议路由器从一开始就获得了市场优势。</p>
<p>开明的内部管理模式：提供投资让员工创业在回购，垄断了技术市场。</p>
<p>诺威格定律：当一家公司的市占率超过50%，就不要指望在市场占有率上翻番了。寻找新的增长点——家庭娱乐。</p>
<h1 id="第八章-英明不朽——杨致远、菲洛和雅虎公司"><a href="#第八章-英明不朽——杨致远、菲洛和雅虎公司" class="headerlink" title="第八章 英明不朽——杨致远、菲洛和雅虎公司"></a>第八章 英明不朽——杨致远、菲洛和雅虎公司</h1><p>制定了互联网这个行业全世界至今遵守的游戏规则——开放、免费、盈利。使“免费的午餐”成为了可能。</p>
<p>选错了战略方向，在不擅长的搜索引擎上徒费心力。在优势的品牌传媒方向又止步不前。</p>
<p>没有强力的技术支撑，缺少技术基因，整体的工作环境和企业文化也不对技术人员胃口。</p>
<p>失败的高层管理，差劲的掌舵人。</p>
<h1 id="第九章-硅谷的见证人——惠普公司"><a href="#第九章-硅谷的见证人——惠普公司" class="headerlink" title="第九章 硅谷的见证人——惠普公司"></a>第九章 硅谷的见证人——惠普公司</h1><p>惠普衰落的原因：</p>
<ul>
<li>领导者的错误</li>
<li>“日本/中国制造“的冲击</li>
</ul>
<h1 id="第十章-没落的贵族——摩托罗拉公司"><a href="#第十章-没落的贵族——摩托罗拉公司" class="headerlink" title="第十章 没落的贵族——摩托罗拉公司"></a>第十章 没落的贵族——摩托罗拉公司</h1><p>衰落的原因：</p>
<ol>
<li>低估了摩尔定律的作用和产品更新的速度，对数字手机关注不足，依旧将主要精力放在落后的模拟手机上</li>
<li>领导层不能开拓，或许也无力守成</li>
</ol>
<p>铱星计划： 对市场的错误评估</p>
<blockquote>
<p>摩托罗拉至今都看不起三星和诺基亚不注重核心技术、只在外型和功能上搞花架子的做法。</p>
</blockquote>
<p>长于技术，弱于市场。不够重视市场和客户需求。</p>
<p>与AT&amp;T的短视和贪婪相反，摩托罗拉作为一个家族企业，不会出现把AT&amp;T拆了卖的败家行为，但家族第三代领导人也心有余而力不足。君子之泽，五世而折。</p>
<h1 id="第十一章-硅谷的另一面"><a href="#第十一章-硅谷的另一面" class="headerlink" title="第十一章 硅谷的另一面"></a>第十一章 硅谷的另一面</h1><p>幸存者偏差</p>
<p>勤奋与创新</p>
<h1 id="第十二章-短暂的春秋——与机会失之交臂的公司"><a href="#第十二章-短暂的春秋——与机会失之交臂的公司" class="headerlink" title="第十二章 短暂的春秋——与机会失之交臂的公司"></a>第十二章 短暂的春秋——与机会失之交臂的公司</h1><h1 id="第十三章-幕后的英雄——风险投资"><a href="#第十三章-幕后的英雄——风险投资" class="headerlink" title="第十三章 幕后的英雄——风险投资"></a>第十三章 幕后的英雄——风险投资</h1><h1 id="第十四章-信息产业的规律性"><a href="#第十四章-信息产业的规律性" class="headerlink" title="第十四章 信息产业的规律性"></a>第十四章 信息产业的规律性</h1><ul>
<li><p>70-20-10律：科技产品的指标往往是硬性的，没有办法制造差异度。以至于强者恒强。然而我不大认可这种说法。。更多的应该是先发至人和（或）配套软硬件带来的强大用户粘性导致的市场独占。</p>
</li>
<li><p>诺威格定律：一家公司市场占有率超过50%后，就无法再使市场占有率翻番了。而开拓新的财源有效的途径只有两条：扩展现有业务和转型。</p>
</li>
<li><p>基因决定定律：基因决定了公司的市场运作，发展模式等，并难以改变。我觉得基因有两种：一种是从创始之时开始确立的公司的发展方向和管理方式，市场运作方式等，还有一场则是公司成型之后各个部门之间的利益纠葛。</p>
</li>
</ul>
<h1 id="第十五章-硅谷的摇篮——斯坦福大学"><a href="#第十五章-硅谷的摇篮——斯坦福大学" class="headerlink" title="第十五章 硅谷的摇篮——斯坦福大学"></a>第十五章 硅谷的摇篮——斯坦福大学</h1><ul>
<li><p>纽曼教育</p>
</li>
<li><p>洪堡教育</p>
</li>
<li><p>斯坦福和工业界的紧密联系，创业成风的校园氛围，以及能够给学生和教授提供商业资源的能力。</p>
</li>
</ul>
<h1 id="第十六章-科技公司的吹鼓手——投资银行"><a href="#第十六章-科技公司的吹鼓手——投资银行" class="headerlink" title="第十六章 科技公司的吹鼓手——投资银行"></a>第十六章 科技公司的吹鼓手——投资银行</h1><p>华尔街对经济的影响确实可怖，但也确实有所益处。</p>
<h1 id="第十七章-挑战者——Google公司"><a href="#第十七章-挑战者——Google公司" class="headerlink" title="第十七章 挑战者——Google公司"></a>第十七章 挑战者——Google公司</h1><ul>
<li><p>个人英雄主义的文化，宁缺勿滥、一个顶十个的择人标准</p>
</li>
<li><p>公平、平等的领导、员工关系，开放、自由的工作环境</p>
</li>
<li><p>不作恶的企业原则，善待竞争者（不采用收购等合法而略显无耻的手段，在雅虎放弃低价购买google股票后悔不迭之后依旧以低价给了雅虎大量股票等），赢得了业界的尊重和支持，组建了强大的同盟军</p>
</li>
<li><p>“快速向前跑，不要看两边”的研发策略，以领先的技术击溃对手</p>
</li>
<li><p>商业运作、市场脉搏等方面的成功等</p>
</li>
</ul>
<h1 id="第十八章-成功的转基因——诺基亚、3M、GE公司"><a href="#第十八章-成功的转基因——诺基亚、3M、GE公司" class="headerlink" title="第十八章 成功的转基因——诺基亚、3M、GE公司"></a>第十八章 成功的转基因——诺基亚、3M、GE公司</h1><p>3M不断保持活力的原因：</p>
<ul>
<li><p>扬新。创新往往伴随着失败。只有能够容忍失败、容忍表面的不可能才能真正的实现创新。</p>
</li>
<li><p>弃旧。不仅弃掉已经旧的，还要弃掉虽然有盈利但是前景不佳还会阻碍创新的旧部门、旧势力</p>
</li>
<li><p>群众基础。日用品之类是最不容易受到冲击的。</p>
</li>
</ul>
<h1 id="第十九章-印钞机——最佳的商业模式"><a href="#第十九章-印钞机——最佳的商业模式" class="headerlink" title="第十九章 印钞机——最佳的商业模式"></a>第十九章 印钞机——最佳的商业模式</h1><p>下面三种商业模式都算不上好的：</p>
<ul>
<li><p>每增加一份营收就必须多雇佣一个人</p>
</li>
<li><p>无法横向拓展的业务，例如从一个地区扩展到另外一个地区需要做需要额外的工作</p>
</li>
<li><p>需要消耗过多的原料和成本</p>
</li>
</ul>
<h1 id="第二十章-互联网2-0"><a href="#第二十章-互联网2-0" class="headerlink" title="第二十章 互联网2.0"></a>第二十章 互联网2.0</h1><p>互联网2.0公司应该具备的特征（至少其中之一）：</p>
<ul>
<li><p>必须有一个平台，可以接受并且管理用户提交的内容，并且这些内容是服务主体</p>
</li>
<li><p>提供一个开放平台，让用户可以在平台上开发自己的应用程序，并且提供给其他用户使用</p>
</li>
<li><p>交互性</p>
</li>
<li><p>非竞争性和自足性</p>
</li>
</ul>
<h1 id="第二十一章-金融风暴的冲击"><a href="#第二十一章-金融风暴的冲击" class="headerlink" title="第二十一章 金融风暴的冲击"></a>第二十一章 金融风暴的冲击</h1><ul>
<li><p>生产和供给能力的大大提高，资本从实体经济向虚拟虚拟经济转移</p>
</li>
<li><p>超前消费的流行</p>
</li>
</ul>
<p>上述两种风气使社会变得浮躁和短视，很多良好的价值观被破坏。在经济危机之下，这些泡沫将会被打破，人们会捡起稳健、勤勉的传统。</p>
<p>对于欧洲封建社会变革的分析非常真实而有趣。商人用金钱作为借贷一步步蚕食领主的权力。</p>
<h1 id="第二十二章-云计算"><a href="#第二十二章-云计算" class="headerlink" title="第二十二章 云计算"></a>第二十二章 云计算</h1><h1 id="第二十三章-下一个Google"><a href="#第二十三章-下一个Google" class="headerlink" title="第二十三章 下一个Google"></a>第二十三章 下一个Google</h1><p>分析了几个新兴行业发展方向以及国内的潜力公司和发展状况。</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.muzhen.tk/2019/02/28/pansee/book review/宽容——房龙/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muzhen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the Home of MuZhen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/pansee/book review/宽容——房龙/" class="post-title-link" itemprop="url">宽容——房龙</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-28 20:45:06" itemprop="dateCreated datePublished" datetime="2019-02-28T20:45:06+08:00">2019-02-28</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/book-review/" itemprop="url" rel="index"><span itemprop="name">book review</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本书的宽容主题主要围绕着的是宗教变革过程中种种的斗争、迫害、不宽容。并在最后指出，人类历经千年斗争终于在不同信仰不同教义方面取得了初步的宽容，但紧接着种族不宽容、社会不宽容以及许多不足挂齿的不宽容又开始正式登上舞台，带给人们更大的痛苦。</p>
<p>如果说宗教不宽容更多的是团体之间的对抗，个人精神的解放带来的可能是更加极端更加琐碎而难以想象的各种不宽容。团体之间的对抗可以更加容易的通过法令、通过政治去控制，个人的不宽容却更加难以防范与规范，更加危险而无处不在，更频繁而尖锐的让每个人处在痛苦之中。</p>
<p>我想，个人的不宽容应当是自古而今始终存在的，也是各类不宽容的根源所在。只是原先大众尚未开化，个体思想不显，容易被个别领袖所操纵，又受限于生产力产生的群体依赖关系，因而更显式的表现为团体对抗。</p>
<p>我并没有在此书中看到人应该如何宽容。仅仅是对自己的思想报以警惕，看到自身的局限性与相对性并不能指导人在遭遇矛盾时的做法。绝对容易衍生强权与独裁，相对容易导致软弱与犹豫。警惕与防范不宽容要么将宽容的敌人引进大门，要么陷入另一种不宽容。我看不到恰到好处的可能性。相对是没有地基的，要么被敌人毁灭，要么从自身内部腐烂瓦解。</p>
<p>大和谐的前提一定是人拥抱同一种基本原则。在这一种原则上没有任何的宽容可以放任。尤其追求虚无缥缈的宽容与自由，不如实实在在的讨论什么是必须认同的，以及尽量放宽这一认同原则的范围，减少不必要的束缚。并以此为指导消灭异端。很遗憾的，这一基本原则的找寻不可能是一蹴而就的，势必需要不停的迭代，也就在此过程中必不可少的会发生迫害与变革。在这个过程中我们能做的也就是不要去犯相同的错误，不要采用极端的手段。不要如加尔文一般在掌权之后将相同的迫害加之于后人。</p>
<p>至于说恐惧是不宽容的根源。或许在人类伊始是这样的，但到了今天或许不宽容对部分人而言成为了一种本能。就如电影《老无所依》的恶。</p>
<h1 id="序言"><a href="#序言" class="headerlink" title="序言"></a>序言</h1><h1 id="一、无知的暴虐"><a href="#一、无知的暴虐" class="headerlink" title="一、无知的暴虐"></a>一、无知的暴虐</h1><blockquote>
<p>该书第二十六卷一○五二页这样写道“宽容(来源于拉丁字 tolerare):容许别人有行 动和判断的自由，对不同于自己或传统观点的见解的耐心公正的容忍。” </p>
</blockquote>
<blockquote>
<p>原始社会非常复杂，原始语言的时态和变格比俄语和阿拉伯语还要多，原始人不仅是现实的奴隶，也是过去和未来的奴隶;一句话，他们是凄凉悲惨的生灵，在恐惧中求生，在战栗中死去。</p>
</blockquote>
<blockquote>
<p>他们根本不懂因果法则。……<br>因此，在一个社会中，如果一切事情都被认为是由看不见的生灵操纵的，那么社会要维持下去，就必须绝对服从能平息上帝怒火的律法。<br>……<br>而低级社会形态的特点是，人们认为现状已经完 美无暇了，没有理由再做什么改进，因为他们从未见过别的世界。<br>如果上面所说的是真的，那么怎样才能防止律法和已定的社会形式有所变更呢?<br>就是靠及时惩处拒不把公共条例看做是上天旨意具体体现的那些人，说得露骨一点，就是靠僵化的专横制度。</p>
</blockquote>
<p>因为无知，所以信奉初始阶段总结出来的错误律法和“忌讳”。</p>
<blockquote>
<p>我们有时看到的宽容，其实是由于无知导致的漠不关心。</p>
</blockquote>
<blockquote>
<p>为宽容的斗争直到个性发现以后才开始。 </p>
</blockquote>
<h1 id="二、希腊人"><a href="#二、希腊人" class="headerlink" title="二、希腊人"></a>二、希腊人</h1><blockquote>
<p>“只有所有种族、气候、经济和政治条件在不健全的世界中达到或接近一种理想比例时， 高级形式的文明才会突然地、貌似自动地脱颖而出。” </p>
</blockquote>
<blockquote>
<p>他们提出，苏格拉底只要摈弃辩论、争吵、说教这些可怕陋习，不再干涉别人所偏爱的东西，不再用永无止境的疑问去纠缠他们，就可以被赦免。</p>
</blockquote>
<p>苏格拉底这样的行为是宽容么？</p>
<blockquote>
<p>但柏拉图却是古代众多理论家中唯一的一个出于对完美精神世界的炽爱而鼓吹不宽客的人。</p>
<p>……</p>
<p>这个世界观转变的原因并不难寻找。苏格拉底扎根于民众之中，而柏拉图却惧怕生活。 他为了逃避丑陋的世界，躲到了自己臆想的王国中。 </p>
</blockquote>
<p>惧怕因而独裁。</p>
<blockquote>
<p>罗马人在许多事情上甚至比黄金时代的希腊人还要宽容。他们容许臣民自由思考，但是不允许人们对政治上的某些随机应变的原则提出质问，因为罗马政权之所以从史前时期就能保持繁荣安定，全部仰仗这些原则。</p>
</blockquote>
<blockquote>
<p>希腊思想体系的老一代领袖人物把其宽容精神基于某些明确的结论上，这些结论是他们经过数世纪认真实践和苦思冥想总结出来的。而罗马人却认为，他们用不着从事这方面的探讨。他们对理论问题漠不关心，还把这种态度引为自豪，他们对实用的东西感兴趣，注重行动，看不起高谈阔论。</p>
<p>……</p>
<p>人们时常争辩说，罗马人之所以能够摆出一副至高无上的宽容姿态，是因为他们对哥罗西人、卡帕迪西亚人以及其他所有野蛮部落的人都持有同等的轻蔑态度。这可能是正确的。</p>
</blockquote>
<p>宽容起于蔑视。</p>
<blockquote>
<p>结果，所有的美味佳肴都失去了味道，所有的图书都变得乏味，所有的女人都失去了魅力，甚至生存本身也成为一种负担，很多人宁可获取一个体面的机会使自己丧生。<br>剩下的只有一种安慰!对未知和无形世界的遐想。</p>
<p>……</p>
<p>不过从长远的观点看，这种纯理性的教义缺乏罗马人所需要的营养，他们开始追求一种 可以作为精神食粮的“情感”。 </p>
<p>由此说来，纯哲学色彩的“宗教”(如果我们把宗教思想和追求有益高尚生活的愿望联系 起来，这确是一种哲学色彩的宗教)只能取悦于一小部分人……</p>
</blockquote>
<p>自我无法支撑起自我的充盈，只好需求外物。物品也无法支撑的时候，就需要求诸“神圣”。</p>
<h1 id="三、桎梏的开始"><a href="#三、桎梏的开始" class="headerlink" title="三、桎梏的开始"></a>三、桎梏的开始</h1><blockquote>
<p>大多数罗马人水深火热的生活与最早期传教士的成功 有着很大关系，就象窘苦生活导致神学的成功一样。 </p>
</blockquote>
<p>贫穷也导致自我的消亡。</p>
<blockquote>
<p>没有文字规定，没有明确的条例规则，反而使信仰者可以自由地遵循耶稣的精神而不是<br>教规文字了。如果他们被一本书束缚了，势必会把全部精力用在理论讨论上，沉缅于对句号<br>冒号的迷人的研究中。</p>
</blockquote>
<h1 id="四、上帝的晨光"><a href="#四、上帝的晨光" class="headerlink" title="四、上帝的晨光"></a>四、上帝的晨光</h1><h1 id="五、囚禁"><a href="#五、囚禁" class="headerlink" title="五、囚禁"></a>五、囚禁</h1><h1 id="六、生活的纯洁"><a href="#六、生活的纯洁" class="headerlink" title="六、生活的纯洁"></a>六、生活的纯洁</h1><p>用圆圈做比喻，说明一旦社会失衡，过于偏向某些领域，会导致崩溃。</p>
<h1 id="七、宗教裁判所"><a href="#七、宗教裁判所" class="headerlink" title="七、宗教裁判所"></a>七、宗教裁判所</h1><p>为了巩固地位和权威而裁判异教徒</p>
<h1 id="八、求知的人"><a href="#八、求知的人" class="headerlink" title="八、求知的人"></a>八、求知的人</h1><blockquote>
<p>现代的不宽容就像高卢人一样，可以分为三种：处于懒惰的不宽容，处于无知的不宽容和出于自私自利的不宽容。</p>
</blockquote>
<blockquote>
<p>无知的人仅仅因为他对事物的一无所知 便可以成为极度危险的人物。但是，他如果还为自己的智力不足措辞辩解，那就更为可怕。</p>
</blockquote>
<p>超出时代的智者如何冲出愚蠢的思想的包围？宽容和坚持并不矛盾。但当人与人之间的差距过大的时候，就会难以交流，那个时候还可能有真的宽容和谦卑么？或许更多的是怜悯？</p>
<h1 id="九、向书开战"><a href="#九、向书开战" class="headerlink" title="九、向书开战"></a>九、向书开战</h1><blockquote>
<p>因此我主张，由他们去说去写吧。如果说的是至理名言，我们就应该知道，如不然，也会很快被忘记。</p>
</blockquote>
<p>真的是这样么</p>
<h1 id="十、关于一般历史书籍，尤其是这本书"><a href="#十、关于一般历史书籍，尤其是这本书" class="headerlink" title="十、关于一般历史书籍，尤其是这本书"></a>十、关于一般历史书籍，尤其是这本书</h1><blockquote>
<p>一句话，个人的不宽容只能以自由国家的大多数公民不介意为极限，不得超越。然而官方的不宽容却不然，它可以权力浩大。</p>
</blockquote>
<h1 id="十一、文艺复兴"><a href="#十一、文艺复兴" class="headerlink" title="十一、文艺复兴"></a>十一、文艺复兴</h1><blockquote>
<p>在我看来，作家在许多地方与攻城炮兵有相同之处。他们也在操纵一门重型火炮，他们的文学炮弹也许会在最不可能的地方引起革命或动乱。</p>
</blockquote>
<blockquote>
<p>不过严格他讲，文艺复兴起先并不是“向前看”的运动。它鄙视刚刚消失的过去，称上 一代人的著作为“野蛮”之作(或“哥特式的野蛮”之作，因为哥特人曾一度和匈奴人一样 名声狼藉)。文艺复兴的主要志趣在艺术品上，因为艺术品里蕴藏着一种叫“古典精神”的物  。 </p>
<p>文艺复兴的确大大振兴了良知的自由、宽容和更为美好的世界，不过运动的领袖们并没想这样做。</p>
</blockquote>
<blockquote>
<p>马可·波罗从生到死当然一直是教会的虔诚弟子，谁要是把他比做几乎是同时代的著名的罗吉尔·培根，他还会怒不可遏。……</p>
<p>不过这两个人中还是波罗更为危险。</p>
<p>十万人中最多只有一个人会跟随培根追逐天上的虹，琢磨娓娓动 的进化理论以颠扑当 时的神圣观点，而只学过 ABC 的平民百姓却可以从马可·波罗那儿得知世界上还存在着《旧 约》作者从 想到过的东西。 </p>
<p>我并不是说在世界尚 获得一丝一毫的自由之前，仅靠出版一 书就能引起对《圣经》权威性的反叛。普遍的启蒙开化是数世纪艰苦准备的结果。不过，探险家、航海家和旅行家的朴实宣言却得到了大家的理解，这对怀疑论精神的兴起起了重大作用。怀疑论是文艺复兴后期的特点，它允许人们去说去写那些仅在几年前还会使人落入宗教法庭的魔爪的言论。</p>
</blockquote>
<blockquote>
<p>文艺复兴不是自觉钻研科学的时代，在精神领域中也很遗憾缺乏真正的志趣。这三百年里在一切事物中作主导的是美和享乐。教皇虽然暴跳如雷反对一些臣民的异端教旨，可是只要这些反叛者健谈、懂一点印刷和建筑学，他倒也十分乐于邀请他们共进晚餐。……</p>
<p>人们表露的是对生活的新的向往，但是里面却无疑蕴藏着一种潜在的不满，反对现存的社会和拥有无上权力的教会对人类理解发展的束缚。</p>
</blockquote>
<h1 id="十二、基督教改革运动"><a href="#十二、基督教改革运动" class="headerlink" title="十二、基督教改革运动"></a>十二、基督教改革运动</h1><blockquote>
<p>宗教改革是形形色色的人出于形形色色的动机造成的。直到最近我们才开始明白，宗教上的不满只是这场大动乱的次要原因，实际上它是一场不可避免的社会和经济革命，神学的背景微乎其微。</p>
</blockquote>
<blockquote>
<p>可是新教徒没有受过长达数世纪的如何进行迫害和镇压的训练，他们想建立一个没有反对者的禁地，却失败了。……</p>
<p>这就是新教为宽容事业带来的帮助。  </p>
<p>它重建了人的尊严。</p>
</blockquote>
<h1 id="十三、伊拉斯谟"><a href="#十三、伊拉斯谟" class="headerlink" title="十三、伊拉斯谟"></a>十三、伊拉斯谟</h1><blockquote>
<p>也许乔纳森·斯威夫特(按我的记忆)接近了这个问题，他说，大多数人都有足 够的宗教信仰做依据憎恨旁人，却不能爱别人。遗憾的是，这条真知灼见还不能完全解决我 们目前的困难。有些人对宗教的熟悉不逊于任何人，也最从心底里仇恨别人。有些人全无信 仰宗教的天性，却对野猫、野狗和基督世界的人类倾注了真挚感情。 </p>
</blockquote>
<blockquote>
<p>大凡为宽容而战的人，不论彼此有什么不同，都有一点是一致的，他们的信仰总是伴随着怀疑;他们可以诚实地相信自己正确，却又从不能使自己的怀疑转化为坚固绝对的信念。</p>
</blockquote>
<p>如果没有绝对的确信又如何行事？抱持一种尝试的态度当然可以，但前提在于它是一种对未来不可把控而进行的无奈尝试。而对于既定共识的违反并由此带来伤害的行为，难道还要怀疑么？譬如杀人，譬如欺诈，行此等事之人或许有其可怜之处，迫于无奈，冲动，或者是愚蠢，然而这种恶难道不应该是被确信的么？如果不能确信，岂不是彻底的陷入混乱。然而一旦被确信，便容易陷入独裁，很难界定什么是需要被确信的，什么是值得存有怀疑的。</p>
<p>更进一步的，所谓的基本原则与共识，有是如何出现的呢？不过是绝大多数人都畏惧的。譬如说都不希望被杀，被偷盗。换言之，一些行为很难被人所防范，很容易危险到绝大多数人的利益，因此行为了集体的共识。但是，如果出现一个超人，譬如死侍这样不死的存在，共识、道德对他还有用处么？绝大多数人又有什么资格来要求超人从他们的弱者角度进行思考和行动？</p>
<p>宽容之所以存在，不过是因为人能看到自己的不足，看到不宽容的事也可能发生在自己身上而已？</p>
<h1 id="十四、-拉伯雷"><a href="#十四、-拉伯雷" class="headerlink" title="十四、 拉伯雷"></a>十四、 拉伯雷</h1><blockquote>
<p>人们说:“一个大组织只要有一个人说了算，而其他所有人都跪下喊阿门，服从他，那么 管理起来还不是易若反掌。” </p>
<p>在新教徒国家长大的人要对这个错误复杂的问题有一个正确全面的了解，那真是难上加 难。不过，如果我没有搞错，教皇“一 正确”的言论就象美国的宪法修定案一样历历可数。 </p>
<p>况且，重要决策总要经过充分讨论，而最后做出决定之前的争论常常会动摇教会的稳定。 这样产生的宣言是“一 正确”的，正如同我们的宪法修定案也一 正确一样，因为它们是 “最后”的，一经明确地并入最高法律，任何争持都到此结束。 </p>
<p>谁要是说管理美国很容易，因为人们在紧急时刻都会站在宪法的一边，那就大错特错了， 就象是说天主教徒既然在重大的信仰问题上承认教皇的绝对权威，那么，他们一定是一群驯 良的羔羊，把拥有自己独特想法的权力都放弃了。 </p>
<p>假如真是这样，那么住在拉特兰和梵蒂冈宫殿里的人倒是有好日子过了。但是，只要肤浅地研究一下一千五百年来的历史，就会发现事情恰恰相反。那些主张信仰改革的人在著书立说时，似乎以为罗马当权者全然不知道路德、加尔文和茨温利满怀仇恨谴 的那些罪恶，其实他们才是真正不知事情的真相，或者说不能处埋好他们对美好事业的热情。  </p>
<p>象艾德里安六世和克莱芒七世这样的人完全了解教会有重大弊病。不过，指出丹麦王国里有些腐 现象是一回事，而改正弊病则是另一回事，就连可怜的哈姆雷特最后也不得不承认这一点。</p>
</blockquote>
<p>统治阶层并不是真的傻到不知道正在发生的事，往往他们还是最先知道的。</p>
<h1 id="十五、旧时代的新招牌"><a href="#十五、旧时代的新招牌" class="headerlink" title="十五、旧时代的新招牌"></a>十五、旧时代的新招牌</h1><blockquote>
<p>宽容就如同自由。  </p>
<p>只是乞求是得不到的。只有永远保持警惕才能保住它。</p>
</blockquote>
<p>加尔文和路德的光辉形象全部崩塌了。。</p>
<h1 id="十六、-再洗礼教徒"><a href="#十六、-再洗礼教徒" class="headerlink" title="十六、 再洗礼教徒"></a>十六、 再洗礼教徒</h1><p>是再洗礼孕育了约翰还是倒霉的被约翰坑了？</p>
<h1 id="十七、索兹尼一家"><a href="#十七、索兹尼一家" class="headerlink" title="十七、索兹尼一家"></a>十七、索兹尼一家</h1><blockquote>
<p>我们为什么不记住，我们唯一的主是耶稣基督，大家都是兄弟，有谁被赋予了压服别人的力量呢？可能其中一个兄弟比别人博学一点，但是在自由和基督的关系上，我们是平等的。</p>
</blockquote>
<h1 id="十八、蒙田"><a href="#十八、蒙田" class="headerlink" title="十八、蒙田"></a>十八、蒙田</h1><blockquote>
<p>不久之后，欧洲大陆的条件大为好转，国际商业又成为可能，于是产生了另一种历史现象。</p>
<p>以三个双字词组表示便是：生意益于宽容。</p>
</blockquote>
<p> 是否可以说物质利益高于信仰坚持呢？</p>
<h1 id="十九、阿米尼斯"><a href="#十九、阿米尼斯" class="headerlink" title="十九、阿米尼斯"></a>十九、阿米尼斯</h1><h1 id="二十、布鲁诺"><a href="#二十、布鲁诺" class="headerlink" title="二十、布鲁诺"></a>二十、布鲁诺</h1><h1 id="二十一、斯宾诺沙"><a href="#二十一、斯宾诺沙" class="headerlink" title="二十一、斯宾诺沙"></a>二十一、斯宾诺沙</h1><h1 id="二十二、新的天国"><a href="#二十二、新的天国" class="headerlink" title="二十二、新的天国"></a>二十二、新的天国</h1><h1 id="二十三、太阳国王"><a href="#二十三、太阳国王" class="headerlink" title="二十三、太阳国王"></a>二十三、太阳国王</h1><h1 id="二十四、弗雷迪里克大帝"><a href="#二十四、弗雷迪里克大帝" class="headerlink" title="二十四、弗雷迪里克大帝"></a>二十四、弗雷迪里克大帝</h1><h1 id="二十五、伏尔泰"><a href="#二十五、伏尔泰" class="headerlink" title="二十五、伏尔泰"></a>二十五、伏尔泰</h1><h1 id="二十六、百科全书"><a href="#二十六、百科全书" class="headerlink" title="二十六、百科全书"></a>二十六、百科全书</h1><blockquote>
<p>他们常常后悔没有同时代的大部分人对各种事物的敬畏感，认为这不过是过去遗留下来的、虽然没什么害处却很幼稚的东西。</p>
<p>他们很少注意古代民族的历史，西方的人们出于某些好奇的原因，从巴比伦亚人、埃及人、赫梯人和迦勒底人的历史中挑出一些记载，作为道德和习俗的行动指南。但是大师苏格拉底的真正信徒们只倾 自己良心的呼唤，根 不管后果，他们无所畏惧地生活在早已变得屈服温顺的世界。</p>
</blockquote>
<h1 id="二十七、革命的不宽容"><a href="#二十七、革命的不宽容" class="headerlink" title="二十七、革命的不宽容"></a>二十七、革命的不宽容</h1><h1 id="二十八、莱辛"><a href="#二十八、莱辛" class="headerlink" title="二十八、莱辛"></a>二十八、莱辛</h1><blockquote>
<p>莱辛用这个古老的民间故事来证明他的信念:没有一种宗教可以垄断真理。人的内心世 界比他表面上遵奉某种规定的仪式和教条更有价值，因此人们的任务就是友好地相处，任何 人也无权把自己视为完美无缺的偶像让别人崇拜，无权宣布“我比其他任何人都好，因为只 有我掌握真理。” </p>
</blockquote>
<blockquote>
<p>至少可以说，抗泰姆的推理方法是有独创性的。 </p>
<p>他说:“上帝是万能的，他可以制定出对所有人民在任何时间任何情况下都适用的科学定 律。所以，只要他想做，就可以很容易地引导人们的思想，使人们在宗教问题上持相同的观 点。我们知道上帝并没有这么干。因此，如果我们用武力迫使别人相信自己是正确的，我们 就违背了上帝的明确旨意。” </p>
</blockquote>
<h1 id="二十九、汤姆·佩恩"><a href="#二十九、汤姆·佩恩" class="headerlink" title="二十九、汤姆·佩恩"></a>二十九、汤姆·佩恩</h1><blockquote>
<p>佩恩认为，真正的宗教，他称之为“人性的宗教”，有两个敌人，一个是无神论，另一个 是盲信主义。 </p>
</blockquote>
<blockquote>
<p>公众的不宽容刚一发泄完自己的愤怒，个人的不宽容又开始了。</p>
<p>官方死刑已告终止，而私刑处死又问世了。</p>
</blockquote>
<h1 id="三十、最后一百年"><a href="#三十、最后一百年" class="headerlink" title="三十、最后一百年"></a>三十、最后一百年</h1><blockquote>
<p>二十年前写这 书一定很容易。那时在大多数人的头脑中，“不宽容”这个词几乎完全和 “宗教不宽容”的意思一样 ……</p>
<p>社会刚开始摆脱宗教偏执的恐怖，又得忍受更为痛苦的种族不宽容、社会不宽容以及许多不足挂齿的不宽容，对于它们的存在，十年前的人们连想都没想过。</p>
</blockquote>
<p>宗教偏执的摆脱让其他的不宽容进入学者、媒体、社会活动家的视野而已。或许对普通人来说，这样的不宽容无时无刻不再发生，从来不曾间断？</p>
<blockquote>
<p> 我这里说的“教育”不是指纯粹的事实积累，这被看作是现代孩子们的必需有的精神库存。我想说的是，对现时的真正理解孕育于对过去的善意大度的了解之中。</p>
<p>在这 书中我已经力图证明，不宽容不过是老百姓自卫 能的一种表现。</p>
<p>……</p>
<p>我重复一遍，恐怖是所有不宽容的起因。 </p>
<p>……</p>
<p>只要不宽容是我们的自我保护法则中必不可少的一部分，要求宽容简直是犯罪。</p>
</blockquote>
<h1 id="后记-但是这个世界并不幸福"><a href="#后记-但是这个世界并不幸福" class="headerlink" title="后记 但是这个世界并不幸福"></a>后记 但是这个世界并不幸福</h1>
          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/18/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/18/">18</a><span class="page-number current">19</span>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">muzhen</p>
              <div class="site-description motion-element" itemprop="description"></div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">369</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">38</span>
                    <span class="site-state-item-name">categories</span>
                  
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">114</span>
                    <span class="site-state-item-name">tags</span>
                  
                </div>
              
            </nav>
          

          

          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">muzhen</span>

  

  
</div>


  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.0.1</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=7.0.1"></script>

  <script src="/js/src/motion.js?v=7.0.1"></script>



  
  


  <script src="/js/src/schemes/muse.js?v=7.0.1"></script>



  

  


  <script src="/js/src/next-boot.js?v=7.0.1"></script>


  
  



  




  

  

  
  

  
  
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  


  

  

  

  

  

  

  

  

  

  

</body>
</html>
