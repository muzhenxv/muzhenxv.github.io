<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <title>优化方法 | the Home of MuZhen</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="梯度下降法SGD/batch GD/mini-batch GDSGD: 每次对一个样本点计算梯度进行更新batch GD： 每次都所有样本点计算梯度进行更新mini-batch GD: 每次对一小批样本点计算梯度进行更新 momentum\begin{split} v_t &amp;amp;&amp;amp;= \gamma v_{t-1} + \eta \cdot \nabla_\theta J(\theta">
<meta name="keywords" content="optimization,parameter estimation,gradient">
<meta property="og:type" content="article">
<meta property="og:title" content="优化方法">
<meta property="og:url" content="http://www.muzhen.tk/2017/05/14/machine learning/optimization/优化方法/index.html">
<meta property="og:site_name" content="the Home of MuZhen">
<meta property="og:description" content="梯度下降法SGD/batch GD/mini-batch GDSGD: 每次对一个样本点计算梯度进行更新batch GD： 每次都所有样本点计算梯度进行更新mini-batch GD: 每次对一小批样本点计算梯度进行更新 momentum\begin{split} v_t &amp;amp;&amp;amp;= \gamma v_{t-1} + \eta \cdot \nabla_\theta J(\theta">
<meta property="og:locale" content="en">
<meta property="og:image" content="http://omdhuynsr.bkt.clouddn.com/17-5-5/39961276-file_1493979742645_3f6b.png">
<meta property="og:image" content="http://omdhuynsr.bkt.clouddn.com/17-5-5/49809367-file_1493979972098_105f0.png">
<meta property="og:updated_time" content="2019-02-26T12:59:33.520Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="优化方法">
<meta name="twitter:description" content="梯度下降法SGD/batch GD/mini-batch GDSGD: 每次对一个样本点计算梯度进行更新batch GD： 每次都所有样本点计算梯度进行更新mini-batch GD: 每次对一小批样本点计算梯度进行更新 momentum\begin{split} v_t &amp;amp;&amp;amp;= \gamma v_{t-1} + \eta \cdot \nabla_\theta J(\theta">
<meta name="twitter:image" content="http://omdhuynsr.bkt.clouddn.com/17-5-5/39961276-file_1493979742645_3f6b.png">
  
    <link rel="alternate" href="/atom.xml" title="the Home of MuZhen" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">the Home of MuZhen</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://www.muzhen.tk"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-machine learning/optimization/优化方法" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/05/14/machine learning/optimization/优化方法/" class="article-date">
  <time datetime="2017-05-14T04:38:56.000Z" itemprop="datePublished">2017-05-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/optimization/">optimization</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      优化方法
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script></p>
<h1 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h1><h2 id="SGD-batch-GD-mini-batch-GD"><a href="#SGD-batch-GD-mini-batch-GD" class="headerlink" title="SGD/batch GD/mini-batch GD"></a>SGD/batch GD/mini-batch GD</h2><p>SGD: 每次对一个样本点计算梯度进行更新<br>batch GD： 每次都所有样本点计算梯度进行更新<br>mini-batch GD: 每次对一小批样本点计算梯度进行更新</p>
<h2 id="momentum"><a href="#momentum" class="headerlink" title="momentum"></a>momentum</h2><p>\begin{split} v_t &amp;&amp;= \gamma v_{t-1} + \eta \cdot \nabla_\theta J(\theta)  \newline<br>\theta &amp;&amp;= \theta - v_t \end{split}</p>
<p><img src="http://omdhuynsr.bkt.clouddn.com/17-5-5/39961276-file_1493979742645_3f6b.png" alt><br><img src="http://omdhuynsr.bkt.clouddn.com/17-5-5/49809367-file_1493979972098_105f0.png" alt>  </p>
<p>峡谷区域： 某些方向比另一些方向上陡峭的多，常见于局部极值点<br>在这种情况下，会出现一个方向更新缓慢（如图中x轴），一个方向更新剧烈震荡（如y轴）。<br>使用momentum后，x轴方向可以叠加历史效应使得变化便快，而y轴方向则由于前后梯度方向相反，会发生抑制，不再剧烈震荡。可以参考右图理解。</p>
<h2 id="NAG"><a href="#NAG" class="headerlink" title="NAG"></a>NAG</h2><p>NAG是对momentum的改进。<br>\begin{split} v_t &amp;&amp;= \gamma v_{t-1} + \eta \cdot \nabla J(\theta - \gamma v_{t-1})  \newline<br>\theta &amp;&amp;= \theta - v_t \end{split}<br>可以看到，差异在于当前梯度的计算上。<br>正常情况下就是算当前参数位置的梯度。但是，NAG算的却是近似未来位置的梯度。因为我们知道，参数的更新有一部分就是根据momentum作出的。这里提前将参数位置提前做了momentum这一部分变化，并计算对应梯度。<br>为什么这样更好呢？</p>
<p>NAG用到了近似二阶导信息，详见 <a href="http://www.360doc.com/content/16/1010/08/36492363_597225745.shtml" target="_blank" rel="noopener">比Momentum更快：揭开Nesterov Accelerated Gradient的真面目</a></p>
<h2 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h2><p>Adagrad可以对每个参数自适应不同的学习速率，对稀疏特征，得到大的学习更系，对非稀疏特征，得到较小的学习更新，因此该算法适合处理稀疏特征数据。  </p>
<p>其参数更新方程如下：<br>\begin{split} &amp;&amp;g_{t,i} = \nabla_{\theta_i} (\theta_i) \newline<br>&amp;&amp;\theta_{t+1,i} = \theta_{t,i} - \frac{\eta}{\sqrt{G_{t,ii} + \epsilon}} \cdot g_{t,i}\newline<br>&amp;&amp;G_t \text{为一个对角矩阵，对角元素 } e_{ii} \text{ 为过去到当前第 i 个参数 } \theta_i \text{ 的梯度平方和} \newline<br>&amp;&amp;\epsilon \text{是一个平滑参数，为了使分母不为0} \newline<br>&amp;&amp;\text{如果分母不开根号，算法性能会很糟糕} \end{split}</p>
<p>需要注意，前期很可能先起到一个梯度放大的作用！而非梯度从一开始就不断的衰减！  </p>
<p>Adagrad 存在学习速率衰减过快的问题。因此，深度学习中可能会造成训练提前结束。</p>
<h2 id="RMSProp"><a href="#RMSProp" class="headerlink" title="RMSProp"></a>RMSProp</h2><p>\begin{split} &amp;&amp;g = \nabla J(\theta) \newline<br>&amp;&amp;r = \rho r + (1- \rho) \cdot (g \odot g) \newline<br>&amp;&amp; \theta = \theta - \frac{\eta}{\epsilon + \sqrt{r}} \odot g \newline<br>&amp;&amp; \text{注： 此处为向量写法， } \odot \text{为点乘} \end{split}</p>
<p>RMSProp在Adagrad基础上引入了动量思想,并由于分母不再是以前所有时刻的梯度平方和，减小了衰减速度。</p>
<p>同样的，也可以进一步引入NAG方法，只需要在梯度计算上做改进，同时引入动量。</p>
<p>\begin{split} &amp;&amp;\theta’ = \theta - \alpha v \newline<br>&amp;&amp;g = \nabla J(\theta’) \newline<br>&amp;&amp;r = \rho r + (1- \rho) \cdot (g \odot g) \newline<br>&amp;&amp;v = \alpha v + \frac{\eta}{\epsilon + \sqrt{r}} \odot g \newline<br>&amp;&amp; \theta = \theta - v \newline<br>&amp;&amp; \text{注： 此处为向量写法， } \odot \text{为点乘} \end{split}</p>
<h2 id="Adadelta"><a href="#Adadelta" class="headerlink" title="Adadelta"></a>Adadelta</h2><p>Adagrad存在三个问题：</p>
<ol>
<li>其学习率单调递减，训练后期学习率非常小</li>
<li>其需要手工设置一个全局的初始学习率</li>
<li>更新参数时，左右两边单位不同一</li>
</ol>
<p>针对第一个问题，RMSprop可以解决。</p>
<p>针对第三个问题，我们来讨论一下。</p>
<p>对于一般的sgd方法：<br>\begin{split} unit(\Delta \theta)  \propto unit(\nabla J(\theta)) \propto  \frac{\partial{J}}{\partial{\theta}} \propto \frac{1}{unit(\theta)} \end{split}</p>
<p>类似的，在Adagrad中：<br>\begin{split} unit(\Delta \theta)  \propto 1 \end{split}</p>
<p>在牛顿法中：<br>\begin{split} unit(\Delta \theta)  \propto H^{-1} \nabla J(\theta) \propto  \frac{\partial{J}/ \partial{\theta}}{\partial^2{J}/ \partial{\theta^2}} \propto unit(\theta) \end{split}</p>
<p>可以看到，牛顿法的更新单位是一致的。</p>
<p>因此，可以仿牛顿法进行构造：</p>
<p>\begin{split} g_t &amp;&amp;= \nabla J(\theta_t) \newline<br>\Delta \theta_t &amp;&amp;= - \frac{\sqrt{E[\Delta \theta^2]_{t-1}}}{\sqrt{E[g^2]_t}+\epsilon} g_t \newline<br>E[g^2]_t &amp;&amp;= \rho E[g^2]_{t-1} + (1 - \rho) g_t^2 \newline<br>E[\Delta \theta^2]_t &amp;&amp;= \rho E[\Delta \theta^2]_{t-1} + (1 - \rho) \Delta \theta^2 \newline<br>\theta_t &amp;&amp;= \theta_{t-1} + \Delta \theta_t<br>\end{split}</p>
<p>如此一来，第三个问题就得到了解决，并且顺带解决了第二个问题。<br>为何如此仿造是合理的，参<a href="http://www.cnblogs.com/neopenx/p/4768388.html" target="_blank" rel="noopener">自适应学习率调整：AdaDelta</a>  </p>
<p>总结一下：<br>Adagrad进行了学习率衰减，RMSProp优化了Adagrad衰减过快的问题，Adadelta进一步利用了近似二阶导数信息优化了RMSProp。</p>
<h2 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h2><p>\begin{split} g &amp;&amp;= \nabla J(\theta) \newline<br>s &amp;&amp;= \rho_1 s + (1 - \rho_1) g \newline<br>r &amp;&amp;= \rho_2 r + (1 - \rho_2) g^2 \newline<br>\hat{s} &amp;&amp;= \frac{s}{1 - \rho_1} \newline<br>\hat{r} &amp;&amp;= \frac{r}{1 - \rho_2} \newline<br>\Delta \theta &amp;&amp;= - \eta \frac{\hat{s}}{\sqrt{\hat{r}}+\epsilon} \newline<br>\theta &amp;&amp;= \theta + \Delta \theta \end{split}</p>
<h1 id="二阶方法"><a href="#二阶方法" class="headerlink" title="二阶方法"></a>二阶方法</h1><h2 id="牛顿法"><a href="#牛顿法" class="headerlink" title="牛顿法"></a>牛顿法</h2><p>\begin{split} &amp;&amp;f(x) \approx f(x_k) + f’(x_k)(x-x_k) + \frac{1}{2} f’’(x_k)(x-x_k)^2 = \varphi (x)\newline<br> \text{在x处取极值时满足： } &amp;&amp;\varphi’(x) = 0 \newline<br> \text{推出： } &amp;&amp;f’(x_k) + f’’(x_k)(x-x_k) = 0 \newline<br> &amp;&amp;x = x_k - \frac{f’(x_k)}{f’’(x_k)} \newline<br> &amp;&amp; x_{k+1} = x_k - \frac{f’(x_k)}{f’’(x_k)}, k =0,1,… \end{split}</p>
<p>多维情况下：<br>\begin{split} &amp;&amp;f(x) \approx f(x_k) + \nabla f(x_k)(x-x_k) + \frac{1}{2}(x-x_k)^T \cdot \nabla^2 f(x_k) \cdot (x-x_k) = \varphi (x)\newline<br> \text{在x处取极值时满足： } &amp;&amp;\nabla \varphi(x) = 0 \newline<br> \text{推出： } &amp;&amp;g_k + H_k \cdot (x-x_k) = 0 \newline<br> &amp;&amp;x = x_k - H_k^{-1} \cdot g_k \newline<br> &amp;&amp; x_{k+1} = x_k -  H_k^{-1} \cdot g_k, k =0,1,… \newline<br> &amp;&amp; g = \nabla, H = \nabla^2 \end{split}</p>
<p>牛顿法利用二阶泰勒展开自动选择更新方向。<br>当目标是二次函数时，由于二次泰勒展开函数与原目标函数不是近似而是完全相同的二次式，Hessian矩阵退化成一个常数矩阵，从任一初始点出发，只需要一步迭代即可达到最小值点。对于非二次函数，若函数的二次性态较强，或迭代点以进入极小值的领域，则其收敛速度也是很快的。<br>但对于非二次型目标函数，有时会使函数值上升，不能保证函数值稳定下降，甚至可能发散。因为在极大值处也可以一阶导数为0。<br>以及可能会陷入局部极小值中无法跳出。</p>
<p>牛顿法存在连个主要缺点：</p>
<ol>
<li>对目标函数有较严格的要求。函数必须具有连续的一、二阶偏导数，Hessian矩阵必须正定;</li>
<li>计算复杂。计算量、存储量均很大，且均以维数N的平方比增加。</li>
</ol>
<h2 id="阻尼牛顿法"><a href="#阻尼牛顿法" class="headerlink" title="阻尼牛顿法"></a>阻尼牛顿法</h2><p>阻尼牛顿法在牛顿法的基础上引入了步长：<br>\begin{split} &amp;&amp;d_k = - H_k^{-1} \cdot g_k \newline<br>&amp;&amp;\lambda_k = \arg \min_{\lambda \in R} f(x_k + \lambda d_k) \newline<br>&amp;&amp;x_{k+1} = x_k + \lambda_k d_k \newline\end{split}</p>
<p>前面说到 $f(x_{k+1}) &gt; f(x_k))$ 的情况可能发生，因此，我们可以引入步长因子，进行一维搜索，使得更新后得到的 $f(x_{k+1})$ 必然不会变大，从而一直沿着正确的方向前进。</p>
<p>一维搜索可以使用进退法寻找到单谷所在区间，然后使用黄金分割法、评分法等在区间内找寻最小值。（理想情况下是单谷，但即使不是单谷，也并不会影响更新方向）</p>
<h2 id="拟牛顿法"><a href="#拟牛顿法" class="headerlink" title="拟牛顿法"></a>拟牛顿法</h2><p>这个方法的基本思想是：不用二阶偏导数而构造出可以近似Hessian矩阵（或其逆）的正定对称矩阵，在“拟牛顿”的条件下优化目标函数。<br>为明确起见，用B表示对H的近似，用D表示对H的逆的近似。</p>
<p>对H作出近似，需要满足拟牛顿条件，下面推导之。</p>
<p>\begin{split} &amp;&amp;f(x) \approx f(x_{k+1}) +  \nabla f(x_{k+1}) \cdot (x - x_{k+1}) + \frac{1}{2} \cdot (x - x_{k+1})^T \cdot \nabla^2 f(x_{k+1}) \cdot (x - x_{k+1}) \newline<br>\text{两边同时对x求导: } &amp;&amp;\nabla f(x) \approx \nabla f(x_{k+1}) + H_{k+1} \cdot (x - x_{k+1}) \newline<br>\text{令} x = x_k \text{整理得: }  &amp;&amp;g_{k+1} - g_k \approx H_{k+1} \cdot (x_{k+1} - x_k) \newline<br>\text{引入记号: } &amp;&amp;s_k = x_{k+1} - x_k,y_k = g_{k+1} - g_k \newline<br>\text{有: } &amp;&amp;y_k \approx H_{k+1} \cdot s_k \newline<br>\text{或: } &amp;&amp;s_k \approx H^{-1}_{k+1} \cdot y_k \end{split}</p>
<p>这就是拟牛顿条件，他对迭代过程中的 $H_{k+1}$ 作出了约束。因此，作为近似的 $B_{k+1}$ 和 $D_{k+1}$ 可以将以下公式作为指导。<br>\begin{split} &amp;&amp;y_k = B_{k+1} \cdot s_k \newline<br>&amp;&amp;s_k = D_{k+1} \cdot y_k \end{split}</p>
<p>根据H的构造函数不同，可以分为不同的拟牛顿法。下面介绍。</p>
<h2 id="DFP法"><a href="#DFP法" class="headerlink" title="DFP法"></a>DFP法</h2><p>该算法的核心是：通过迭代的方法，对H的逆做近似：<br>\begin{split} D_{k+1} = D_k + \Delta D_k, k = 0,1,2,……, D_0 = I \end{split}</p>
<p>显然，关键在于 $\Delta D_k$ 的构造，很容易猜想其可能会和 $s_k,y_k,D_k$ 发生关联。这里，我们采用待定法，即首先将其待定为某种形式，然后结合拟牛顿条件来推导。</p>
<p>可以将其待定为：<br>\begin{split} \Delta D_k = \alpha \mathbf{uu}^T +\beta \mathbf{vv}^T \end{split}<br>从形式上看，至少保证了其对称性。</p>
<p>将之代入拟牛顿条件：<br>\begin{split} \mathbf{s}_k &amp;&amp;= D_k \mathbf{y}_k + \alpha \mathbf{uu}^T \mathbf{y}_k + \beta \mathbf{vv}^T \mathbf{y}_k \newline<br>&amp;&amp;= D_k \mathbf{y}_k + (\alpha \mathbf{u}^T \mathbf{y}_k) \mathbf{u} + (\beta \mathbf{v}^T \mathbf{y}_k) \mathbf{v} \newline<br>\text{不妨令: } &amp;&amp;\alpha \mathbf{u}^T \mathbf{y}_k = 1, \beta \mathbf{v}^T \mathbf{y}_k = -1 \newline<br>\text{得: } &amp;&amp;\alpha = \frac{1}{\mathbf{u}^T \mathbf{y}_k}, \beta = - \frac{1}{\mathbf{v}^T \mathbf{y}_k} \newline \newline<br>&amp;&amp;\mathbf{u} - \mathbf{v} = \mathbf{s}_k - D_k \mathbf{y}_k \newline<br>\text{为使上式成立，不妨直接令: } &amp;&amp;\mathbf{u} = \mathbf{s}_k, \mathbf{v} = D_k \mathbf{y}_k \newline<br>\text{代入有: } &amp;&amp;\alpha = \frac{1}{\mathbf{s}_k^T \mathbf{y}_k}, \beta = - \frac{1}{\mathbf{y}_k^T D_k \mathbf{Y}_k} \text{ 其中第二个等式用到了对称性} D_k^T = D_k \newline<br>&amp;&amp;\Delta D_k = \frac{\mathbf{s}_k\mathbf{s}_k^T}{\mathbf{s}_k^T \mathbf{y}_k} - \frac{D_k \mathbf{y}_k \mathbf{y}_k^T D_k}{\mathbf{y}_k^T D_k \mathbf{y}_k} \end{split}</p>
<p>由此可以利用近似的H运用牛顿法。</p>
<h2 id="BFGS法"><a href="#BFGS法" class="headerlink" title="BFGS法"></a>BFGS法</h2><p>BFGS则是通过迭代的方法，直接对H做近似。其形式和思路和DFP基本相同。最后再去求近似H的逆运用牛顿法即可。</p>
<p>另外，除了前面提到的一维搜索来计算步长之外，还有其他搜索方法。Powell证明了带Wolfe搜索的BFGS算法的全局收敛性和超线性收敛性。</p>
<p>具体见 <a href="http://blog.csdn.net/itplus/article/details/21897443" target="_blank" rel="noopener">牛顿法与拟牛顿法学习笔记（四）BFGS 算法</a></p>
<h2 id="L-BFGS法"><a href="#L-BFGS法" class="headerlink" title="L-BFGS法"></a>L-BFGS法</h2><p>考虑一个N阶矩阵，当N=10万时，用double（8字节）来存储该矩阵将需要74.5GB内存。其内存开销非常大！</p>
<p>因此，L-BFGS 对 BFGS 进行了近似，可以减小内存开销。其基本思想是： 不再存储完整的矩阵 $D_k$ ,而是存储计算过程中的向量序列 ${s_i},{y_i}$ ，需要矩阵 $D_k$ 时，利用向量序列的计算来代替。而且，向量序列不是所有的都存，而是固定存最新的m个。每次计算 $D_k$ 时，只利用最新的m个来进行近似计算。</p>
<p>具体见<a href="http://blog.csdn.net/itplus/article/details/21897715" target="_blank" rel="noopener">牛顿法与拟牛顿法学习笔记（五）L-BFGS 算法</a></p>
<h1 id="其他策略"><a href="#其他策略" class="headerlink" title="其他策略"></a>其他策略</h1><h2 id="Shuffling-and-Curriculum-Learning"><a href="#Shuffling-and-Curriculum-Learning" class="headerlink" title="Shuffling and Curriculum Learning"></a>Shuffling and Curriculum Learning</h2><p>为了使得学习过程更加无偏，可以打乱训练样本。  </p>
<p>另一方面，可以将训练集按照某个有意义的顺序排列一次来提高模型性能和SGD收敛性，如何建立有意义的排列成为Curriculum Learning。</p>
<h2 id="Batch-normalization"><a href="#Batch-normalization" class="headerlink" title="Batch normalization"></a>Batch normalization</h2><p>\begin{split} \mu &amp;&amp;= \frac{1}{m} \sum_{i=1}^m x_i \newline<br>\sigma &amp;&amp;= \frac{1}{m} \sum_{i=1}^m (x_i - \mu)^2 \newline<br>\hat{x_i} &amp;&amp;= \frac{x_i - \mu}{\sqrt{\sigma^2 + \epsilon}} \newline<br>y_i &amp;&amp;= \gamma \hat{x_i} + \beta \equiv BN_{\gamma,\beta}(x_i) \end{split}</p>
<p>BN方法对需要层的输出做z标准化，然后再训练参数进行还原，通过这种方式来保存原输出数据的分布特征。  </p>
<p>在原paper中作者建议BN放在激活函数之前，但也有实验表明放在激活值后更好。<br>[TBC]为什么经过这样的变化之后会更好？并解决梯度消失问题？Batch Normalization: Accelerating Deep Network Training by  Reducing Internal Covariate Shift</p>
<h2 id="LRN"><a href="#LRN" class="headerlink" title="LRN"></a>LRN</h2><p>[TBC]</p>
<h2 id="Early-stopping"><a href="#Early-stopping" class="headerlink" title="Early stopping"></a>Early stopping</h2><p>当验证集效果不再显著提升时，提前结束训练。</p>
<h2 id="Gradient-noise"><a href="#Gradient-noise" class="headerlink" title="Gradient noise"></a>Gradient noise</h2><p>对于计算出的梯度增加一个高斯分布的随机误差，即：<br>\begin{split} g_{t,i} &amp;&amp;= g_{t,i} + N(0,\sigma_t^2) \newline<br>\sigma_t^2 &amp;&amp;= \frac{\eta}{(1+t)^\gamma} \end{split}</p>
<p>对梯度增加误差可以增加鲁棒性，即使初始参数值选择不好。<br>并且适合对深层次网络进行你个训练。原因在于增加随机噪声会有更多的可能性跳过局部极值点并去寻找一个更好的局部极值点，这种可能性在深层次网络中更常见。</p>
<h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><p><a href="http://sebastianruder.com/optimizing-gradient-descent/" target="_blank" rel="noopener">An overview of gradient descent optimization algorithms</a><br><a href="http://blog.csdn.net/heyongluoyao8/article/details/52478715" target="_blank" rel="noopener">梯度下降优化算法综述</a><br><a href="https://zhuanlan.zhihu.com/p/21486826" target="_blank" rel="noopener">路遥知马力——Momentum</a><br><a href="http://www.360doc.com/content/16/1010/08/36492363_597225745.shtml" target="_blank" rel="noopener">比Momentum更快：揭开Nesterov Accelerated Gradient的真面目</a><br><a href="http://blog.csdn.net/u014595019/article/details/52989301" target="_blank" rel="noopener">深度学习笔记：优化方法总结(BGD,SGD,Momentum,AdaGrad,RMSProp,Adam)</a><br><a href="http://climin.readthedocs.io/en/latest/rmsprop.html" target="_blank" rel="noopener">rmsprop</a><br><a href="http://www.cnblogs.com/neopenx/p/4768388.html" target="_blank" rel="noopener">自适应学习率调整：AdaDelta</a><br><a href="http://blog.csdn.net/luo123n/article/details/48239963" target="_blank" rel="noopener">各种优化方法总结比较（sgd/momentum/Nesterov/adagrad/adadelta）</a><br><a href="http://blog.csdn.net/elaine_bao/article/details/50890491" target="_blank" rel="noopener">解读Batch Normalization</a><br><a href="http://blog.csdn.net/itplus/article/details/21896453" target="_blank" rel="noopener">牛顿法与拟牛顿法学习笔记（一）牛顿法</a><br><a href="http://dataunion.org/20714.html" target="_blank" rel="noopener"><strong><em>寻找最优参数解：最速下降法，牛顿下降法，阻尼牛顿法，拟牛顿法DFP/BFGS</em></strong></a><br><a href="https://wenku.baidu.com/view/22138d22bcd126fff7050b99.html" target="_blank" rel="noopener">一维搜索</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.muzhen.tk/2017/05/14/machine learning/optimization/优化方法/" data-id="cjsls34x601fxhtv5xjh8w40d" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/gradient/">gradient</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/optimization/">optimization</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/parameter-estimation/">parameter estimation</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/05/14/python/class & instance/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          class &amp; instance
        
      </div>
    </a>
  
  
    <a href="/2017/05/10/development/environment/markdown下latex用法/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">markdown下latex用法</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Information-theory/">Information theory</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/NN/">NN</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/book-review/">book review</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/cluster/">cluster</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/competition/">competition</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/computer-science/">computer science</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/coss-function/">coss function</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/cv/">cv</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/data-compute/">data_compute</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/database/">database</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/datacenter/">datacenter</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/develepment/">develepment</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/dimensionality-reduction/">dimensionality reduction</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/documentation/">documentation</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/ensemble/">ensemble</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/environment/">environment</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/error-process/">error-process</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/essay/">essay</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/feature-engineering/">feature engineering</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/film-review/">film review</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/git/">git</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/imbalance-data/">imbalance data</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/linux/">linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/machine-learning/">machine learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/math/">math</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/optimization/">optimization</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/preprocessing/">preprocessing</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python-sklearn/">python-sklearn</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/recommendation-system/">recommendation system</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/series-analysis/">series analysis</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/sklearn/">sklearn</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/spark/">spark</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/statistics/">statistics</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/vision/">vision</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/visualize/">visualize</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/web/">web</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bayes/">Bayes</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/EM/">EM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ESL/">ESL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GBDT/">GBDT</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GBM/">GBM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GLM/">GLM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HTML/">HTML</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Information-theory/">Information theory</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JetBrains/">JetBrains</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/KKT/">KKT</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LDA/">LDA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Latex/">Latex</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MLE/">MLE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NLP/">NLP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NN/">NN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PCA/">PCA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SVD/">SVD</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TF-IDF/">TF-IDF</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/WMD/">WMD</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Xgboost/">Xgboost</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/adaboost/">adaboost</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/array/">array</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/blog/">blog</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/book-review/">book review</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/category-encoding/">category encoding</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cluster/">cluster</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/competition/">competition</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cost-function/">cost function</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cv/">cv</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/data-sevice/">data sevice</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/database/">database</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/datacenter/">datacenter</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/datagrip/">datagrip</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/debug/">debug</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/decision-tree/">decision tree</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/deep-learning/">deep learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/detect/">detect</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/development/">development</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dimensionality-reduction/">dimensionality reduction</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/docker/">docker</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/elasticsearch/">elasticsearch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ensemble/">ensemble</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/entropy/">entropy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/environment/">environment</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/error/">error</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/essay/">essay</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/feature-engineering/">feature engineering</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ffmpeg/">ffmpeg</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/film-review/">film review</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/flask/">flask</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/gcforest/">gcforest</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/git/">git</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/gpu/">gpu</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/gradient/">gradient</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hexo/">hexo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hive/">hive</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/infomation-extraction/">infomation extraction</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/jdk/">jdk</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/json-dumps/">json_dumps</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/">linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/log/">log</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning/">machine learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/markdown/">markdown</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/math/">math</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/matplotlib/">matplotlib</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/monitor/">monitor</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/multiprocess/">multiprocess</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mysql/">mysql</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nginx/">nginx</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nodejs/">nodejs</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nonparametric-approach/">nonparametric approach</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/optimization/">optimization</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pagerank/">pagerank</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pandas/">pandas</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pansee/">pansee</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/parameter-estimation/">parameter estimation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pip/">pip</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/preprocessing/">preprocessing</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/queue/">queue</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/recommendation-system/">recommendation system</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/regression-tree/">regression tree</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/regularization/">regularization</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/rule-learning/">rule learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scala/">scala</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scrapy/">scrapy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/screen/">screen</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sentiment-analysis/">sentiment analysis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/series-analysis/">series analysis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/setup/">setup</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/shadowsocks/">shadowsocks</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sklearn/">sklearn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spark/">spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/statistics/">statistics</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/subprocess/">subprocess</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/t-SNE/">t-SNE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tensor/">tensor</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tensorflow/">tensorflow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/terminal/">terminal</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/text-summarization/">text summarization</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/traceback/">traceback</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ubuntu/">ubuntu</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/unittest/">unittest</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vision/">vision</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/visualize/">visualize</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vps/">vps</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vscode/">vscode</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/w2v/">w2v</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/web/">web</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/website/">website</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/window/">window</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据结构/">数据结构</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Bayes/" style="font-size: 10px;">Bayes</a> <a href="/tags/EM/" style="font-size: 10px;">EM</a> <a href="/tags/ESL/" style="font-size: 10.67px;">ESL</a> <a href="/tags/GBDT/" style="font-size: 10px;">GBDT</a> <a href="/tags/GBM/" style="font-size: 10.67px;">GBM</a> <a href="/tags/GLM/" style="font-size: 14px;">GLM</a> <a href="/tags/HTML/" style="font-size: 10px;">HTML</a> <a href="/tags/Information-theory/" style="font-size: 10px;">Information theory</a> <a href="/tags/JetBrains/" style="font-size: 10.67px;">JetBrains</a> <a href="/tags/KKT/" style="font-size: 10px;">KKT</a> <a href="/tags/LDA/" style="font-size: 10px;">LDA</a> <a href="/tags/Latex/" style="font-size: 10px;">Latex</a> <a href="/tags/MLE/" style="font-size: 10px;">MLE</a> <a href="/tags/NLP/" style="font-size: 16px;">NLP</a> <a href="/tags/NN/" style="font-size: 16.67px;">NN</a> <a href="/tags/PCA/" style="font-size: 10.67px;">PCA</a> <a href="/tags/SVD/" style="font-size: 10px;">SVD</a> <a href="/tags/TF-IDF/" style="font-size: 12px;">TF-IDF</a> <a href="/tags/WMD/" style="font-size: 10px;">WMD</a> <a href="/tags/Xgboost/" style="font-size: 10px;">Xgboost</a> <a href="/tags/adaboost/" style="font-size: 10px;">adaboost</a> <a href="/tags/array/" style="font-size: 10px;">array</a> <a href="/tags/blog/" style="font-size: 10.67px;">blog</a> <a href="/tags/book-review/" style="font-size: 18px;">book review</a> <a href="/tags/category-encoding/" style="font-size: 11.33px;">category encoding</a> <a href="/tags/cluster/" style="font-size: 10px;">cluster</a> <a href="/tags/competition/" style="font-size: 10.67px;">competition</a> <a href="/tags/cost-function/" style="font-size: 11.33px;">cost function</a> <a href="/tags/cv/" style="font-size: 11.33px;">cv</a> <a href="/tags/data-sevice/" style="font-size: 10.67px;">data sevice</a> <a href="/tags/database/" style="font-size: 10.67px;">database</a> <a href="/tags/datacenter/" style="font-size: 10px;">datacenter</a> <a href="/tags/datagrip/" style="font-size: 10px;">datagrip</a> <a href="/tags/debug/" style="font-size: 10px;">debug</a> <a href="/tags/decision-tree/" style="font-size: 11.33px;">decision tree</a> <a href="/tags/deep-learning/" style="font-size: 10px;">deep learning</a> <a href="/tags/detect/" style="font-size: 10px;">detect</a> <a href="/tags/development/" style="font-size: 15.33px;">development</a> <a href="/tags/dimensionality-reduction/" style="font-size: 12.67px;">dimensionality reduction</a> <a href="/tags/docker/" style="font-size: 12px;">docker</a> <a href="/tags/elasticsearch/" style="font-size: 10px;">elasticsearch</a> <a href="/tags/ensemble/" style="font-size: 13.33px;">ensemble</a> <a href="/tags/entropy/" style="font-size: 10px;">entropy</a> <a href="/tags/environment/" style="font-size: 10.67px;">environment</a> <a href="/tags/error/" style="font-size: 10px;">error</a> <a href="/tags/essay/" style="font-size: 16.67px;">essay</a> <a href="/tags/feature-engineering/" style="font-size: 11.33px;">feature engineering</a> <a href="/tags/ffmpeg/" style="font-size: 10.67px;">ffmpeg</a> <a href="/tags/film-review/" style="font-size: 19.33px;">film review</a> <a href="/tags/flask/" style="font-size: 11.33px;">flask</a> <a href="/tags/gcforest/" style="font-size: 10px;">gcforest</a> <a href="/tags/git/" style="font-size: 10px;">git</a> <a href="/tags/gpu/" style="font-size: 10.67px;">gpu</a> <a href="/tags/gradient/" style="font-size: 10px;">gradient</a> <a href="/tags/hexo/" style="font-size: 10.67px;">hexo</a> <a href="/tags/hive/" style="font-size: 10px;">hive</a> <a href="/tags/infomation-extraction/" style="font-size: 10px;">infomation extraction</a> <a href="/tags/jdk/" style="font-size: 10px;">jdk</a> <a href="/tags/json-dumps/" style="font-size: 10px;">json_dumps</a> <a href="/tags/linux/" style="font-size: 16.67px;">linux</a> <a href="/tags/log/" style="font-size: 10.67px;">log</a> <a href="/tags/machine-learning/" style="font-size: 18.67px;">machine learning</a> <a href="/tags/markdown/" style="font-size: 11.33px;">markdown</a> <a href="/tags/math/" style="font-size: 10px;">math</a> <a href="/tags/matplotlib/" style="font-size: 12.67px;">matplotlib</a> <a href="/tags/monitor/" style="font-size: 10.67px;">monitor</a> <a href="/tags/multiprocess/" style="font-size: 10.67px;">multiprocess</a> <a href="/tags/mysql/" style="font-size: 10px;">mysql</a> <a href="/tags/nginx/" style="font-size: 10.67px;">nginx</a> <a href="/tags/nodejs/" style="font-size: 10px;">nodejs</a> <a href="/tags/nonparametric-approach/" style="font-size: 10px;">nonparametric approach</a> <a href="/tags/optimization/" style="font-size: 13.33px;">optimization</a> <a href="/tags/pagerank/" style="font-size: 10px;">pagerank</a> <a href="/tags/pandas/" style="font-size: 10px;">pandas</a> <a href="/tags/pansee/" style="font-size: 20px;">pansee</a> <a href="/tags/parameter-estimation/" style="font-size: 11.33px;">parameter estimation</a> <a href="/tags/pip/" style="font-size: 10px;">pip</a> <a href="/tags/preprocessing/" style="font-size: 10.67px;">preprocessing</a> <a href="/tags/python/" style="font-size: 17.33px;">python</a> <a href="/tags/queue/" style="font-size: 10px;">queue</a> <a href="/tags/recommendation-system/" style="font-size: 12px;">recommendation system</a> <a href="/tags/regression-tree/" style="font-size: 11.33px;">regression tree</a> <a href="/tags/regularization/" style="font-size: 10.67px;">regularization</a> <a href="/tags/rule-learning/" style="font-size: 10.67px;">rule learning</a> <a href="/tags/scala/" style="font-size: 10px;">scala</a> <a href="/tags/scrapy/" style="font-size: 10px;">scrapy</a> <a href="/tags/screen/" style="font-size: 10.67px;">screen</a> <a href="/tags/sentiment-analysis/" style="font-size: 10px;">sentiment analysis</a> <a href="/tags/series-analysis/" style="font-size: 10px;">series analysis</a> <a href="/tags/setup/" style="font-size: 10px;">setup</a> <a href="/tags/shadowsocks/" style="font-size: 10px;">shadowsocks</a> <a href="/tags/sklearn/" style="font-size: 11.33px;">sklearn</a> <a href="/tags/spark/" style="font-size: 10.67px;">spark</a> <a href="/tags/statistics/" style="font-size: 10.67px;">statistics</a> <a href="/tags/subprocess/" style="font-size: 10.67px;">subprocess</a> <a href="/tags/t-SNE/" style="font-size: 10px;">t-SNE</a> <a href="/tags/tensor/" style="font-size: 10px;">tensor</a> <a href="/tags/tensorflow/" style="font-size: 10px;">tensorflow</a> <a href="/tags/terminal/" style="font-size: 10.67px;">terminal</a> <a href="/tags/text-summarization/" style="font-size: 10px;">text summarization</a> <a href="/tags/traceback/" style="font-size: 10px;">traceback</a> <a href="/tags/ubuntu/" style="font-size: 10.67px;">ubuntu</a> <a href="/tags/unittest/" style="font-size: 10.67px;">unittest</a> <a href="/tags/vision/" style="font-size: 12.67px;">vision</a> <a href="/tags/visualize/" style="font-size: 10px;">visualize</a> <a href="/tags/vps/" style="font-size: 10px;">vps</a> <a href="/tags/vscode/" style="font-size: 10px;">vscode</a> <a href="/tags/w2v/" style="font-size: 10.67px;">w2v</a> <a href="/tags/web/" style="font-size: 10px;">web</a> <a href="/tags/website/" style="font-size: 10.67px;">website</a> <a href="/tags/window/" style="font-size: 10px;">window</a> <a href="/tags/数据结构/" style="font-size: 14.67px;">数据结构</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">February 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">June 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">October 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">August 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">July 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">June 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">May 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">April 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/11/">November 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/10/">October 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/09/">September 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/08/">August 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/07/">July 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/06/">June 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/05/">May 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/04/">April 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/03/">March 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/02/">February 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/01/">January 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/12/">December 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/11/">November 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/09/">September 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/08/">August 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/07/">July 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/04/">April 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2012/06/">June 2012</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2012/01/">January 2012</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2011/04/">April 2011</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2010/11/">November 2010</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2010/09/">September 2010</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2010/02/">February 2010</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/02/26/pansee/film review/密室逃生2019——亚当·罗伯特/">(no title)</a>
          </li>
        
          <li>
            <a href="/2019/02/26/pansee/film review/无问西东——李芳芳/">(no title)</a>
          </li>
        
          <li>
            <a href="/2019/02/25/machine learning/NN/deepleanrningai深度学习笔记/">deepleanrningai深度学习笔记</a>
          </li>
        
          <li>
            <a href="/2019/02/24/development/environment/ubuntu install scala and spark/">ubuntu install scala and spark</a>
          </li>
        
          <li>
            <a href="/2019/02/24/development/environment/ubuntu install nodejs/">ubuntu install nodejs</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 muzhen<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>